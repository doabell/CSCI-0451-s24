<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>vectorization-live</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../assets/icons/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><b>Machine Learning</b><br>CSCI 0451</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../"><b>Machine Learning</b><br>CSCI 0451</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../syllabus.html" class="sidebar-item-text sidebar-link">Syllabus</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../schedule.html" class="sidebar-item-text sidebar-link">Schedule</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments.html" class="sidebar-item-text sidebar-link">Index of Assignments</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../project.html" class="sidebar-item-text sidebar-link">Course Project</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#what-data-needs-vectorization" id="toc-what-data-needs-vectorization" class="nav-link" data-scroll-target="#what-data-needs-vectorization">What Data Needs Vectorization?</a></li>
  <li><a href="#case-study-sentiment-analysis-of-covid-19-tweets" id="toc-case-study-sentiment-analysis-of-covid-19-tweets" class="nav-link" data-scroll-target="#case-study-sentiment-analysis-of-covid-19-tweets">Case Study: Sentiment Analysis of COVID-19 Tweets</a>
  <ul class="collapse">
  <li><a href="#sketchy-labels" id="toc-sketchy-labels" class="nav-link" data-scroll-target="#sketchy-labels">Sketchy Labels</a></li>
  <li><a href="#target-vectorization" id="toc-target-vectorization" class="nav-link" data-scroll-target="#target-vectorization">Target Vectorization</a>
  <ul class="collapse">
  <li><a href="#term-frequency-tf-vectorization" id="toc-term-frequency-tf-vectorization" class="nav-link" data-scroll-target="#term-frequency-tf-vectorization">Term Frequency (TF) Vectorization</a></li>
  <li><a href="#first-model" id="toc-first-model" class="nav-link" data-scroll-target="#first-model">First Model</a></li>
  <li><a href="#inverse-document-frequency-weighting" id="toc-inverse-document-frequency-weighting" class="nav-link" data-scroll-target="#inverse-document-frequency-weighting">Inverse Document Frequency Weighting</a></li>
  </ul></li>
  <li><a href="#model-inspection" id="toc-model-inspection" class="nav-link" data-scroll-target="#model-inspection">Model Inspection</a></li>
  <li><a href="#word-based-sentiment-analysis" id="toc-word-based-sentiment-analysis" class="nav-link" data-scroll-target="#word-based-sentiment-analysis">Word-Based Sentiment Analysis</a></li>
  <li><a href="#activity-1" id="toc-activity-1" class="nav-link" data-scroll-target="#activity-1">Activity</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>So far in this course, we’ve considered the general <em>supervised learning</em> scenario, in which we are given a feature matrix <span class="math inline">\(\mX \in \R^{n\times p}\)</span> and a target vector <span class="math inline">\(\vy \in \R^n\)</span>. We then solve the empirical risk minimization problem in order to choose model parameters that minimize a loss function on the training data. The exact structure of this loss function depends on things like whether we are doing classification or regression, what our computational resources are, and other considerations.</p>
<p>But feature matrices <span class="math inline">\(\mX\)</span> and target vectors <span class="math inline">\(\vy\)</span> don’t just exist in the world: they are <em>collected</em> and <em>measured</em>. We can think of data collection and measurement as posing three fundamental questions:</p>
<ul>
<li><strong>Data collection</strong>: Which <strong>rows</strong> (observations) exist in <span class="math inline">\(\mX\)</span> and <span class="math inline">\(\vy\)</span>?</li>
<li><strong>Measurement</strong>: which <strong>columns</strong> (features) exist in <span class="math inline">\(\mX\)</span>?</li>
<li><strong>Measurement</strong>: what is the <strong>target</strong> <span class="math inline">\(\vy\)</span> and how is it measured?</li>
</ul>
<p>Broadly, we can think of the complete machine learning workflow as having phases corresponding to problem definition, data collection + measurement, modeling, and evaluation. Here’s roughly how this looks:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">flowchart TB

    subgraph problem[problem definition]
        need[identify need]--&gt;design_collection[design data collection]
    end
    subgraph measurement[data collection + measurement]
        training[training data] 
        testing[testing data]
    end
    subgraph modeling
        explore[explore data] --&gt; engineer[engineer features]
        engineer --&gt; design[design model]
    end
    subgraph assessment
        test --&gt; audit
        audit --&gt; deploy
        deploy--&gt;evaluate
    end
    design_collection--&gt;measurement
    training --vectorization--&gt; modeling
    design --&gt; assessment
    testing --vectorization--&gt; assessment
    need--&gt;assessment

</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>So far, we’ve spent most of our time in the “modeling” module, especially the last two steps. We’ve also studied some of the ways to test and audit algorithms. Today we’re going to discuss <strong>vectorization</strong>. We can think of vectorization as what happens <em>between</em> the collection of raw data and the use of that data as input for models.</p>
<div class="callout-note callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-vectorization" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Vectorization) </strong></span><strong>Vectorization</strong> is the act of assigning to each data observation a vector <span class="math inline">\(\vx\)</span>, thus forming a feature matrix <span class="math inline">\(\mX\)</span>. Formally, a <strong>vectorization map</strong> is a function <span class="math inline">\(v:\cD\rightarrow \R^p\)</span> such that, if <span class="math inline">\(d \in \cD\)</span> is a data observation, then <span class="math inline">\(\vx = v(d)\)</span> is a set of features corresponding to <span class="math inline">\(d\)</span>.</p>
</div>
</div>
</div>
</div>
<p>The reason that vectorization is necessary is that <strong>machine learning models only understand numbers</strong>. So, if our data <em>isn’t</em> numbers, we need to convert it into numbers in order to use it for modeling.</p>
</section>
<section id="what-data-needs-vectorization" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-data-needs-vectorization">What Data Needs Vectorization?</h2>
<p>Most of it!</p>
<ul>
<li>If your data comes to you as a table or matrix containing only numbers, in which each row corresponds to exactly one observation, then you may not need to vectorize.</li>
<li>If your data comes to you in <em>any other form</em>, then you need to vectorize.</li>
</ul>
<p>Some data that usually require vectorization:</p>
<ul>
<li>Images</li>
<li>Text</li>
<li>Audio files</li>
<li>Most genomic data</li>
<li>Etc. etc.</li>
</ul>
<div class="page-columns page-full"><p>There are tons of ways of vectorizing different kinds of data, and we’re not going to cover all of them. Instead, we’re going to go a little more in depth on <strong>text vectorization</strong>. We’ll discuss image vectorization much more when we get to convolutional neural networks. </p><div class="no-row-height column-margin column-container"><span class="">For your projects, depending on the data you want to work with, you may need to research vectorization schemes appropriate to your data.</span></div></div>
</section>
<section id="case-study-sentiment-analysis-of-covid-19-tweets" class="level1 page-columns page-full">
<h1>Case Study: Sentiment Analysis of COVID-19 Tweets</h1>
<div class="page-columns page-full"><p>Instead of discussing text vectorization in the abstract, let’s jump straight into an example. <em>Sentiment analysis</em> describes modeling techniques that aim to describe the emotional valence of text. For example, sentiment analysis is often used to automatically describe text as “positive”/“happy” or “negative”/“sad”. The function below will download and return a set of training data used for sentiment analysis of tweets related to the COVID-19 pandemic. </p><div class="no-row-height column-margin column-container"><span class="">I retrieved this data from its <a href="https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification">original posting</a> on Kaggle.</span></div></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> grab_tweets(data_set <span class="op">=</span> <span class="st">"train"</span>):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="ss">f"https://raw.githubusercontent.com/PhilChodrow/PIC16A/master/datasets/Corona_NLP_</span><span class="sc">{</span>data_set<span class="sc">}</span><span class="ss">.csv"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(url, encoding<span class="op">=</span><span class="st">'iso-8859-1'</span>) </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[[<span class="st">"OriginalTweet"</span>, <span class="st">"Sentiment"</span>]]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> grab_tweets()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s take a look at our training data:</p>
<div class="callout-warning callout callout-style-simple callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Activity
</div>
</div>
<div class="callout-body-container callout-body">
<p>Chat with your group. What are <strong>three questions</strong> you have about how the data was collected?</p>
</div>
</div>
<section id="sketchy-labels" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sketchy-labels">Sketchy Labels</h2>
<p>These tweets were <a href="https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification/discussion/186907">labeled manually</a> by the original collector of the data. As with any setting in which humans need to make subjective decisions, there is considerable possibility for debate. For example, here is one tweet that was labeld “<strong>extremely positive</strong>”:</p>
<p>Challenges that can cause sketchy labels include:</p>
<ul>
<li>Speed of labeling (it takes a LONG time to make high-quality labels)</li>
<li>Language familiarity</li>
<li>Ambiguity in the target language</li>
<li>Lots more!</li>
</ul>
<div class="page-columns page-full"><p>Almost always, when working with real-world data sets, we need to keep in mind that not only is our model approximate and our data incomplete, but the data may also be contaminated with <em>errors</em> that we aren’t really able to control. </p><div class="no-row-height column-margin column-container"><span class="">See <span class="citation" data-cites="northcutt2021labelerrors">@northcutt2021labelerrors</span> for much more on label errors in common machine learning benchmarks.</span></div></div>
</section>
<section id="target-vectorization" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="target-vectorization">Target Vectorization</h2>
<p>Our aim is to predict the <code>Sentiment</code> in terms of the text of the <code>OriginalTweet</code>. However, neither the text <code>OriginalTweet</code> nor the target <code>Sentiment</code> are numbers. So, we need to vectorize.</p>
<p>The possible values of the <code>Sentiment</code> column are</p>
<p>Vectorizing the target <code>Sentiment</code> is simple (although there are multiple ways). We’ll construct a new target vector which is <code>1</code> if the sentiment is <code>Positive</code> or <code>Extremely Positive</code> and <code>0</code> otherwise:</p>
<p>Vectorizing the predictor <code>OriginalTweet</code> is much more complicated, and here we face a number of choices.</p>
<section id="term-frequency-tf-vectorization" class="level3">
<h3 class="anchored" data-anchor-id="term-frequency-tf-vectorization">Term Frequency (TF) Vectorization</h3>
<p>In natural language processing (NLP), a data set of text is often called a <em>corpus</em>, and each observation is often called a <em>document</em>. Here, each document is a tweet.</p>
<p>One standard vectorization technique is to construct a <em>term-document matrix</em>. In a term-document matrix, each row corresponds to a document and each column corresponds to a “term” (usually a word) that is present in the document. The entry <span class="math inline">\(x_{ij}\)</span> of this matrix is the number of terms that term <span class="math inline">\(j\)</span> appears in document <span class="math inline">\(i\)</span>, which we’ll call <span class="math inline">\(\mathrm{tf}_{ij}\)</span>. To construct a term-document matrix, we can use the <code>CountVectorizer</code> from <code>sklearn</code>.</p>
<p>Here, <code>max_df</code> and <code>min_df</code> specify a range of frequencies to include. If a term is present in almost all documents (like “the” or “of”), then this term may not be a good indication of sentiment. On the other hand, if a term appears in only one or two documents, we probably don’t have enough data to figure out whether it matters. Finally, the choice of <code>stop_words</code> tells our vectorizer to ignore common English words that are unlikely to carry much emotional meaning, like “and” or “if”.</p>
<p>Here’s our term-document matrix. Note that most of the entries are 0 because tweets are so short!</p>
<p>The function below summarizes our entire data prep pipeline, which we’ll need for when we get to the test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_tweets(df, vectorizer, train <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> train: </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        vectorizer.fit(df_train[<span class="st">"OriginalTweet"</span>])</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> vectorizer.transform(df[<span class="st">"OriginalTweet"</span>]) <span class="co"># term-document matrix</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="dv">1</span><span class="op">*</span>df[<span class="st">"Sentiment"</span>].<span class="bu">str</span>.contains(<span class="st">"Positive"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="first-model" class="level3">
<h3 class="anchored" data-anchor-id="first-model">First Model</h3>
<p>Let’s check on the base rate:</p>
<p>So, always guessing that a tweet is <em>not</em> positive would be correct 56% of the time. Let’s see if we can beat this using logistic regression.</p>
<p>This model achieves 87% accuracy on the training data.</p>
</section>
<section id="inverse-document-frequency-weighting" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="inverse-document-frequency-weighting">Inverse Document Frequency Weighting</h3>
<p>Simple term-document matrices are good for some tasks, but in other cases it is useful to downweight terms according to their frequency in the overall training corpus. This allows our models to place greater emphasis on rarer terms, which might be more expressive of strong emotions.</p>
<div class="page-columns page-full"><p>In term-frequency-inverse-document-frequency (TF-IDF) weighting, the entry for term <span class="math inline">\(j\)</span> in document <span class="math inline">\(i\)</span> is </p><div class="no-row-height column-margin column-container"><span class="">Exact details of TF-IDF weightings differ; this is the one implemented by default in <code>sklearn</code>.</span></div></div>
<p><span class="math display">\[
\tilde{\mathrm{x}}_{ij} = \overbrace{\mathrm{tf}_{ij}}^{\text{Term frequency}}\times \underbrace{\mathrm{idf}_i}_{\text{inverse document frequency}}\;.
\]</span></p>
<p>Here, the <em>term frequency</em> <span class="math inline">\(\mathrm{tf}_{ij}\)</span> is again the number of times that term <span class="math inline">\(i\)</span> appears in document <span class="math inline">\(j\)</span>, while the inverse document frequency <span class="math inline">\(\mathrm{idf}_i\)</span> is computed with the formula</p>
<p><span class="math display">\[
\mathrm{idf}_i = \log \frac{1+n}{1+\mathrm{df}_i} + 1\;
\]</span> with <span class="math inline">\(\mathrm{df}_i\)</span> being the total number of documents in which term <span class="math inline">\(i\)</span> appears. Finally, each row of <span class="math inline">\(\tilde{\mathrm{x}}_{ij}\)</span> is normalized to have unit length:</p>
<p><span class="math display">\[
x_{ij} = \frac{x_{ij}}{\sqrt{\sum_{j}x_{ij}^2}}
\]</span></p>
<p>These <span class="math inline">\(x_{ij}\)</span> are then collected to form the feature matrix <span class="math inline">\(\mX\)</span>. Let’s try constructing a model using TF-IDF vectorization:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>tfidfv <span class="op">=</span> TfidfVectorizer(max_df <span class="op">=</span> <span class="fl">0.2</span>, min_df <span class="op">=</span> <span class="fl">0.001</span>, stop_words <span class="op">=</span> <span class="st">'english'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>X_train_tfidf, y_train <span class="op">=</span> prep_tweets(df_train, tfidfv, train <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>LR_tfidf <span class="op">=</span> LogisticRegression()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>LR_tfidf.fit(X_train_tfidf, y_train)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>LR_tfidf.score(X_train_tfidf, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our TF-IDF model got a lower training score. At this stage, one good approach would be to choose which vectorization to use (as well as the vectorization parameters) using cross-validation. For now, we’ll just go ahead and grab the test set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> grab_tweets(data_set <span class="op">=</span> <span class="st">"test"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X_test_cv, y_test <span class="op">=</span> prep_tweets(df_test, vectorizer <span class="op">=</span> cv, train <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>X_test_tfidf, y_test <span class="op">=</span> prep_tweets(df_test, vectorizer <span class="op">=</span> tfidfv, train <span class="op">=</span> <span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And evaluate!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Term-Document Frequency"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(LR_cv.score(X_test_cv, y_test))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TF-IDF"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(LR_tfidf.score(X_test_tfidf, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this case, TF-IDF did a little worse than term-document frequency vectorization on the test set.</p>
</section>
</section>
<section id="model-inspection" class="level2">
<h2 class="anchored" data-anchor-id="model-inspection">Model Inspection</h2>
<p>Let’s take a moment to learn more about how our term-document frequency-based model looks at the data. One good way to do this is by looking at the confusion matrices:</p>
<p>The false negative rate is higher than the true positive rate, suggesting that our model tends to tilt negative. Let’s take a look at some tweets that our model labeled as negative even though the label was positive:</p>
<p>At this point we might have some further questions for the producer of this data set about how he did the labeling: don’t some of these tweets look like they “really” should be negative?</p>
</section>
<section id="word-based-sentiment-analysis" class="level2">
<h2 class="anchored" data-anchor-id="word-based-sentiment-analysis">Word-Based Sentiment Analysis</h2>
<p>A nice feature of linear models like logistic regression is that we can actually check the coefficient for each word in the model. This coefficient can give us important information about which words the model believes are most positive or most negative. One easy way to get at this information is to construct a data frame with the coefficients and the words:</p>
<p>Now we can obtain positive and negative words by sorting. Here are some of the good ones:</p>
<p>On the other hand, here are some of the negative ones:</p>
<p>A common use for these coefficients is to assign sentiment scores to sentences. Here’s a function that does this. It works by first stripping the punctuation and capitalization from a string, and then looking up each of its individual words in a dictionary.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> string <span class="im">import</span> punctuation </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> {coef_df[<span class="st">"word"</span>].loc[i] : coef_df[<span class="st">"coef"</span>].loc[i] <span class="cf">for</span> i <span class="kw">in</span> coef_df.index}</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sentiment_of_string(s):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    no_punc <span class="op">=</span> s</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> punc <span class="kw">in</span> punctuation:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        no_punc <span class="op">=</span> no_punc.replace(punc, <span class="st">""</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> no_punc.lower().split()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean([d[word] <span class="cf">for</span> word <span class="kw">in</span> words <span class="cf">if</span> word <span class="kw">in</span> d ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This approach is the basis of <a href="https://hedonometer.org/timeseries/en_all/?from=2021-09-23&amp;to=2023-03-22">The Hedonometer</a>, a large-scale Twitter sentiment analysis tool from our friends at the University of Vermont.</p>
</section>
<section id="activity-1" class="level2 {callout-warning}">
<h2 class="anchored" data-anchor-id="activity-1">Activity</h2>
<p>There is a very important kind of information that is <em>not</em> captured by term-document matrices, even with inverse-document-frequency weighting. Consider the following two sentences:</p>
<ol type="1">
<li>“I like pears, not apples.”</li>
<li>“I like apples, not pears.”</li>
</ol>
<p>Would these sentences have different representations in a term-document matrix?</p>
</section>


</section>

<p><br> <br> <span style="color:grey;">© Phil Chodrow, 2023</span></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>