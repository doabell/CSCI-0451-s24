<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Schedule</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./assets/icons/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-listing/list.min.js"></script>
<script src="site_libs/quarto-listing/quarto-listing.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-date','listing-header','listing-summary','listing-objectives','listing-reading','listing-notes','listing-module','listing-publish','listing-warmup','listing-assignments','listing-optional',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] }],
      
      searchColumns: ["listing-date","listing-header","listing-summary","listing-objectives","listing-reading","listing-notes","listing-module","listing-publish","listing-warmup","listing-assignments","listing-optional"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Schedule</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"><b>Machine Learning</b><br>CSCI 0451</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link">Syllabus</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./schedule.html" class="sidebar-item-text sidebar-link active">Schedule</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assignments.html" class="sidebar-item-text sidebar-link">Index of Assignments</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./project.html" class="sidebar-item-text sidebar-link">Course Project</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Schedule</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<ul>
<li>Readings in normal font should be completed and annotated ahead of lecture.</li>
<li><em>Readings in italic provide optional additional depth on the material.</em><br>
</li>
<li><strong>Assignments</strong> are listed on the day when I suggest you begin working on them.</li>
</ul>




<div class="quarto-listing quarto-listing-container-custom" id="listing-listing">

            <h2 class="anchored"> Week 1 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Feb. 13</span></td> 
            <td colspan="2"> Welcome!
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss how the course works and begin our discussion of classification and auditing. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Getting Oriented <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="./syllabus.html">Course syllabus</a><br> 
                           <a href="./collaboration.html">Collaboration</a><br> 
                           <a href="https://via.hypothes.is/https://www.jessestommel.com/why-i-dont-grade/">Why I Don't Grade</a> by Jesse Stommel<br> 
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch01.pdf">Daumé 1.1-1.5</a><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./slides/welcome.html">Welcome slides</a>
 <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./software.html">Set up your software</a>.
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    No really, <br><a href="./software.html">set up your software</a>.
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Feb. 15</span></td> 
            <td colspan="2"> Classification: The Perceptron
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We study the perceptron algorithm, a historical method that serves as the foundation for many modern classifiers. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch04.pdf">Daumé 4.1-4.5, 4.7</a><br> 
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/#2.-Introduction-to-NumPy">Introduction to Numpy</a> from The Python Data Science Handbook by Jake VanderPlas<br> 
                           <a href="https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/math/linear-algebra-I.ipynb">Linear algebra with Numpy</a><br> 
                           <i><a href="https://via.hypothes.is/https://arxiv.org/pdf/2102.05242.pdf">Hardt and Recht</a>, p. 33-41 (if you need to see a definition of a function gradient, see <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé p. 93</a>)</i><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/perceptron.html">Lecture notes</a>
 <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-perceptron">Perceptron</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-perceptron.html">Blog post: perceptron</a>
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 2 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Feb. 20</span></td> 
            <td colspan="2"> Convex Linear Models and Logistic Regression
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss the modeling choices necessary to make the empirical risk minimization problem for linear classifiers tractable. In doing so we discuss convex functions and some of their properties that are relevant for optimization. Finally, we introduce logistic regression as an example of a convex linear classifier. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch02.pdf">Daumé 2.1-2.7</a>
<br> 
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé 7.1-7.3</a>
<br> 
                           <a href="https://via.hypothes.is/https://arxiv.org/pdf/2102.05242.pdf">Hardt and Recht, p. 70-77</a><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/convex-linear-models.html">Lecture notes</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-convexity">Convexity</a>
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Feb. 22</span></td> 
            <td colspan="2"> Optimization via Gradient Descent 
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss standard mathematical methods for empirical risk minimization, including gradient descent and stochastic gradient descent. We also recontextualize the perceptron algorithm as stochastic subgradient descent for a linear classifier with a specific loss function. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé 7.4-7.6</a><br> 
                           <a href="https://via.hypothes.is/https://mml-book.github.io/book/mml-book.pdf">Diesenroth, Faisal, and Soon, p. 225-233</a><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/gradient-descent.html">Lecture notes</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-gradient-descent">Gradient Descent</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-optimization.html">Blog post: gradient descent</a>
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 3 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Feb. 27</span></td> 
            <td colspan="2"> Features, Regularization, and Nonlinear Decision Boundaries
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We learn how to use feature maps to help our convex linear classifiers learn nonlinear patterns. We also introduce the problem of overfitting and introduce feature selection and regularization as methods for addressing this problem. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
                            Navigation <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html">Introducing Scikit-Learn</a><br> 
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html">Hyperparameters and Model Validation</a><br> 
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html">Feature Engineering</a><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/features-regularization.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/features-regularization-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-gradient-descent-2">Gradient Descent Again</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <b>ACTUAL REAL DUE DATE</b>: <a href="./assignments/process/goal-setting.html">Reflective Goal-Setting</a> due 2/27 
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Mar. 01</span></td> 
            <td colspan="2"> Classification in Practice
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We work through a complete modeling workflow for the Titanic survival data set. Along the way, we work with data frames and discuss cross-validation. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Navigation <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch02.pdf">Daumé Chapter 2</a> <i>You may find it useful to review Chapter 1 as well.</i><br> 
                           <a href="https://via.hypothes.is/https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html">Data Manipulation with Pandas</a> (Focus on the sections up to and including "Aggregation and Grouping")<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/classification-in-practice.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/classification-in-practice-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-overfitting">Overfitting and the Scientific Method</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-kernel-logistic.html">Blog post: kernel logistic regression</a> <br> <b>OR</b> <br> <a href="./assignments/blog-posts/blog-post-penguins.html">Blog post: penguins</a>
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 4 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Mar. 06</span></td> 
            <td colspan="2"> Beyond Convex Linear Classifiers
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss several examples of other classifiers at a high level, including some that are nonlinear or nonconvex. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Navigation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           NA<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/more-on-classification.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/more-on-classification-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Mar. 08</span></td> 
            <td colspan="2"> Linear Regression
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We introduce linear regression, another convex linear model suitable for predicting real numbers instead of class labels. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           NA<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/regression.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/regression-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-linear-regression.html">Blog post: Linear regression</a> 
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 5 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Mar. 13</span></td> 
            <td colspan="2"> Introduction to Bias and Fairness
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                TBD
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Social Responsibility <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://via.hypothes.is/https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias</a> by Julia Angwin et al. for ProPublica.<br> 
                           <a href="https://via.hypothes.is/https://arxiv.org/pdf/1703.00056.pdf">Fair prediction with disparate impact</a> by Alexandra Chouldechova, Sections 1 and 2.<br> 
                           <a href="https://arxiv.org/pdf/1609.05807,">Inherent trade-offs in the fair determination of risk scores</a> by Jon Kleinberg et al, pages 1-5.<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/intro-allocative-bias.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/intro-allocative-bias-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-classification-rates-2">Balancing Classification Rates</a>
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Mar. 15</span></td> 
            <td colspan="2"> Critical Perspectives 
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss limitations of the quantitative approach to studying discrimination, as well as critical perspectives on the role that automated decision systems play in surveilling and controlling marginalized individuals. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Social Responsibility <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://www.cs.princeton.edu/~arvindn/talks/baldwin-discrimination/baldwin-discrimination-transcript.pdf">The Limits of the Quantitative Approach to Discrimination</a>, speech by Arvind Narayanan<br> 
                           <a href="https://harpers-org.ezproxy.middlebury.edu/archive/2018/01/the-digital-poorhouse/">"The Digital Poorhouse"</a> by Virginia Eubanks for <i>Harper's Magazine</i><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            TBD <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-limits-quantitative">Limits of the Quantitative Approach</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-limits-of-quantitative.html">Blog post: Limits of quantitative methods</a> <br> <b> OR </b><br> 
<a href="./assignments/blog-posts/blog-post-bias-allocative.html">Blog post: Auditing allocative bias</a>
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 6 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Mar. 27</span></td> 
            <td colspan="2"> Vectorization
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We discuss some ways by which complex objects like images and especially text can be represented as numerical vectors for machine learning algorithms. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Navigation <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://probml.github.io/pml-book/book1.html">Murphy, Chapter 1</a>. This is not related to vectorization; it's for you to get oriented on some possible project ideas. Don't worry about any math you don't understand.<br> 
                           <a href="./project.html">Course project description</a><br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/vectorization.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/vectorization-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-project-idea">Pitch a Project Idea</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <b>ACTUAL REAL DUE DATE</b>: <a href="./assignments/process/mid-course.html">Mid-semester reflection</a> due 4/05
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Mar. 29</span></td> 
            <td colspan="2"> Introducing Unsupervised Learning: Topic Modeling
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We begin to discuss <i>unsupervised</i> learning, with topic modeling as our initial example. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Navigation <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html">Principal Component Analysis</a> from the Python Data Science Handbook<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/introducing-dimensionality-reduction.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/introducing-dimensionality-reduction-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-vectorization">Vectorization Brainstorm</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <b>ACTUAL REAL DUE DATE</b>: <a href="./assignments/project/proposal.html">Project Proposal</a> due 4/07
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 7 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Apr. 03</span></td> 
            <td colspan="2"> Clustering Data
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We continue our discussion of <i>unsupervised</i> learning with two methods for clustering sets of data. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Navigation <br> 
                            Experimentation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html">K-Means Clustering</a> from the Python Data Science Handbook<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/clustering.html">Lecture notes</a> <br> 
                            <a href="https://middlebury-csci-0451.github.io/CSCI-0451/lecture-notes/clustering-live.ipynb">Live version</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-compression">K-Means Compression</a>
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Assignments</b><br>
                    <a href="./assignments/blog-posts/blog-post-image-processing.html">Blog post: Unsupervised learning with linear algebra</a> (however, using this time to complete a previous blog post is also highly recommended)
            </td>
        </tr>
        <tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">W</span>
                    <br>
                    <span class="syllabus-date">Apr. 05</span></td> 
            <td colspan="2"> Introducing Deep Learning
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We begin our discussion of deep learning with a quick theoretical motivation and a first glance at the PyTorch package. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Navigation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://chinmayhegde.github.io/dl-notes/notes/lecture01/">Lecture 1, Introduction</a> from Chinmay Hegde's course on deep learning at NYU<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            <a href="./lecture-notes/intro-deep.html">Lecture notes</a> <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-intro-tensors">Introducing Tensors</a>
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
        </tr>
            </tbody></table>
            <h2 class="anchored"> Week 8 </h2>
            <table>
        <tbody><tr>
            <td rowspan="2" class="syllabus-date-pane">
                    <span class="syllabus-day-of-week">M</span>
                    <br>
                    <span class="syllabus-date">Apr. 10</span></td> 
            <td colspan="2"> Optimization For Deep Learning
 </td>  
        </tr>
        <tr>
            <td colspan="4" class="smaller"> 
                We begin a discussion of the training process for neural networks, which requires efficient computation of gradients via backpropagation and efficient variations of gradient descent. 
            </td>
        </tr>
        <tr>
            <td></td>
            <td class="smaller syllabus-item-objective">
                    <b>Learning Objectives</b><br>
                            Theory <br> 
                            Implementation <br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Reading</b><br>
                           <a href="https://chinmayhegde.github.io/dl-notes/notes/lecture02/">Lecture 2, Neural Nets</a> from Chinmay Hegde's course on deep learning at NYU<br> 
            </td>
            <td class="smaller syllabus-item-readings">
                    <b>Notes</b><br>
                            TBD <br> 
            </td>
            <td class="smaller syllabus-item-assignment">
                    <b>Warmup</b><br>
                    <a href="./warmup-exercises.html#sec-backprop">Efficient Differentiation</a>
            </td>
            <td class="smaller syllabus-item-assignment">
            </td>
        </tr>
        </tbody></table>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><p><br> <br> <span style="color:grey;">© Phil Chodrow, 2023</span></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>