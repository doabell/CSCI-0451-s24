[
  {
    "objectID": "lecture-notes/convex-linear-models-demo.html",
    "href": "lecture-notes/convex-linear-models-demo.html",
    "title": "",
    "section": "",
    "text": "z = np.linspace(0, 5, 101)\nplt.plot(z, -np.log(1/(1 + np.exp(-z)))) \nlabs = plt.gca().set(xlabel = r\"$\\hat{y}$\", ylabel = r\"$-\\log \\sigma(\\hat{y})$\")\n\n\n\n\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\nNote that this data is not linearly separable. The perceptron algorithm wouldn’t even have converged for this data set, but logistic regression will do great.\n\n\n\n\n\n# add a constant feature to the feature matrix\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\nNow we’ll define some functions to compute the empirical risk:\n\n# implement: (WE ARE CODING TOGETHER HERE!!)\n# - predict\n# - sigmoid\n# - logistic_loss\n# - empirical_risk\n\ndef predict(X, w):\n    return X@w\n\ndef logistic_loss(y_hat, y):\n    return -y*np.log(sigmoid(y_hat)) - (1-y)*np.log(1 - sigmoid(y_hat))\n\ndef sigmoid(y_hat): \n    return 1 / (1 + np.exp(-y_hat))\n\ndef empirical_risk(X, y, w, loss):\n    y_hat = predict(X, w)\n    return loss(y_hat, y).mean()\n\nFinally, we can write the function that will solve the empirical risk minimization problem for us. We’re going to use the scipy.optimize.minimize function, which is a built-in function for solving minimization problems. Soon, we’ll study how to solve minimization problems from scratch.\nThe scipy.optimize.minimize function requires us to pass it a single function that accepts a vector of parameters, plus an initial guess for the parameters.\n\ndef find_pars(X, y):\n    \n    p = X.shape[1]\n    w0 = np.random.rand(p) # random initial guess\n    \n    # perform the minimization\n    result = minimize(lambda w: empirical_risk(X, y, w, logistic_loss), \n                      x0 = w0) \n    \n    # return the parameters\n    return result.x\n\nOk, let’s try it and take a look at the parameters we obtained. Because the final column of X_ is the constant column of 1s, the final entry of w is interpretable as the intercept term b.\n\nw = find_pars(X_, y)\nw\n\narray([ 2.13023501,  1.71745945, -0.15021883])\n\n\nAnd, finally, we can plot the linear classifier that we learned.\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\n\nplt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\n\n\n\nSince the logistic loss is convex, we are guaranteed that this solution is the unique best solution (as measured by the logistic loss). There is no other possible set of parameters that would lead to a better result (again, as measured by the logistic loss).\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/gradient-descent.html",
    "href": "lecture-notes/gradient-descent.html",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "$$\n$$\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/gradient-descent.html#gradients",
    "href": "lecture-notes/gradient-descent.html#gradients",
    "title": "Optimization with Gradient Descent",
    "section": "Gradients",
    "text": "Gradients\nWe’re not going to talk much about what it means for a function to be multivariate differentiable. You can assume that all the functions we will deal with in this class are unless I highlight otherwise. For a more rigorous definition, you should check out a multivariable calculus class.\n\n\n\n\n\n\n\nDefinition 1 (Gradient of a Multivariate Function) Let \\(f:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) be a multivariate differentiable function. The gradient of \\(f\\) evaluated at point \\(\\mathbf{z}\\in \\mathbb{R}^p\\) is written \\(\\nabla f(\\mathbf{z})\\), and has value\n\\[\n\\nabla f(\\mathbf{z}) \\triangleq\n\\left(\\begin{matrix}\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_1} \\\\\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_2} \\\\\n    \\cdots \\\\\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_p} \\\\\n\\end{matrix}\\right) \\in \\mathbb{R}^p\\;.\n\\]\nHere, \\(\\frac{\\partial f(\\mathbf{z})}{\\partial z_1}\\) is the partial derivative of \\(f\\) with respect to \\(z_1\\), evaluated at \\(\\mathbf{z}\\). To compute it:\n\nTake the derivative of \\(f\\) *with respect to variable \\(z_1\\), holding all other variables constant, and then evaluate the result at \\(\\mathbf{z}\\).\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet \\(p = 3\\). Let \\(f(\\mathbf{z}) = z_2\\sin z_1 + z_1e^{2z_3}\\). The partial derivatives we need are\n\\[\n\\begin{align}\n\\frac{\\partial f(\\mathbf{z})}{\\partial z_1} &= z_2 \\cos z_1 + e^{2z_3}\\\\\n\\frac{\\partial f(\\mathbf{z})}{\\partial z_2} &= \\sin z_1\\\\\n\\frac{\\partial f(\\mathbf{z})}{\\partial z_3} &= 2z_1 e^{2z_3}\\;.\n\\end{align}\n\\]\nSo, the gradient of \\(f\\) evaluated at a point \\(\\mathbf{z}\\) is\n\\[\n\\nabla f(\\mathbf{z}) =\n\\left(\\begin{matrix}\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_1} \\\\\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_2} \\\\\n    \\frac{\\partial f(\\mathbf{z})}{\\partial z_3} \\\\\n\\end{matrix}\\right) =\n\\left(\\begin{matrix}\n    z_2 \\cos z_1 + e^{2z_3}\\\\\n    \\sin z_1\\\\\n    2z_1 e^{2z_3}\n\\end{matrix}\\right)\n\\]\n\n\nSo, a gradient \\(\\nabla f(\\mathbf{z})\\) is a vector of the same dimension as \\(\\mathbf{z}\\). What happens if we combine them? This is where we get to the really important aspects of gradients for practical purposes:\n\n\n\n\n\n\n\nTheorem 1 (Local Minima Have \\(\\nabla f(\\mathbf{z}_0) = \\mathbf{0}\\)) \nLet \\(f:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) be differentiable. If \\(\\mathbf{z}_0\\) is a local minimum of \\(f\\), then \\(\\nabla f(\\mathbf{z}_0) = \\mathbf{0}\\).\n\n\nTheorem 2 (\\(-\\nabla f\\) Is A Descent Direction) \nLet \\(f:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) be differentiable. Then, for any point \\(\\mathbf{z}\\in \\mathbb{R}^p\\), if \\(\\nabla f(\\mathbf{z}) \\neq \\mathbf{0}\\), then there exists a scalar \\(\\alpha\\) such that, if \\(\\mathbf{z}' = \\mathbf{z}- \\alpha \\nabla f(\\mathbf{z})\\), then \\(f(\\mathbf{z}') \\leq f(\\mathbf{z})\\).\n\n\n\n\nTheorem 1 and Theorem 2 are important because they give us the mechanics of how to solve the empirical risk minimization problem (Equation 1). Here’s our first version:\n\n\n\n\n\n\nAlgorithm: (Batch) Gradient Descent\n\n\n\nInputs: Function \\(f\\), initial starting point \\(\\mathbf{z}^{(0)}\\), learning rate \\(\\alpha\\).\nUntil convergence, in each iteration \\(t\\),\n\nCompute \\(\\mathbf{z}^{(t+1)} \\gets \\mathbf{z}^{(t)} - \\alpha \\nabla f(\\mathbf{z}^{(t)})\\).\n\nReturn the final value of \\(\\mathbf{z}^{(t)}\\).\n\n\nConvergence for gradient descent can be decided in a few different ways. One approach is to declare convergence when \\(\\nabla f(\\mathbf{z}^{(t)})\\) is close to 0. Another way is to declare convergence when the improvement in the function \\(f\\) is small enough in magnitude.\n\nSample code:\nif np.allclose(grad, np.zeros(len(grad))):\n    print(\"converged\")\n\n# or\n\nif f(w_new) - f(w_prev) < 1e-6:\n    print(\"converged\")\n\nThe following theorem says that gradient descent works if the learning rate is small enough:\n\n\n\n\n\n\n\nTheorem 3 \nSuppose that \\(f\\) is strictly convex, is differentiable, and has a global minimizer \\(\\mathbf{z}^*\\). Then, there exists some \\(\\alpha > 0\\) such that gradient descent applied to \\(f\\) produces a sequence of points \\(\\mathbf{z}^{(0)}, \\mathbf{z}^{(1)},\\ldots, \\mathbf{z}^{(t)}\\) that converges to \\(\\mathbf{z}^*\\)."
  },
  {
    "objectID": "lecture-notes/gradient-descent.html#gradient-descent-for-empirical-risk-minimization",
    "href": "lecture-notes/gradient-descent.html#gradient-descent-for-empirical-risk-minimization",
    "title": "Optimization with Gradient Descent",
    "section": "Gradient Descent For Empirical Risk Minimization",
    "text": "Gradient Descent For Empirical Risk Minimization\nSuppose that we have a per-observation loss function \\(\\ell\\) that is strictly convex and differentiable. Suppose that we are still dealing with a linear predictor of the form in Equation 2. Then, we know that the empirical risk objective function \\(L\\) is also strictly convex and differentiable. It follows from Theorem 3 that, if there is a minimizer \\(\\mathbf{w}^*\\) for the empirical risk, then we can find it using gradient descent. To do this, we need to be able to calculate the gradient of the loss function \\(L\\). Here’s how this looks. Keep in mind that we are differentiating with respect to \\(\\mathbf{w}\\).\n\\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\nabla \\left(\\frac{1}{n} \\sum_{i = 1}^n \\ell(f_{\\mathbf{w}}(\\mathbf{x}_i), y_i)\\right) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n \\nabla \\ell(f_{\\mathbf{w}}(\\mathbf{x}_i), y_i) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(\\hat{y}_i, y_i)}{d\\hat{y}} \\nabla f_{\\mathbf{w}}(\\mathbf{x}_i) \\tag{multivariate chain rule} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(\\hat{y}_i, y_i)}{d\\hat{y}} \\nabla \\mathbf{x}_i \\tag{gradient of a linear function} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle, y_i)}{d\\hat{y}} \\mathbf{x}_i \\tag{$\\hat{y}_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle$} \\\\\n\\end{align}\n\\]\nThe good news here is that for linear models, we don’t actually need to be able to compute more gradients: we just need to be able to compute derivatives of the form \\(\\frac{d\\ell(\\hat{y}_i, y_i)}{d\\hat{y}}\\) and then plug in \\(\\hat{y}_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\).\nLet’s do an example with the logistic loss:\n\\[\\ell(\\hat{y}, y) = -y \\log \\sigma(\\hat{y}) - (1-y)\\log (1-\\sigma(\\hat{y}))\\;.\\]\nA useful fact to know about the logistic sigmoid function \\(\\sigma\\) is that \\(\\frac{d\\sigma(\\hat{y}) }{d\\hat{y}} = \\sigma(\\hat{y}) (1 - \\sigma(\\hat{y}))\\). So, using that and the chain rule, the derivative we need is\n\\[\n\\begin{align}\n\\frac{d\\ell(\\hat{y}, y)}{d\\hat{y}} &= -y \\frac{1}{\\sigma(\\hat{y})}\\frac{d\\sigma(\\hat{y}) }{d\\hat{y}} - (1-y)\\frac{1}{1-\\sigma(\\hat{y})}\\left(- \\frac{d\\sigma(\\hat{y}) }{d\\hat{y}}\\right) \\\\\n&= -y \\frac{1}{\\sigma(\\hat{y})}\\sigma(\\hat{y}) (1 - \\sigma(\\hat{y})) - (1-y)\\frac{1}{1-\\sigma(\\hat{y})}\\left(- \\sigma(\\hat{y}) (1 - \\sigma(\\hat{y}))\\right) \\\\\n&= -y (1 - \\sigma(\\hat{y})) + (1-y)\\sigma(\\hat{y}) \\\\\n&= \\sigma(\\hat{y}) - y\\;.\n\\end{align}\n\\]\nFinally, we need to plug this back in to our empirical risk, obtaining the gradient of the empirical risk for logistic regression:\n\\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\frac{1}{n} \\sum_{i = 1}^n (\\sigma(\\hat{y}_i) - y_i)\\mathbf{x}_i \\\\\n              &=\\frac{1}{n} \\sum_{i = 1}^n (\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle) - y_i)\\mathbf{x}_i\\;.\n\\end{align}\n\\]\nSo, we can do logistic regression by choosing a learning rate and iterating the update \\(\\mathbf{w}^{(t+1)} \\gets \\mathbf{w}^{(t)} - \\alpha \\nabla L(\\mathbf{w}^{(t)})\\) until convergence.\nLet’s see this in action. Here’s a data set:\n\n\nCode\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets import make_blobs\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nNote that this data is not linearly separable. The perceptron algorithm wouldn’t even have converged for this data set, but logistic regression will do great.\n\n\n\n\nThe code below is very similar to the code from last time, but I’m going to first transform the feature matrix \\(\\mathbf{X}\\) so that it contains a column of constant features. This is going to make our mathematical life a lot easier.\n\nimport numpy as np \nfrom scipy.optimize import minimize\nnp.seterr(all='ignore') \n\n# add a constant feature to the feature matrix\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\ndef predict(X, w):\n    return X@w\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef logistic_loss(y_hat, y): \n    return -y*np.log(sigmoid(y_hat)) - (1-y)*np.log(1-sigmoid(y_hat))\n\ndef empirical_risk(X, y, loss, w):\n    y_hat = predict(X, w)\n    return loss(y_hat, y).mean()\n\nI’ll start by picking a random parameter vector, visualizing the corresponding line, and computing the loss:\n\nnp.random.seed(123)\n\n# pick a random weight vector and calculate the loss\nw = .5 - np.random.rand(p_features)\nloss = empirical_risk(X_, y, logistic_loss, w)\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = plt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\ntitle = plt.gca().set_title(f\"Loss = {loss}\")\n\n\n\n\nIt can be hard to put these kinds of numbers in context, but this is a pretty poor value of the loss. You could probably guess that considering how bad the classifier line looks.\nNow let’s go ahead and use gradient descent to compute a better value of the parameter vector \\(\\tilde{\\mathbf{w}}\\). I’ve shown you the main loop of the algorithm, but not the calculation of the gradient. It’ll be up to you to implement the gradient (as well as variations of gradient descent) in an upcoming blog post.\n\nfrom hidden.logistic import gradient\n\nalpha = .001 # learning rate\n\ndone = False       # initialize for while loop\nprev_loss = np.inf # handy way to start off the loss\n\n# main loop\nwhile not done: \n    w -= alpha*gradient(w, X_, y)                      # gradient step\n    new_loss = empirical_risk(X_, y, logistic_loss, w) # compute loss\n    \n    # check if loss hasn't changed and terminate if so\n    if np.isclose(new_loss, prev_loss):          \n        done = True\n    else:\n        prev_loss = new_loss\n\nNow we can visualize the resulting classifier and check the value of the loss that it achieves.\n\n\nCode\nloss = empirical_risk(X_, y, logistic_loss, w)\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = plt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\ntitle = plt.gca().set_title(f\"Loss = {loss}\")\n\n\n\n\n\nThat looks better! Note that the data is not linearly separable, but our algorithm still converged to a reasonable solution."
  },
  {
    "objectID": "lecture-notes/perceptron-demo.html",
    "href": "lecture-notes/perceptron-demo.html",
    "title": "",
    "section": "",
    "text": "© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/intro-classification.html",
    "href": "lecture-notes/intro-classification.html",
    "title": "Introduction to Classification and Auditing",
    "section": "",
    "text": "In this lecture, we’ll make our first acquaintance to the classification task. Classification is a form of supervised machine learning. Here’s the big-picture version of the supervised ML task.\nWe are given:\n\nA set of observations of predictor variables. We’ll call the \\(i\\)th such observation \\(\\mathbf{x}_i\\). We write it this way because \\(\\mathbf{x}_i\\) is usually a vector of multiple variables, often called features or covariates. We often collect these observations into a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times p}\\), where \\(n\\) is the number of observations and \\(p\\) is the total number of features.\nA set of observations of a single target variable. We’ll call the \\(i\\)th such observation \\(y_i\\). We write it this way because (at least in this course) \\(y_i\\) will always be a scalar number, rather than a vector. We can collect these observations into a (column) vector \\(\\mathbf{y} \\in \\mathbb{R}^n\\).\nWe can refer to a single observation as a pair \\((\\mathbf{x}_i, y_i)\\).\n\nBig picture, the supervised machine learning task is to use \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) to find a function \\(f:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) with the property that\n\\[\nf(\\mathbf{x}) \\approx y\n\\]\nWhat does it mean for \\[f(\\mathbf{x}) \\approx y\\]? This requires mathematical fleshing-out that we’ll do very soon.\nfor new observations \\((\\mathbf{x}, y)\\). We can think of the function \\(f\\) as an expression of the (unknown) relationship between the features \\(\\mathbf{x}\\) and the target \\(y\\). If we can find an approximation of that pattern, then we’ll have the ability to make predictions.\nWe often use \\(\\hat{y} = f(\\mathbf{x})\\) to denote the predicted value for \\(y\\) based on \\(\\mathbf{x}\\). So, we want to choose \\(f\\) so that \\(\\hat{y} \\approx y\\).\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/intro-classification.html#classification",
    "href": "lecture-notes/intro-classification.html#classification",
    "title": "Introduction to Classification and Auditing",
    "section": "Classification",
    "text": "Classification\nWe use the vector \\(\\mathbf{y}\\) to hold our observations of the target variable. We have assumed that each observation of the target variable is a real number (i.e. an element of \\(\\mathbb{R}\\)). This looks reasonable for when the thing we want to predictive is a real number (like a stock price or a probability to like a post), but what about when we want to predict a categorical label? In this case, we can simply encode labels using integers: \\(0\\) for one category, \\(1\\) for the next category, \\(2\\) for the one after that, and so on."
  },
  {
    "objectID": "lecture-notes/intro-classification.html#the-compas-recidivism-prediction-algorithm",
    "href": "lecture-notes/intro-classification.html#the-compas-recidivism-prediction-algorithm",
    "title": "Introduction to Classification and Auditing",
    "section": "The COMPAS Recidivism Prediction Algorithm",
    "text": "The COMPAS Recidivism Prediction Algorithm\nCriminal recidivism occurs when a person is convicted of a crime, completes the legal terms of their punishment, and is then convicted of another crime after release. In the American penal system, predictions of recidivism play a role in determining whether or not a defendant will be released on bail before trial or granted parole after serving a portion of a prison sentence. In other words, the belief of the court about whether a person is likely to commit a future crime can have concrete consequences for that person’s current and future freedom. Of course, it’s difficult for a human to predict whether a defendant is likely to commit a future crime. Furthermore, humans are subject to bias. Wouldn’t it be nice if we could use a machine learning algorithm to make this prediction for us?\nIn 2016, the journalism website ProPublica published an investigative story on COMPAS, a machine learning algorithm used to predict recidivism in Broward County, Florida. They obtained data for criminal defendants in Broward County in the years 2013 and 2014. These data include the COMPAS predictions, as well as demographic information (like age, gender, and race) and legal information (e.g. the crime with which the defendant was charged). The data also include an indicator of whether or not the defendant went on to be arrested of a crime within the two years following their initial trial.\nThe COMPAS algorithm actually uses information about the defendant beyond what is shown in this table; here is an example of the survey used for COMPAS to form its prediction.\n\n\n\n\n\n\nActivity\n\n\n\nHere are three concepts:\n\nDemographic data and legal information related to a defendant.\nWhether or not the defendant proceeds to be arrested for a crime within the two years following their initial trial.\nThe COMPAS algorithm.\n\nMatch these three concepts to the three mathematical symbols in the relationship\n\\[f(\\mathbf{x}) \\approx y\\].\n\n\nLet’s look at an excerpt of the data that ProPublica obtained. I have chosen only a subset of the columns and I have filtered out some of the rows as well. The hidden code saves the data in a pandas.DataFrame called df, and then views it.\nClick the little arrow to the right to view the code I used to display this table.\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\n\ndf = pd.read_csv(\"https://github.com/middlebury-csci-0451/CSCI-0451/raw/main/data/compas-scores-two-years.csv\")\n\n# filtering as in the original analysis by ProPublica\n# https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n\ndf = df[df.days_b_screening_arrest <= 30]\ndf = df[df.days_b_screening_arrest >= -30]\ndf = df[df.is_recid != -1]\ndf = df[df.c_charge_degree != \"O\"]\ndf = df[df.score_text != \"NA\"]\ndf = df[(df.race == \"African-American\") | (df.race == \"Caucasian\")]\n\ncol_list = df.columns\n\ndf[\"compas_prediction\"] = 1*(df.score_text != \"Low\")\ndf = df.reset_index()\ncols = [\"race\", \"age\", \"compas_prediction\", \"two_year_recid\"]\ndf = df[cols]\n\ndf\n\n\n\n\n\n\n  \n    \n      \n      race\n      age\n      compas_prediction\n      two_year_recid\n    \n  \n  \n    \n      0\n      African-American\n      34\n      0\n      1\n    \n    \n      1\n      African-American\n      24\n      0\n      1\n    \n    \n      2\n      Caucasian\n      41\n      1\n      1\n    \n    \n      3\n      Caucasian\n      39\n      0\n      0\n    \n    \n      4\n      Caucasian\n      27\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      5273\n      African-American\n      30\n      0\n      1\n    \n    \n      5274\n      African-American\n      20\n      1\n      0\n    \n    \n      5275\n      African-American\n      23\n      1\n      0\n    \n    \n      5276\n      African-American\n      23\n      0\n      0\n    \n    \n      5277\n      African-American\n      33\n      0\n      0\n    \n  \n\n5278 rows × 4 columns\n\n\n\nThe column compas_prediction is the COMPAS algorithm’s prediction of whether the individual will be arrested again.\n\n0 means “no:” according to COMPAS, the individual does not have an elevated risk to be arrested for a crime within the next two years.\n1 means “yes:” according to COMPAS, the individual does have an elevated risk to be arrested for a crime within the next two years.\n\nwhere 0 means The column two_year_recid records the actual outcome: 0 means “no,” the individual was not arrested within the next two years, while 1 means “yes,” the individual was arrested within the next two years.\nThere are a number of other columns that I have omitted, including the defendant name, the severity of the criminal charge, whether or not the charge is for a violent crime, presence of a prior record, sex, and other information.\n\n\n\n\n\n\nDiscussion\n\n\n\nTake some time to look at the excerpted data set and my description of it. What questions do you have when you look at the data? Try to find at least two questions about:\n\nHow the data was collected/gathered/presented by me.\nWhat patterns might be present in the data? What concerns might you have that you would want to check?"
  },
  {
    "objectID": "lecture-notes/intro-classification.html#evaluating-classification-algorithms",
    "href": "lecture-notes/intro-classification.html#evaluating-classification-algorithms",
    "title": "Introduction to Classification and Auditing",
    "section": "Evaluating Classification Algorithms",
    "text": "Evaluating Classification Algorithms\nWas COMPAS successful at making its predictions? There are lots of ways to assess this.\n\nOverall Accuracy\nOne way is the overall accuracy of the predictions: how often was it the case that the predictions were correct? The code below computes the proportion of the time that the COMPAS prediction matched reality:\n\ndf[\"accurate\"] = df[\"compas_prediction\"] == df[\"two_year_recid\"]\ndf[\"accurate\"].mean()\n\n0.6582038651004168\n\n\nIs this a good result? We can compare it to the performance of a hypothetical algorithm that simply always predicted that the individual would not reoffend.\n\n\nCode\n(1-df[\"two_year_recid\"]).mean()\n\n\n0.5295566502463054\n\n\nThis is an example of comparing against a base rate. There’s no formal definition of a base rate, but you can think of it as the performance of the best approach to the problem that doesn’t involve anything fancy. Here, the base rate is 53% and the accuracy of COMPAS is 66%, indicating that the COMPAS algorithm is significantly outperforming the base rate."
  },
  {
    "objectID": "lecture-notes/intro-classification.html#classification-rates",
    "href": "lecture-notes/intro-classification.html#classification-rates",
    "title": "Introduction to Classification and Auditing",
    "section": "Classification Rates",
    "text": "Classification Rates\nWhile accuracy is a useful metric for classification problems, it’s useful to break it down in more detailed ways. In the case of binary classification, there are four cases:\nRecall that \\(\\hat{y}\\) is just another name for \\(f(\\mathbf{x})\\), the predicted value of \\(y\\) based on \\(\\mathbf{x}\\).\n\nIf \\(y = 1\\) and \\(\\hat{y} = 1\\), we have a true positive.\nIf \\(y = 0\\) and \\(\\hat{y} = 1\\), we have a false positive.\nIf \\(y = 1\\) and \\(\\hat{y} = 0\\), we have a false negative.\nIf \\(y = 0\\) and \\(\\hat{y} = 0\\), we have a true negative.\n\nThe false positive rate is the fraction of all negative events for which the prediction is positive:\nHere \\(\\mathbb{1}\\) is the indicator function that is 1 if its arguments all evaluate to true and 0 otherwise.\n\\[\\mathrm{FPR}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\sum_{i=1}^n \\mathbb{1}(\\hat{y}_i = 1, y_i = 0)}{\\sum_{i = 1}^n \\mathbb{1}(y_i = 0)}\\]\nWe can calculate the FPR like this: numpy boolean arrays and pandas boolean columns can be multiplied to do entrywise Boolean and.\n\n\nCode\ndef FPR(y, y_hat):\n    return sum((y_hat == 1)*(y == 0))/sum(y == 0) \n\n\nOne can also define the False Negative Rate, True Positive Rate, and True Negative Rate. Let’s also do the False Negative Rate:\n\n\nCode\ndef FNR(y, y_hat):\n    return sum((y_hat == 0)*(y == 1))/sum(y == 1) \n\n\n\n\nCode\ny = df[\"two_year_recid\"]\ny_hat = df[\"compas_prediction\"]\nFPR(y, y_hat), FNR(y, y_hat)\n\n\n(0.3302325581395349, 0.35481272654047524)\n\n\nIn other words:\n\nOf people who were not arrested within two years, the COMPAS algorithm wrongly predicted that 33% of them would be arrested within two years (but correctly predicted that 67% of them would not be).\nOf people who were arrested within two years, the COMPAS algorithm wrongly predicted that 35% of them would not be arrested within two years (but correctly predicted that 65% of them would be).\n\n\n\nCode\nfor label, fun in {\"False positive rates\": FPR, \"False negative rates\" : FNR}.items():\n    print(label)\n    print(df.groupby(\"race\").apply(lambda df: fun(df[\"two_year_recid\"], df[\"compas_prediction\"])))\n    print(\"\")\n\n\nFalse positive rates\nrace\nAfrican-American    0.423382\nCaucasian           0.220141\ndtype: float64\n\nFalse negative rates\nrace\nAfrican-American    0.284768\nCaucasian           0.496350\ndtype: float64"
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html",
    "href": "lecture-notes/convex-linear-models.html",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "",
    "text": "$$\n$$\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html#quick-recap",
    "href": "lecture-notes/convex-linear-models.html#quick-recap",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "Quick Recap",
    "text": "Quick Recap\nLast time, we studied the perceptron algorithm for binary classification using hyperplanes. In doing so, we introduced the loss of a hyperplane, which we defined as the number of misclassifications made by the classifier based on that hyperplane.\nWe also saw that the perceptron has some major challenges associated with it. In this lecture, we’re going to extend the idea of loss to cover a broader range of models. Within this theory, we’ll be able to understand where some of the perceptron’s problems come from, and what to do about them.\nRecall that our setup for the perceptron was as follows. We have data, a pair \\((\\mathbf{X}, \\mathbf{y})\\) where\n\n\\(\\mathbf{X}\\in \\mathbb{R}^{n\\times p}\\) is the feature matrix. There are \\(n\\) distinct observations, encoded as rows. Each of the \\(p\\) columns corresponds to a feature: something about each observation that we can measure or infer. Each observation is written \\(\\mathbf{x}_1, \\mathbf{x}_2,\\ldots\\).\n\n\\[\n\\mathbf{X}= \\left[\\begin{matrix} & - & \\mathbf{x}_1 & - \\\\\n& - & \\mathbf{x}_2 & - \\\\\n& \\vdots & \\vdots & \\vdots \\\\\n& - & \\mathbf{x}_{n} & - \\end{matrix}\\right]\n\\]\n\n\\(\\mathbf{y}\\in \\mathbb{R}^{n}\\) is the target vector. The target vector gives a label, value, or outcome for each observation.\n\nIn the perceptron, we assumed that \\(\\mathbf{y}\\in \\{-1, 1\\}^n\\). We also assumed that we are going to try to linearly classify the points by finding a pair \\((\\mathbf{w}, b)\\) that define a hyperplane. This is the set of points \\(\\mathbf{x}\\in \\mathbb{R}^n\\) that satisfy the equation\n\\[\n\\langle \\mathbf{w}, \\mathbf{x} \\rangle - b = 0\\;.\n\\]\nWe saw that if we redefined \\(\\tilde{\\mathbf{x}} = (\\mathbf{x}, 1)\\) and \\(\\tilde{\\mathbf{w}} = (\\mathbf{w}, -b)\\), we could simply write this as\n\\[\n\\langle \\tilde{\\mathbf{w}}, \\tilde{\\mathbf{x}} \\rangle = 0\\;\n\\]\ninstead. For the remainder of these notes, we’ll simply write our feature vectors as \\(\\mathbf{x}\\) and our parameter vector as \\(\\mathbf{w}\\), assuming that the final entry of \\(\\mathbf{x}\\) is also a 1.\n\nFor a given point \\(\\mathbf{x}\\), we can make a prediction \\(\\hat{y} = \\langle \\mathbf{w}, \\mathbf{x} \\rangle\\).\nWe decide that a prediction is accurate (and give ourself one “point”) if \\(\\hat{y}\\) has the same sign as \\(y\\). This can be expressed in either of the following equivalent ways:\n\n\\(\\mathbb{1}\\left[ \\mathrm{sign}(\\hat{y}) = y \\right]\\)\n\\(\\mathbb{1}\\left[ \\hat{y}y > 0 \\right]\\)\n\nThe overall accuracy or score is the accuracy rate averaged across the entire data set. We also defined the overall loss to be one minus the accuracy:\n\n\\[\n\\begin{aligned}\nA(\\mathbf{w}) &= \\frac{1}{n}\\sum_{i = 1}^n \\mathbb{1}\\left[ \\hat{y}_iy_i > 0 \\right]\\\\\n          &= \\frac{1}{n}\\sum_{i = 1}^n \\mathbb{1}\\left[ (\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle)y_i > 0 \\right] \\\\\nL(\\mathbf{w}) &= 1 - A(\\mathbf{w}) \\\\\n          &= \\frac{1}{n}\\sum_{i = 1}^n \\left(1 - \\mathbb{1}\\left[ \\hat{y}_iy_i > 0 \\right]\\right) \\\\\n          &= \\frac{1}{n}\\sum_{i = 1}^n \\left(1- \\mathbb{1}\\left[ (\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle)y_i > 0 \\right]\\right)\\;.\n\\end{aligned}\n\\]\nWe’d like to find \\(\\mathbf{w}\\) to minimize the loss function. That is, we’d like to solve the problem\n\\[\n\\hat{\\mathbf{w}} = \\mathop{\\mathrm{arg\\,min}}_{\\mathbf{w}} \\; L(\\mathbf{w})\n\\tag{1}\\]\nThe loss is also often called the empirical risk, and this minimization problem is often called empirical risk minimization, for reasons that we’ll discuss in a coming lecture. The perceptron algorithm was one way to attack the empirical risk minimization problem."
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html#some-questions-for-empirical-risk-minimization",
    "href": "lecture-notes/convex-linear-models.html#some-questions-for-empirical-risk-minimization",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "Some Questions For Empirical Risk Minimization",
    "text": "Some Questions For Empirical Risk Minimization\nIt is at this point that we need to ask some important questions with awkward answers.\n\nExistence: Does Equation 1 have any solutions?\nUniqueness: Assuming there exists a solution to Equation 1, is it unique? Or are there many different solutions?\nSearchability: Is it possible to write algorithms are guaranteed to find a solution of Equation 1?\nPerformance: Is it possible to make these algorithms fast?\n\nIn most prediction problems, what we’d really like is to be right about the true value of \\(y\\). In the context of linear classifiers, this means that we want all the points of one label to be on one side of the line, and all the points of the other label to be on the other side. The loss function that expresses this idea is the 0-1 loss function, which is, again, the loss function used in the perceptron algorithm:\n\\[\n\\ell(\\hat{y}, y) = 1 - \\mathbb{1}\\left[ \\hat{y}y > 0 \\right]\\;.\n\\]\nWhen we graph the 0-1 loss function, it looks like this. I’ve shown versions corresponding to both values of the true label, \\(y = 1\\) and \\(y = -1\\).\n\n\nCode\nfrom matplotlib import pyplot as plt \nimport numpy as np\n\nplt.rcParams[\"figure.figsize\"] = (10, 4)\n\nfig, axarr = plt.subplots(1, 2) \ny_hat = np.linspace(-1, 1, 101)\n\nloss = lambda y_hat, y: 1 - 1*(y_hat*y > 0)\n\nfor j in range(2):\n    y = [-1, 1][j]\n    axarr[j].set_title(f\"y = {y}\")\n    axarr[j].set(xlabel = r\"$\\hat{y}$\", \n                 ylabel = r\"$\\ell(\\hat{y}, y)$\")\n    \n    axarr[j].plot(y_hat, loss(y_hat, y))\n\nplt.tight_layout()\n\n\n\n\n\nLet’s now ask our four questions about empirical risk minimization for the 0-1 loss function.\nExistence: Does Equation 1 have any solutions?\n\nWe are good on this one! Specifically, the risk can take on only a finite number of possible values (values between 0 and 1 in increments of \\(1/n\\)). In any given problem there is a smallest such value obtained, and this is a solution.\n\nUniqueness: Assuming there exists a solution to Equation 1, is it unique? Or are there many different solutions?\nTo define “usually” and “just a little bit” rigorously, we need to specify a data generating distribution and do some math.\n\nUnfortunately, the solution to Equation 1 for the 0-1 loss is almost never unique. This is because, if you have one solution \\(\\mathbf{w}\\), you can “usually” jiggle it by “just a little bit” and still have a minimizing solution.\n\nSearchability: Is it possible to write algorithms are guaranteed to find a solution of Equation 1?\n\nTechnically, we could just try a very large number of choices of \\(\\mathbf{w}\\) and hope for the best, but that’s not very efficient (in fact, the problem of getting a reasonable answer this way is exponential in \\(d\\), the number of features). Can we do better?\n\nPerformance: Is it possible to make these algorithms fast?\n\nThis is where our real problem lies:\n\n\n\n\n\n\n\n\nTheorem 1 (0-1 Minimization for Linear Classifiers is NP Hard (Kearns, Schapire, and Sellie (1994))) \nUnless P = NP, there is no polynomial-time algorithm that can solve the 0-1 empirical risk minimization problem for linear classifiers.\n\n\n\n\nSo, if we are going to have reasonable algorithms for empirical risk minimization, we need to choose a different loss function. There are multiple choices. Before we jump into examples, we’re going to define the core mathematical concept that is going to help address our core questions of existence, uniqueness, searchability, and performance."
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html#convexity",
    "href": "lecture-notes/convex-linear-models.html#convexity",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "Convexity",
    "text": "Convexity\n\n\n\n\n\n\n\nDefinition 1 \nA set \\(S \\subseteq \\mathbb{R}^n\\) is convex if, for any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\) and for any \\(\\lambda \\in [0,1]\\), the point \\(\\mathbf{z}= \\lambda \\mathbf{z}_1 + (1-\\lambda) \\mathbf{z}_2\\) is also an element of \\(S\\).\n\n\n\n\n\n\n\n\n\n\n\nDefinition 2 (Convex Functions) Let \\(S \\subseteq \\mathbb{R}^n\\) be convex. A function \\(f:S \\rightarrow \\mathbb{R}\\) is convex if, for any \\(\\lambda \\in \\mathbb{R}\\) and any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\), we have\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) \\leq \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\nThe function \\(f\\) is strictly convex if the inequality is strict: for all \\(\\lambda\\), \\(\\mathbf{z}_1\\), and \\(\\mathbf{z}_2\\),\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) < \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\n\n\n\n\nRoughly, a convex function is “bowl-shaped.”\n\n\n\n\n\n\n\nDefinition 3 (Local and Global Minimizers) A point \\(\\mathbf{z}\\in S\\) is a global minimizer of the function \\(f:S \\rightarrow \\mathbb{R}\\) if \\(f(\\mathbf{z}) \\leq f(\\mathbf{z}')\\) for all \\(\\mathbf{z}' \\in S\\).\nA point \\(\\mathbf{z}\\in S\\) is a local minimizer of \\(f:S \\rightarrow \\mathbb{R}\\) if there exists a neighborhood \\(T \\subseteq S\\) containing \\(\\mathbf{z}\\) such that \\(\\mathbf{z}\\) is a global minimizer of \\(f\\) on \\(T\\).\n\n\n\n\nIt’s ok if you don’t know what it means for a set to be closed – all the convex functions we will care about in this class will either be defined on sets where this theorem holds or will be otherwise defined so that the conclusions apply.\n\n\n\n\n\n\n\nTheorem 2 Let \\(f:S \\rightarrow \\mathbb{R}\\) be a convex function. Then:\n\nIf \\(S\\) is closed and bounded, \\(f\\) has a minimizer \\(\\mathbf{z}^*\\) in \\(S\\).\nFurthermore, if \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), then it is also a global minimizer.\nIf in addition \\(f\\) is strictly convex, then this minimizer is unique.\n\n\n\n\n\n\nProof. The proof of item 1 needs some tools from real analysis. The short version is:\n\nEvery convex function is continuous.\nIf \\(S\\subseteq \\mathbb{R}^n\\) is closed and bounded, then it is compact.\nContinuous functions achieve minimizers and maximizers on compact sets.\n\nIt’s ok if you didn’t follow this! Fortunately the second part of the proof is one we can do together. Suppose to contradiction that \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), but that there is also a point \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') < f(\\mathbf{z}^*)\\). Since \\(\\mathbf{z}^*\\) is a local minimizer, we can find some neighborhood \\(T\\) containing \\(\\mathbf{z}^*\\) such that \\(\\mathbf{z}^*\\) is a minimizer of \\(f\\) on \\(T\\). Let \\(\\lambda\\) be some very small number and consider the point \\(\\mathbf{z}= \\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*\\). Specifically, choose \\(\\lambda\\) small enough so that \\(\\mathbf{z}\\in T\\) (since this makes \\(\\mathbf{z}\\) close to \\(\\mathbf{z}^*\\)). We can evaluate\n\\[\n\\begin{align}\nf(\\mathbf{z}) &= f(\\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*) \\tag{definition of $\\mathbf{z}$}\\\\\n       &\\leq \\lambda f(\\mathbf{z}') + (1-\\lambda)f(\\mathbf{z}^*)  \\tag{$f$ is convex} \\\\\n       &= f(\\mathbf{z}^*) + \\lambda (f(\\mathbf{z}') - f(\\mathbf{z}^*)) \\tag{algebra}\\\\\n       &< f(\\mathbf{z}^*)\\;. \\tag{assumption that $f(\\mathbf{z}') < f(\\mathbf{z}^*)$}\n\\end{align}\n\\]\nBut this is a contradiction, since we constructed \\(\\mathbf{z}\\) to be in the neighborhood \\(T\\) where \\(\\mathbf{z}^*\\) is a local minimizer. We conclude that there is no \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') < f(\\mathbf{z}^*)\\), and therefore that \\(\\mathbf{z}^*\\) is a global minimizer.\nThe proof of the third part follows a very similar argument to the proof of the second part!\n\nThere’s two other very important math facts that we need in order to apply convexity to the empirical risk minimization problem for linear models.\nBy induction, it follows that any linear combination of convex functions with positive coefficients is convex.\n\n\n\n\n\n\n\nTheorem 3 \n\nLet \\(f_1\\) and \\(f_2\\) be convex functions with the same domain, and let \\(a\\) and \\(b\\) be nonnegative real numbers. Then, the function \\(f\\) defined by \\(f(\\mathbf{z}) = af_1(\\mathbf{z}) + bf_2(\\mathbf{z})\\) is also convex.\nLet \\(f:\\mathbb{R}^n\\rightarrow \\mathbb{R}\\) be convex. Let \\(\\mathbf{A}\\in \\mathbb{R}^{n\\times p}\\) and \\(\\mathbf{b} \\in \\mathbb{R}^n\\). Then, the function \\(f_\\mathbf{A}\\) defined by \\(f_{\\mathbf{A},\\mathbf{b}}(\\mathbf{z}) = f(\\mathbf{A}\\mathbf{z}- \\mathbf{b})\\) is convex."
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html#convexity-and-empirical-risk-minimization",
    "href": "lecture-notes/convex-linear-models.html#convexity-and-empirical-risk-minimization",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "Convexity and Empirical Risk Minimization",
    "text": "Convexity and Empirical Risk Minimization\nLet’s finally go back to the empirical risk minimization problem for linear models. We’re going to write it in terms of a general loss function \\(\\ell\\); the choice \\(\\ell(\\hat{y}, y) = 1 - \\mathbb{1}\\left[ \\hat{y}y > 0 \\right]\\) gets us back to the 0-1 loss situation. The general empirical risk minimization problem for linear classifiers is\n\\[\n\\hat{\\mathbf{w}} = \\mathop{\\mathrm{arg\\,min}}_{\\mathbf{w}} \\frac{1}{n} \\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle, y_i)\\;.\n\\tag{2}\\]\nLet’s now assume that the loss function \\(\\ell\\) is strictly convex in its first argument: that is, for any possible value of \\(y\\) and any \\(\\lambda \\in [0,1]\\),\n\\[\n\\ell(\\lambda \\hat{y}_1 + (1-\\lambda)\\hat{y}, y) \\leq  \\lambda \\ell(\\hat{y}_1, y) + (1-\\lambda)\\ell(\\hat{y}, y)\\;.\n\\]\nThen, suddenly the following things would all also be true:\n\n\\(\\ell(\\langle \\mathbf{w}, \\mathbf{x} \\rangle, y)\\) is strictly convex as a function of \\(\\mathbf{w}\\) (Theorem 3, part 2).\nThe empirical risk \\(L(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle, y_i)\\) is strictly convex as a function of \\(\\mathbf{w}\\) (Theorem 3, part 1).\nIf the empirical risk \\(R(\\mathbf{w})\\) has a global minimizer, that global minimizer is unique (Theorem 2, part 3).\nThe empirical risk \\(R(\\mathbf{w})\\) has no local minimizers which are not global minimizers.\n\nThese facts have important implications for our fundamental questions on empirical risk minimization.\nExistence. Even convex functions are not guaranteed to have minimizers. However, there are lots of choices of loss function \\(\\ell\\) which do guarantee that the empirical risk has a minimizer.\nUniqueness: When the empirical risk is strictly convex, there can only be one global minimizer.\nSearchability: When the empirical risk is strictly convex, there are also no local minimizers other than the global minimizer. Algorithmically, this is the most important property of convexity. It means that if I manage to find any local minimizer at all, that point must be the global minimizer.\n Performance: Convexity significantly reduces the difficulty of our task: instead of trying to find “the best” solution, it’s sufficient for us to find any local optimum. This means that we can design our algorithms to be “greedy local minimizer hunters.” There are lots of fast algorithms to do this. An especially important class of algorithms are gradient descent methods, which we’ll discuss soon.If you’ve taken an algorithms class, one way of thinking of convexity is that it guarantees that greedy methods work for solving minimization problems."
  },
  {
    "objectID": "lecture-notes/convex-linear-models.html#demo-logistic-regression",
    "href": "lecture-notes/convex-linear-models.html#demo-logistic-regression",
    "title": "Convex Linear Models and Logistic Regression",
    "section": "Demo: Logistic Regression",
    "text": "Demo: Logistic Regression\nLet’s do a partial implementation of logistic regression to illustrate these techniques. In logistic regression, we assume that \\(y \\in \\{0,1\\}\\). Our loss function is the logistic loss:\n\\[\n\\ell(\\hat{y}, y) = -y \\log \\sigma(\\hat{y}) - (1-y)\\log (1-\\sigma(\\hat{y}))\\;,\n\\]\nwhere \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\) is the logistic sigmoid function.\nThe logistic loss is convex in \\(\\hat{y}\\), although proving this requires a little bit of extra math that we won’t discuss. Here’s a “proof by picture” for the case when the label is \\(y = 1\\).\n\n\nCode\nz = np.linspace(0, 5, 101)\nplt.plot(z, -np.log(1/(1 + np.exp(-z)))) \nlabs = plt.gca().set(xlabel = r\"$\\hat{y}$\", ylabel = r\"$-\\log \\sigma(\\hat{y})$\")\n\n\n\n\n\nBecause the logistic loss is convex in \\(\\hat{y}\\), the empirical risk minimization problem can have at most one minimum. In fact, it’s possible to show, if the data is not linearly separable, there exists a global minimum.\nHere is some sample data for which we will try to find a good linear classifier.\n\n\nCode\nfrom sklearn.datasets import make_blobs\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nNote that this data is not linearly separable. The perceptron algorithm wouldn’t even have converged for this data set, but logistic regression will do great.\n\n\n\n\nNow let’s do an implementation. First let’s define a linear predictor function of the form \\(f(\\mathbf{x}) = \\langle w, \\mathbf{x} \\rangle\\). Note that this predictor makes the predictions on all the training data at once!\n\nimport numpy as np \nfrom scipy.optimize import minimize\n\n# logistic regression tends to involve a lot of log(0) and things that wash out in the end. \nnp.seterr(all='ignore') \n\n# add a constant feature to the feature matrix\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\ndef predict(X, w):\n    return X@w\n\nNow we’ll define some functions to compute the empirical risk:\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n# returns a vector containing the per-observation logistic loss for each observation\ndef logistic_loss(y_hat, y): \n    return -y * np.log(sigmoid(y_hat)) - (1 - y)*np.log(1 - sigmoid(y_hat))\n\n# first compute the predictions, then compute the average loss per observation\n# note that this works on the ENTIRE DATA SET AT ONCE: no for-loops\ndef empirical_risk(X, y, w, loss):\n    y_hat = predict(X, w)\n    return loss(y_hat, y).mean()\n\nFinally, we can write the function that will solve the empirical risk minimization problem for us. We’re going to use the scipy.optimize.minimize function, which is a built-in function for solving minimization problems. Soon, we’ll study how to solve minimization problems from scratch.\nThe scipy.optimize.minimize function requires us to pass it a single function that accepts a vector of parameters, plus an initial guess for the parameters.\n\ndef find_pars(X, y):\n    \n    p = X.shape[1]\n    w0 = np.random.rand(p) # random initial guess\n    \n    # perform the minimization\n    result = minimize(lambda w: empirical_risk(X, y, w, logistic_loss), \n                      x0 = w0) \n    \n    # return the parameters\n    return result.x\n\nOk, let’s try it and take a look at the parameters we obtained. Because the final column of X_ is the constant column of 1s, the final entry of w is interpretable as the intercept term b.\n\nw = find_pars(X_, y)\nw\n\narray([2.33621929, 1.83628124, 0.37074447])\n\n\nAnd, finally, we can plot the linear classifier that we learned.\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\n\nplt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\n\n\n\nSince the logistic loss is convex, we are guaranteed that this solution is the unique best solution (as measured by the logistic loss). There is no other possible set of parameters that would lead to a better result (again, as measured by the logistic loss)."
  },
  {
    "objectID": "lecture-notes/perceptron.html",
    "href": "lecture-notes/perceptron.html",
    "title": "Introduction to Classification: The Perceptron",
    "section": "",
    "text": "\\[\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\vx}{\\mathbf{x}}\n\\newcommand{\\vy}{\\mathbf{y}}\n\\newcommand{\\mX}{\\mathbf{X}}\n\\newcommand{\\vw}{\\mathbf{w}}\n\\newcommand{\\bracket}[1]{\\langle #1 \\rangle}\n\\newcommand{\\paren}[1]{\\left( #1 \\right)}\n\\newcommand{\\one}[1]{\\mathbb{1}\\left[ #1 \\right]}\n\\newcommand{\\cL}{\\mathcal{L}}\n\\newcommand{\\norm}[1]{\\lVert #1 \\rVert}\n\\]\nIn this lecture, we’ll study one of the oldest machine learning algorithms: the perceptron. Invented in 1943 but not actually implemented in hardware until 1958, the perceptron is still relevant today as a fundamental building-block of modern deep neural networks. Indeed, one of the implementations of neural networks in scikit-learn is still called the “multilayer perceptron.”\nWhen first announced, the perceptron algorithm also displayed one of the first examples of AI Hype®. The New York Times uncritically repeated claims by a Navy rep that the perceptron algorithm would be the “embryo” of a computer that would “walk, talk, see, write, reproduce itself, and be conscious of its existence.” As we study and implement the perceptron, you may wish to reflect on what you are doing and decide for yourself whether you believe that you are building the “embryo” of any such capabilities yourself.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/perceptron.html#illustration",
    "href": "lecture-notes/perceptron.html#illustration",
    "title": "Introduction to Classification: The Perceptron",
    "section": "Illustration",
    "text": "Illustration\nNow let’s go ahead and run the perceptron algorithm on some data. First we should set up our feature matrix \\(\\mX\\) and target vector \\(\\vy\\).\n\n\nCode\nX = np.append(np.column_stack((X1, X2)), np.column_stack((X3, X4)), axis = 0) # feature matrix\ny = 2*(np.arange(0, 200) >= 100) - 1 # target vector\n\n\nHere are the first few rows of the feature matrix:\n\n\nCode\nX[0:5, :]\n\n\narray([[-1.0856306 ,  0.64205469],\n       [ 0.99734545, -1.97788793],\n       [ 0.2829785 ,  0.71226464],\n       [-1.50629471,  2.59830393],\n       [-0.57860025, -0.02462598]])\n\n\nAnd here are the corresponding values of the target vector:\n\n\nCode\ny[0:5]\n\n\narray([-1, -1, -1, -1, -1])\n\n\n\n\nCode\nnp.random.seed(123456)\nw = np.random.rand(3)\n\nplt.rcParams[\"figure.figsize\"] = (8, 4)\nfig, axarr = plt.subplots(2, 5, sharex = True, sharey = True)\nfor ax in axarr.ravel():\n    ax.set(xlim = (-5, 5), ylim = (-5, 5))\n    plot_scatter(X1, X2, X3, X4, ax, legend = False)\n    draw_line(w, -10, 10, ax, color = \"black\", linestyle = \"dashed\")\n    w, i, loss = perceptron_update(X, y, w)    \n    ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\")\n    draw_line(w, -10, 10, ax, color = \"black\")\n    ax.set_title(f\"loss = {loss}\")\n    \nplt.tight_layout()\n\n\n\n\n\nFigure 3: Several iterations of the perceptron algorithm. In each panel, the dashed line is the hyperplane corresponding to the previous weight vector \\(\\vw^{(t)}\\), while the solid line is the hyperplane for the updated weight vector \\(\\vw^{t+1}\\). The empty circle is the point \\(i\\) used in the update; only iterations in which \\(i\\) was a mistake are shown, with the exception of the final two iterations (by which the algorithm has converged). The loss is computed as in Equation 4. (The perceptron update itself takes place using a function called perceptron_update whose implementation I have intentionally hidden – you’ll implement a version yourself in a blog post!)"
  },
  {
    "objectID": "lecture-notes/perceptron.html#convergence-of-the-perceptron-algorithm",
    "href": "lecture-notes/perceptron.html#convergence-of-the-perceptron-algorithm",
    "title": "Introduction to Classification: The Perceptron",
    "section": "Convergence of the Perceptron Algorithm",
    "text": "Convergence of the Perceptron Algorithm\nIs the perceptron algorithm guaranteed to terminate? And if so, is it guaranteed to find a weight vector \\(\\tilde{\\vw}\\) that perfectly separates the two data classes?\n\n\n\n\n\n\n\nDefinition 1 (Linear Separability) A data set with feature matrix \\(\\mX \\in \\R^{n\\times k}\\) and target vector \\(y\\in \\{0, 1\\}\\) is linearly separable if there exists a weight vector \\(\\tilde{\\vw}\\) such that, for all \\(i \\in [n]\\),\n\\[\n\\bracket{\\tilde{\\vw}, \\tilde{\\vx}_i} > 0 \\Leftrightarrow y = 1\\;.\n\\]\n\n\n\n\nTake a moment to convince yourself of the following:\n\n\n\n\n\n\n\nProposition 1 (Nonconvergence of perceptron for nonseparable data) \nSuppose that \\((\\mX, \\vy)\\) is not linearly separable. Then, the perceptron update does not converge. Furthermore, at no iteration of the algorithm is it the case that \\(\\cL(\\tilde{\\vw}) = 0\\).\n\n\n\n\nIt’s not as obvious that, if the data is linearly separable, then the perceptron algorithm will converge to a correct answer. Perhaps surprisingly, this is also true:\n\n\n\n\n\n\n\nTheorem 1 (Convergence of perceptron for separable data) Suppose that \\((\\mX, \\vy)\\) is linearly separable. Then:\n\nThe perceptron algorithm converges in a finite number of iterations to a vector \\(\\tilde{\\vw}\\) that separates the data.\n\nDuring the running of the perceptron algorithm, the total number of updates made is no more than\n\n\\[\\frac{2 + r(\\mX)^2}{\\gamma(\\mX, \\vy)}\\;,\\]\nwhere \\(r(\\mX) = \\max_{i \\in [n]} \\norm{\\vx_i}\\) and \\(\\gamma(\\mX, \\vy)\\) is a geometric measure called the margin of how far apart the two label classes are.\n\n\n\n\nFor a proof of Theorem 1, see p. 37-44 of Hardt and Recht (2021)."
  },
  {
    "objectID": "lecture-notes/perceptron.html#close-out-activity",
    "href": "lecture-notes/perceptron.html#close-out-activity",
    "title": "Introduction to Classification: The Perceptron",
    "section": "Close-out Activity",
    "text": "Close-out Activity\n\n\n\n\n\n\nStart Implementing the Perceptron Algorithm\n\n\n\nSuppose that you have a numpy.Array X of features and an np.Array y of binary labels. Assume that X does NOT contain a column of 1s; that is, it corresponds to \\(\\mX\\) rather than \\(\\tilde{\\mX}\\) from the notes above. Additionally, Assume that the labels in y are 0s and 1s rather than -1s and 1s. This is not the mathematically convenient setup, but is the one that is most frequently seen in machine learning software.\nAt the board, write as much code as you can to achieve some of the following tasks. Please work with a partner. It’s ok to pick and choose which of these to try; but you should work together (i.e. in conversation) rather than in parallel.\n\nDetermine n (the number of data points) and p (the number of features) from X.\nModify X into X_ (which contains a column of 1s and corresponds to \\(\\tilde{\\mX}\\)). This one I’ll give you for free:\n\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\nModify y into an array y_ of -1s and 1s, corresponding to the version we use in the notes above.\nInitialize a random weight vector w_ with appropriate dimensions, corresponding to \\(\\tilde{\\vw}^{(0)}\\).\nGenerate a random index i between 0 and n-1.\nExtract the ith row of X_, which corresponds to \\(\\tilde{\\vx}_i\\).\n\nCompute \\(\\ell_i^{(0)} = \\bracket{\\tilde{\\vw}^{(0)}, \\tilde{\\vx}_i}\\).\n\nThese items will give you a head start on the blog post in which you will construct a full implementation of the perceptron algorithm."
  },
  {
    "objectID": "lecture-notes/erm.html",
    "href": "lecture-notes/erm.html",
    "title": "Models, Algorithms, and Learning",
    "section": "",
    "text": "$$\n$$\nIn this lecture, we are going to develop our core theoretical framework for supervised prediction. Supervised means that we are trying to predict something for which there is, or could be, a “ground-truth answer.” Some examples of supervised tasks are:\nIn each of these cases, you could find out whether your prediction was right or wrong just by waiting and checking. Did you predict that a person is likely to commit a crime within the next few years? Wait two years and find out whether you were right.\nIn contrast, unsupervised algorithms generate output for which there is no firm right answer. Unsupervised machine learning tasks aim to do things like “find patterns” or “generate realistic examples.” Large language models (LLMs) like ChatGPT are perhaps the most prominent examples of unsupervised models these days.\nBig picture, the goal of supervised learning is to find a function that takes in some features and uses them to make a prediction that is usually right. Heuristically, we’re looking for a function \\(f\\) that accepts some features \\(x_1,\\ldots,x_p\\) and gives a prediction \\(\\hat{y}\\) that is “close” to the real answer \\(y\\):\n\\[\nf(x_1,\\ldots,x_p) = \\hat{y} \\approx y\\;.\n\\]\nWhat does “\\(\\approx\\)” actually mean in this context? Briefly, we mean that \\(\\hat{y}\\) is usually “close” to \\(y\\) when measured in a certain way.\nThe goal of supervised learning is to “train” a “model” that will make “good” “predictions” on “data.” We need to cash out each of these terms.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "lecture-notes/erm.html#data-generating-distributions",
    "href": "lecture-notes/erm.html#data-generating-distributions",
    "title": "Models, Algorithms, and Learning",
    "section": "Data Generating Distributions",
    "text": "Data Generating Distributions\nIntuitively, a data generating distribution is an expression of our expectations of what the world looks like. For example, let’s suppose we are trying to predict whether someone enjoys skiing. So, we do a survey in which we ask two questions:\n\nOn a scale from 1 to 10, how much do you enjoy being outdoors in cold weather?\nDo you enjoy skiing? (yes/no)\n\nHere, we have a single feature \\(x\\in [10]\\) and a binary outcome \\(y \\in \\{0,1\\}\\). We might imagine that when \\(x\\) is larger, it is more likely for \\(y\\) to be equal to 1. Here’s a probabilistic model that expresses this idea:\n\\[\n\\begin{align}\n    \\mathbb{P}\\left[X = x\\right] &= 1/10 \\quad \\forall x \\in [10] \\\\\n    \\mathbb{P}\\left[Y = 1 | X\\right] &= \\frac{x}{11}\\;.\n\\end{align}\n\\]\nThis probabilistic model is an example of a data generating distribution. The reason it’s called this is that you could “generate” a data point from it: first pick a random value of \\(x\\) uniformly between 1 and 10. Then, to generate \\(y\\), flip a weighted coin with probability of heads equal to \\(x/11\\).\nHere’s some “data” sampled from this probabilistic model:\n\n\nCode\nimport numpy as np \nfrom matplotlib import pyplot as plt \n\nn = 100\nx = np.random.randint(1, 11, n)\ny = np.random.rand(n) < x/11\n\n\nf = plt.scatter(x, y + 0.2*np.random.rand(n) - 0.1, alpha = 0.5)\nl = plt.xlabel(\"Enjoys cold weather\") \nl = plt.ylabel(\"Enjoys skiing\")\n\n\n\n\n\nFigure 1: Data sampled from the probabilistic model of enjoyment of skiing based on enjoyment of cold weather. The vertical axis has been jittered so for legibility.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 2 (Data Generating Distribution) An observation generating distribution is a probability distribution describing the likelihood of a single observation \\((\\mathbf{x}, y)\\). We’ll usually call this distribution \\(p_\\mathcal{D}\\), so that the likelihood of realizing the pair \\((\\mathbf{x}, y)\\) is \\(p_\\mathcal{D}(\\mathbf{x}, y)\\).\nA data generating distribution is a probability distribution describing the likelihood of a feature matrix-target vector pair \\((\\mathbf{X}, \\mathbf{y})\\) with \\(n\\) observations. In this class we’ll always assume that the observations are independent and identically distributed (i.i.d.) according to \\(p_\\mathcal{D}\\), and so the data generating distribution can be written\n\\[\nP_\\mathcal{D}(\\mathbf{X}, \\mathbf{y}) = \\prod_{i = 1}^n p_\\mathcal{D}(\\mathbf{x}_i, y_i)\\;.\n\\]\n\n\n\n\nIf we knew the data distribution, then it would be easy to make good predictions. In the supervised learning framework, we don’t usually assume that we know the probability model, but we do usually assume that there is one. Our job is to help our models find the patterns encoded in the data generating distribution.\nRecall that in the case of the perceptron, we assumed that we were dealing with linearly separable data like the ones shown below:\n\n\nCode\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom hidden.perceptron import perceptron_update, draw_line\n\nnp.random.seed(123)\n\nplt.rcParams[\"figure.figsize\"] = (4, 4)\n\nX1 = np.random.normal(0, 1, 100)\nX2 = np.random.normal(0, 1, 100)\n\nX3 = np.random.normal(0, 1, 100)*.5+3\nX4 = np.random.normal(0, 1, 100)*.5+3\n\nfig, ax = plt.subplots(1, 1)\n\ndef plot_scatter(X1, X2, X3, X4, ax, legend = True):\n    \n    s = ax.scatter(X1, X2, color = \"#ED90A4\", alpha = 0.5, label = r\"$y_i = -1$\")\n    s = ax.scatter(X3, X4, color = \"#00C1B2\", alpha = 0.5, label = r\"$y_i = 1$\")\n    l = ax.set(xlabel = r\"$x_{i1}$\")\n    l = ax.set(ylabel = \"$x_{i2}$\")\n    if legend:\n        l = ax.legend()\n    \nplot_scatter(X1, X2, X3, X4, ax)\n\n\n\n\n\nFigure 2: 200 data points in the 2d plane, each of which has one of two labels.\n\n\n\n\n\n\n\n\n\n\nActivity 1\n\n\n\nCan you write down some ideas for an observation generating distribution that would generate data that looks like this? Feel free to use a weight vector \\(\\mathbf{w}\\), a bias \\(b\\), and anything else you might need."
  },
  {
    "objectID": "lecture-notes/erm.html#empirical-risk-minimization",
    "href": "lecture-notes/erm.html#empirical-risk-minimization",
    "title": "Models, Algorithms, and Learning",
    "section": "Empirical Risk Minimization",
    "text": "Empirical Risk Minimization\nWe are now prepared to formulate a fundamental paradigm for prediction problems in machine learning.\n\n\n\n\n\n\n\nDefinition 8 (Empirical Risk Minimization) An empirical risk minimization problem involves:\n\nA choice of model family \\(\\mathcal{M} = \\{f_{\\boldsymbol{\\theta}}\\}\\).\nA choice of loss function \\(\\ell: \\mathbb{R}\\times \\mathbb{R}\\rightarrow \\mathbb{R}\\).\n\nA data set \\((\\mathbf{X}, \\mathbf{y})\\).\n\nThe empirical risk problem is then to find the parameter vector \\(\\boldsymbol{\\theta}\\) (which corresponds to a choice of model) that minimizes the empirical risk:\n\\[\n\\begin{align}\n\\hat{\\boldsymbol{\\theta}} &= \\mathop{\\mathrm{arg\\,min}}_{\\boldsymbol{\\theta}} \\; \\hat{R}(f_\\boldsymbol{\\theta})  \\\\\n&= \\mathop{\\mathrm{arg\\,min}}_{\\boldsymbol{\\theta}} \\; \\frac{1}{n} \\sum_{i = 1}^n \\ell(f_\\boldsymbol{\\theta}(\\mathbf{x}_i), y_i)\\;.\n\\end{align}\n\\]\n\n\n\n\nA large number of classification and regression algorithms that we study in this course are instances of empirical risk minimization."
  },
  {
    "objectID": "lecture-notes/erm.html#back-to-perceptron",
    "href": "lecture-notes/erm.html#back-to-perceptron",
    "title": "Models, Algorithms, and Learning",
    "section": "Back to Perceptron",
    "text": "Back to Perceptron\nWe are now able to situate the perceptron algorithm within the framework of empirical risk minimization:\n\nThe model family \\(\\mathcal{M}\\) is the set of all functions of the form \\(f_{\\mathbf{w}, b}(\\mathbf{x}) = \\langle \\mathbf{w}, \\mathbf{x} \\rangle - b\\). We can take the parameter vector to be \\(\\boldsymbol{\\theta} = (\\mathbf{w}, b)\\).\nThe per-observation loss function used is the so-called 0-1 loss function given by\n\n\\[\n\\ell(\\hat{y}, y) = 1 - \\mathbb{1}\\left[ \\hat{y}y > 0 \\right]\\;.\n\\]\n\nThe empirical risk is\n\n\\[\n\\hat{R}(f_{\\mathbf{w}, b}) = \\frac{1}{n} \\sum_{i = 1}^n \\ell(\\hat{y}_i,y_i) = \\sum_{i= 1}^n \\left[1 - \\mathbb{1}\\left[ \\hat{y}_iy_i > 0 \\right]\\right]\\;.\n\\]\n\nThe perceptron algorithm attempts to find a pair \\((\\mathbf{w}, b)\\) that reduces the empirical risk by updating the parameters using one data point at a time.\nThe perceptron convergence theorem for separable data says that if there exists a pair \\((\\mathbf{w}, b)\\) such that \\(\\hat{R}(f_{\\mathbf{w}, b}) = 0\\), then the perceptron algorithm is guaranteed to find such a pair after a number of steps that can be bounded in terms of the data."
  },
  {
    "objectID": "lecture-notes/erm.html#the-point",
    "href": "lecture-notes/erm.html#the-point",
    "title": "Models, Algorithms, and Learning",
    "section": "The Point",
    "text": "The Point\nWhat’s the point of developing all this theory for empirical risk minimization? The reason that this is helpful for us is that most modern prediction algorithms are doing versions of empirical risk minimization. We can even derive important, new algorithms just by modifying the loss function \\(\\ell\\). For example:\nBinary logistic regression is empirical risk minimization in which the labels \\(y \\in \\{0,1\\}\\), the predictions are of the form \\(\\hat{y} = \\langle \\mathbf{w}, \\mathbf{x} \\rangle - b\\) and the loss function is the logistic loss\n\\[\\ell(\\hat{y}, y) = y \\log \\sigma(\\hat{y}) + (1-y) \\log (1-\\sigma(\\hat{y}))\\;,\\]\nwhere \\(\\sigma(z)\\triangleq \\frac{1}{1 + e^{-z}}\\) is the logistic sigmoid function.\nLeast-squares linear regression is a form of empirical risk minimization which is more suitable for predicting a number \\(y \\in \\mathbb{R}\\) than a label like \\(y\\in \\{0,1\\}\\). In linear least-squares, the predictions are of the form \\(\\hat{y} = \\langle \\mathbf{w}, \\mathbf{x} \\rangle - b\\) and the loss function is the squared error\n\\[\\ell(\\hat{y}, y) = (y - \\hat{y})^2\\;.\\]\nSupport vector machines were the state-of-the-art classification method in the late 90s and early 2000s, and are still in use today. Support vector machines still use linear predictions of the form \\(\\hat{y} = \\langle \\mathbf{w}, \\mathbf{x} \\rangle - b\\). If the labels are \\(y \\in \\{-1,1\\}\\), then the loss function is the hinge loss written as\n\\[\\ell(\\hat{y}, y) = \\max\\{1 - y\\hat{y}, 0\\}\\;.\\]\nAs it turns out, the logistic loss, squared error, and hinge loss are all “better” losses than the \\(0-1\\) loss, for reasons which will become clear when we get to writing numerical algorithms for risk minimization."
  },
  {
    "objectID": "lecture-notes/erm.html#the-empirical-risk-minimization-workflow",
    "href": "lecture-notes/erm.html#the-empirical-risk-minimization-workflow",
    "title": "Models, Algorithms, and Learning",
    "section": "The Empirical Risk Minimization Workflow",
    "text": "The Empirical Risk Minimization Workflow\nFundamentally, an empirical risk minimization algorithm consists of:\n\nA family \\(\\mathcal{M}\\) of predictor functions \\(f_\\boldsymbol{\\theta}\\) that generates predictions \\(\\hat{y} = f_\\boldsymbol{\\theta}(\\mathbf{x})\\).\nA loss function \\(\\ell\\) that compares the prediction and the real value \\(\\ell(\\hat{y}, y)\\).\nAn algorithm for minimizing the empirical risk (Equation 2) with respect to the parameters \\(\\boldsymbol{\\theta}\\) of \\(\\mathcal{M}\\).\n\nMany empirical risk minimization algorithms also admit certain guarantees on how close the minimized empirical risk is to the actual risk under certain assumptions about the probability generating distribution. These kinds of guarantees are an extremely active area of ongoing machine learning research. They usually require some probability tools that are beyond the scope of this course."
  },
  {
    "objectID": "lecture-notes/erm.html#closeout-activity",
    "href": "lecture-notes/erm.html#closeout-activity",
    "title": "Models, Algorithms, and Learning",
    "section": "Closeout Activity",
    "text": "Closeout Activity\n\n\n\n\n\n\nBack to the Coin Flipping Game\n\n\n\nLet’s go back to the warmup corresponding to these lecture notes. We can think of the problem of choosing \\(\\hat{p}\\) as a prediction problem in which we observe 0 features! Identify and write down formulae for:\n\nThe data generating distribution.\nThe true risk corresponding to prediction \\(\\hat{p}\\).\nThe empirical risk corresponding to prediction \\(\\hat{p}\\).\n\nAdditionally: which loss function are we using in this game? It’s one of the ones in the notes above!\n\n\nIf your team gets all the way through those questions, please move on to the following coding exercise:\n\n\n\n\n\n\nExperiment\n\n\n\nThe following code simulates 100 random flips of a biased coin and computes the minimizer \\(\\hat{p}\\) of the empirical risk after each flip. It then plots the empirical and actual risk to show how these evolve as we observe more data.\nIt then computes arrays of the empirical risk R_hat and actual risk R associated the estimates \\(p_hat\\). For example, if \\(\\hat{p}_k\\) is the prediction after \\(k\\) observations, then the corresponding entry of \\(\\hat{R}_k\\) should have value \\(\\frac{1}{k} \\sum_{i = 1}^k \\left[-y \\log \\hat{p}_k - (1- y)\\log (1-\\hat{p}_k)\\right]\\) (hint: np.log. Second hint: simplify this expression a little using \\(\\hat{p}_k\\). ).\nHowever, there are two lines missing: the computation of the empirical and actual risks. Fill these in and run the experiment in a Jupyter notebook.\n\n# imports \nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# simulate flips. The array flips now contains 0s and 1s. \nn_flips = 100\np = 0.7 # bias of coin\nflips = 1*(np.random.rand(n_flips) < p)\n\n# minimizing value of p_hat after each flip\np_hat = np.cumsum(flips)/np.arange(1, len(flips)+1) \n\nR_hat = # empirical risk: fill in\nR =     # true risk:      fill in\n\n# construct the plot \nplt.rcParams[\"figure.figsize\"] = (6, 3)\nfig, axarr = plt.subplots(1, 2)\naxarr[0].plot(R_hat, label = \"Empirical risk\")\naxarr[0].plot(R, label = \"Risk\")\naxarr[0].legend()\naxarr[0].set(xlabel = \"iteration\", ylabel = \"risk (nats)\")\n\naxarr[1].plot(p_hat, label = \"Prediction\", color = \"grey\")\naxarr[1].plot(p*np.ones(n_flips), label = \"True value\", color = \"black\")\naxarr[1].set(xlabel = \"iteration\", ylabel = r\"prediction $p$\")\nplt.tight_layout()\n\naxarr[1].legend()\nYour result should look something like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscuss\n\n\n\nTry running your experiment a few times. Comment qualitatively: how accurate is the empirical risk as an estimate of the true risk? How accurate is \\(\\hat{p}\\) as an estimate of \\(p\\)? In this case, how many coin flips would you want to see before you felt comfortable with your predictive model? Why?"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Index of Assignments",
    "section": "",
    "text": "Blog Posts\n\n\n\n                \n                    \n                        \n                            Blog Post\n                         \n                    \n                    \n                        \n                            Implementing the Perceptron Algorithm\n                        \n                    \n                    \n                    Best By:   \n                    \n                    \n                        Feb 22, 2023\n                    \n                \n                \n                    \n                        In this blog post, you'll implement the perceptron algorithm using numerical programming and demonstrate its use on synthetic data sets.\n                    \n                \n            \n                \n                        Learning Objectives: \n                        \n                            Implementation\n                                | \n                            Navigation\n                                | \n                            Experimentation\n            \n        \n            \n        \n                \n                    \n                        \n                            Blog Post\n                         \n                    \n                    \n                        \n                            Optimization for Logistic Regression\n                        \n                    \n                    \n                    Best By:   \n                    \n                    \n                        Mar 1, 2023\n                    \n                \n                \n                    \n                        In this blog post, you'll implement several first-order methods: optimization algorithms based on the gradients of functions. You'll implement simple gradient descent, a momentum method, and stochastic gradient descent, comparing their performance for training logistic regression.\n                    \n                \n            \n                \n                        Learning Objectives: \n                        \n                            Theory\n                                | \n                            Implementation\n                                | \n                            Experimentation\n            \n        \n            \n        \n            \n        \n                \n                    \n                        \n                            Blog Post\n                         \n                    \n                    \n                        \n                            Kernel Logistic Regression\n                        \n                    \n                    \n                    Best By:   \n                    \n                    \n                        Mar 8, 2023\n                    \n                \n                \n                    \n                        In this blog post, you'll implement kernel logistic regression, a method for using linear empirical risk minimization to learn nonlinear decision boundaries.\n                    \n                \n            \n                \n                        Learning Objectives: \n                        \n                            Theory\n                                | \n                            Implementation\n                                | \n                            Navigation\n                                | \n                            Experimentation\n            \n        \n            \n        \n\n\nNo matching items\n\n\n\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-erm.html",
    "href": "assignments/blog-posts/blog-post-erm.html",
    "title": "Empirical Risk Minimization For Classification",
    "section": "",
    "text": "1 Introduction\nLet’s do empirical risk minimization!\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/solutions/logistic/experiments.html",
    "href": "assignments/blog-posts/solutions/logistic/experiments.html",
    "title": "",
    "section": "",
    "text": "from logistic import LogisticRegression\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nfrom logistic import LogisticRegression, gradient, stochastic_gradient\n\n# for step in [gradient, stochastic_gradient]:\n\n# LR = LogisticRegression()\n# LR.fit_stochastic(X, y, k = 1, max_iter = 10000)\n# plt.plot(LR.history, label = \"stochastic gradient\")\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, m_epochs = 100, momentum = True, batch_size = 1, alpha = .05)\nplt.plot(LR.history, label = \"stochastic gradient (momentum)\")\n\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, m_epochs = 100, momentum = False, batch_size = 1, alpha = .05)\nplt.plot(LR.history, label = \"stochastic gradient\")\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = .05)\nplt.plot(LR.history, label = \"gradient\")\nplt.loglog()\n\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f7acace32e0>\n\n\n\n\n\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\nw = LR.w\np = plt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\n\n\n\n\n\n\n[]\n\n\n\n\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-kernel-logistic.html",
    "href": "assignments/blog-posts/blog-post-kernel-logistic.html",
    "title": "Kernel Logistic Regression",
    "section": "",
    "text": "$$\n$$\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-kernel-logistic.html#kernel-logistic-regression",
    "href": "assignments/blog-posts/blog-post-kernel-logistic.html#kernel-logistic-regression",
    "title": "Kernel Logistic Regression",
    "section": "1.1 Kernel Logistic Regression",
    "text": "1.1 Kernel Logistic Regression\nIn the kernel logistic regression problem, we instead solve empirical risk minimization with modified features. The empirical risk is now\n\\[\nL_k(\\mathbf{v}) = \\frac{1}{n} \\sum_{i = 1}^n \\ell(\\langle \\mathbf{v}, \\boldsymbol{\\kappa}(\\mathbf{x}_i) \\rangle, y_i)\\;,\n\\tag{1}\\]\nwhere \\(\\mathbf{v}\\in \\mathbb{R}^n\\) (not  \\(\\mathbb{R}^p\\)). The modified feature vector \\(\\boldsymbol{\\kappa}(\\mathbf{x}_i)\\) has entries\n\\[\n\\boldsymbol{\\kappa}(\\mathbf{x}_i) = \\left( \\begin{matrix}\n    k(\\mathbf{x}_1, \\mathbf{x}_i) \\\\\n    k(\\mathbf{x}_2, \\mathbf{x}_i) \\\\\n    \\vdots \\\\\n    k(\\mathbf{x}_n, \\mathbf{x}_i)\n\\end{matrix}\\right)\\;.\n\\]\nHere, \\(k:\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\) is the kernel function. Kernel functions need to satisfy some special mathematical properties. We’re not going to code them up; instead we’re going to use some built-in functions from scikit-learn to handle the kernel functions for us.\nOnce the model has been trained and an optimal \\(\\hat{\\mathbf{v}}\\) has been obtained, one can then make a prediction using the formula\n\\[\n\\hat{y} = \\langle \\hat{\\mathbf{v}}, \\boldsymbol{\\kappa}(\\mathbf{x}) \\rangle\\;.\n\\]\nIf it is desired to return a 0-1 label instead of a real number, one can return \\(\\mathbb{1}[\\hat{y} > 0]\\)."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-kernel-logistic.html#implement-kernel-logistic-regression",
    "href": "assignments/blog-posts/blog-post-kernel-logistic.html#implement-kernel-logistic-regression",
    "title": "Kernel Logistic Regression",
    "section": "2.1 Implement Kernel Logistic Regression",
    "text": "2.1 Implement Kernel Logistic Regression\nImplement a Python class called KernelLogisticRegression. You’ll be able to use it like the example in the previous section. Your class should implement the following methods:\nIf you’re not sure how to use **kwargs in Python functions and methods, you might want to check this resource.\n\n__init__(self, kernel, **kernel_kwargs) should accept a kernel function and a set of named keyword arguments called kernel_kwargs. All the __init__() method should do is to save these items as instance variables called\n\nself.kernel\nself.kernel_kwargs\n\nfit(self, X, y) will again be the method that learns the optimal parameters \\(\\hat{v}\\). The fit method is going to look a little different this time:\n\nFirst, pad X to make sure that X contains a column of 1s. Here’s a function to do this:\n\n    def pad(X):\n        return np.append(X, np.ones((X.shape[0], 1)), 1)\n\nSave X as an instance variable called self.X_train.\nCompute the kernel matrix of X with itself. If you implemented __init__() correct, this can be done with the call\n\nkm = self.kernel(X_, X_, **self.kernel_kwargs)\n\nMinimize the empirical risk Equation 1. You might find it useful to define a separate function for computing the empirical risk. Note that the predictor is still an inner product, just with a different parameter vector \\(\\mathbf{v}\\) and a different matrix column \\(\\boldsymbol{\\kappa}(\\mathbf{x}_i)\\). This means that, if you’re careful, you can compute the entire empirical risk using just one matrix multiplication!\n\nHowever you find it, save the resulting optimal value of \\(\\mathbf{v}\\) as self.v.\nYou should still use the logistic loss for \\(\\ell\\).\nYou will probably need to choose a random initial \\(\\mathbf{v}\\). Don’t forget that \\(\\mathbf{v}\\) should have length equal to the number of data points, not the number of features.\n\nIf you’ve already implemented gradient descent for logistic regression in this blog post, then it’s not too hard to adapt your method to kernel logistic regression. However, it’s also fine to use the function scipy.optimize.minimize() as demonstrated in this lecture.\n\npredict(self, X) should accept a new feature matrix and return binary labels \\(\\{0,1\\}\\). For each row of \\(\\mathbf{X}\\), the prediction is obtained using the formula \\(\\mathbb{1}[\\langle \\hat{\\v}, \\boldsymbol{\\kappa}(\\mathbf{x}) \\rangle]\\). To do this:\n\nCompute the kernel matrix between self.X_train and the new feature input X. Each column of this matrix is \\(\\boldsymbol{\\kappa}(\\mathbf{x}_j)\\) for some \\(j\\).\nCompute inner products of the form \\(\\langle \\mathbf{v}, \\boldsymbol{\\kappa}(\\mathbf{x}_j) \\rangle\\). If the user supplies a matrix X with multiple columns, you should be able to compute all the predictions at once. This can be done efficiently using matrix multiplication.\nFinally, return a binary vector \\(\\hat{\\mathbf{y}}\\) whose \\(j\\)th entry is \\(\\hat{y}_j = \\mathbb{1}[\\langle \\mathbf{v}, \\mathbf{x}_j \\rangle > 0]\\).\n\nscore(self, X, y) computes the accuracy of the model predictions on the feature matrix X with labels y.\n\nYou can assume that the user will always only call predict and score after calling fit. If you’d like, you’re welcome to add warnings or handle other cases in which the user may be less cooperative and attempt to call one of those methods first.\nMy complete implementation of kernel logistic regression was about 50 lines of code, excluding comments.\nDocstrings are not expected for this blog post."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-kernel-logistic.html#experiments",
    "href": "assignments/blog-posts/blog-post-kernel-logistic.html#experiments",
    "title": "Kernel Logistic Regression",
    "section": "2.2 Experiments",
    "text": "2.2 Experiments\n\nBasic Check\nOnce you’re done, you’ll be able to import and and use your function like this.\nfrom kernel_logistic import KernelLogisticRegression # your source code\nfrom sklearn.metrics.pairwise import rbf_kernel\nfrom sklearn.datasets import make_moons, make_circles\n\nX, y = make_moons(200, shuffle = True, noise = 0.2)\nKLR = KernelLogisticRegression(rbf_kernel, gamma = .1)\nKLR.fit(X, y)\nprint(KLR.score(X, y))\nHere, the rbf_kernel is the kernel function and gamma is a parameter to that kernel function that says how “wiggly” the decision boundary should be. Larger gamma means a more wiggly decision boundary.\nYour implementation is likely correct when you can generate new synthetic versions of the data set above (just call make_moons again) and achieve accuracy consistently at or above 90%. To check that, you can just run the code block above a few times.\n\n\nChoosing gamma\nWhen we choose a very large value of gamma, we can achieve a very wiggly decision boundary with very good accuracy on the training data. For example:\n\nKLR = KernelLogisticRegression(rbf_kernel, gamma = 10000)\nKLR.fit(X, y)\nprint(KLR.score(X, y))\nplot_decision_regions(X, y, clf = KLR)\nt = title = plt.gca().set(title = f\"Accuracy = {KLR.score(X, y)}\",\n                      xlabel = \"Feature 1\", \n                      ylabel = \"Feature 2\")\n\n1.0\n\n\n\n\n\nHere, our classifier draws a little orange blob around each orange data point: points very nearby are classified as orange while other points are classified as blue. This is sufficient to achieve 100% accuracy on the training data. But this doesn’t generalize: generate some new data and we’ll see much worse performance:\n\n# new data with the same rough pattern\nX, y = make_moons(200, shuffle = True, noise = 0.2)\nplot_decision_regions(X, y, clf = KLR)\ntitle = plt.gca().set(title = f\"Accuracy = {KLR.score(X, y)}\",\n                      xlabel = \"Feature 1\", \n                      ylabel = \"Feature 2\")\n\n\n\n\nWhoops! Not so good. We say that the validation or testing accuracy of the classifier is quite low. Cases in which the validation accuracy is low even though the training accuracy is high are classic instances of overfitting.\n Design an experiment in which you fit your model for several different values of gamma. Show accuracy on both training data (the data on which the model was fit) and testing data (data generated from the same settings but which the model has never seen before). Please show your findings in the form of an attractive visualization with clear labels and a clear message.My suggestion is to choose gamma in 10**np.arange(-5, 6)\n\n\nVary the Noise\nRepeat your experiment with at least two other values of the noise parameter to make_moons. The noise determines how spread out the two crescents of points are. Do your findings suggest that the best value of gamma depends much on the amount of noise?\n\n\nTry Other Problem Geometries\nUse the make_circles function to generate some concentric circles instead of crescents. Show a few examples with varying amounts of noise. Can you find some values of gamma that look like they lead to good learning performance for this data set? Here’s an example of a fairly successful classifier: both the points and the accuracy are computed on unseen test data.\n\n\n0.975"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-kernel-logistic.html#blog-post",
    "href": "assignments/blog-posts/blog-post-kernel-logistic.html#blog-post",
    "title": "Kernel Logistic Regression",
    "section": "2.3 Blog Post",
    "text": "2.3 Blog Post\nYour blog post should describe your approach to your code and written descriptions of your experiments.\n\nPlease include a walk-through for your user of how you computed the empirical loss.\nPlease make sure that your figures are appropriately labeled and described.\nPlease make sure to include a link to the GitHub page containing your source code at the very beginning of the blog post.\n\nIn case you’re curious, it’s possible to add formal captions to your figures in Quarto. This makes things look a little fancier, but is not required!\nOnce you’re happy with how things look, render your blog, push it to GitHub, and submit a link to the URL of your blog post on Canvas."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-penguins.html",
    "href": "assignments/blog-posts/blog-post-penguins.html",
    "title": "Application Project: Classifying Palmer Penguins",
    "section": "",
    "text": "© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-medical-bias.html",
    "href": "assignments/blog-posts/blog-post-medical-bias.html",
    "title": "Bias in a Medical Recommender System",
    "section": "",
    "text": "© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-perceptron.html",
    "href": "assignments/blog-posts/blog-post-perceptron.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "\\[\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\vx}{\\mathbf{x}}\n\\newcommand{\\vy}{\\mathbf{y}}\n\\newcommand{\\mX}{\\mathbf{X}}\n\\newcommand{\\vw}{\\mathbf{w}}\n\\newcommand{\\bracket}[1]{\\langle #1 \\rangle}\n\\newcommand{\\paren}[1]{\\left( #1 \\right)}\n\\]\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-perceptron.html#source-code",
    "href": "assignments/blog-posts/blog-post-perceptron.html#source-code",
    "title": "Implementing the Perceptron Algorithm",
    "section": "3.1 Source Code",
    "text": "3.1 Source Code\nYour class should have the following methods:\n\nPerceptron.fit(X, y) is the primary method. This method has no return value. If p is a Perceptron, then after p.fit(X, y) is called, p should have an instance variable of weights called w. This w is the vector \\(\\tilde{\\vw} = (\\vw, -b)\\) in the classifier above. Additionally, p should have an instance variable called p.history which is a list of the evolution of the score over the training period (see Perceptron.score(X, y) below.)\nPerceptron.predict(X) should return a vector \\(\\hat{\\vy} \\in \\{0,1\\}^n\\) of predicted labels. These are the model’s predictions for the labels on the data.\nPerceptron.score(X, y) should return the accuracy of the perceptron as a number between 0 and 1, with 1 corresponding to perfect classification.\n\nFeel free to add any other methods or functions that you find helpful while implementing.\n\nImplementing fit()\nTo implement fit(), it’s convenient to consider a modified version of \\(\\mX\\): \\(\\tilde{\\mX} = [\\mX, \\mathbf{1}]\\), where \\(\\mathbf{1} \\in \\R^n\\) is a column-vector of \\(1\\)s. The reason this is handy is that if we also define \\(\\tilde{\\vw} = (\\vw, -b)\\), then we can write our classification rule as\n\\[\n\\hat{y}_i = \\mathbb{1}(\\langle \\tilde{\\vw}, \\tilde{\\vx}_i\\rangle \\geq 0)\\;.\n\\]\nThis is mathematically convenient and makes it much easier for us to code up our algorithms.\nWith these definitions, the perceptron algorithm proceeds as follows:\n\nFirst, initialize a random initial weight vector \\(\\tilde{\\vw}^{(0)}\\).\nThen, until termination:\n\n\nPick a random index \\(i \\in [n]\\).\nCompute\n\n\\[\n\\tilde{\\vw}^{(t+1)} = \\tilde{\\vw}^{(t)} + \\mathbb{1}(\\tilde{y}_i \\langle \\tilde{\\vw}^{(t)}, \\tilde{\\vx}_i\\rangle < 0)\\tilde{y}_i \\tilde{\\vx}_i\\;.\n\\tag{1}\\]\nIn this expression, \\(\\tilde{y}_i = 2y_i - 1\\) is a convenient version of \\(y_i\\) that takes values \\(-1\\) and \\(1\\) instead of \\(0\\) and \\(1\\).\nThis update is performed until either a user-specified maximum number of steps is reached or until the score (accuracy) reaches 1.0.\nNote that in an iteration in which \\(\\tilde{y}_i \\langle \\tilde{\\vw}^{(t)}, \\tilde{\\vx}_i\\rangle \\geq 0\\), nothing happens. Take a moment to check that this occurs when the current weight vector \\(\\tilde{\\vw}^{(t)}\\) correctly classifies the tuple \\((\\vx_i, y_i)\\).\n\n\nOther Specifications\nYou should be able to replicate the demo in Section 2 with your source code. Feel free to use that demo as a test case – your source code may be in good shape when you are able to fully replicate the results. For perfect replication, you’ll need to include the call to np.random.seed() immediately after importing your packages.\nAn excellent solution will have exactly one for-loop, of the form:\nfor _ in range(max_steps):\n  # perform the perceptron update and log the score in self.history\nThat is, you should not do any loops over the data! Use vectorized numpy operations and matrix-vector multiplication.\nYou should also not use if statements to perform comparisons between numbers.\n\n\nFor a hint on how you can avoid doing this, you can reflect on the following two code snippets:\nprint((1 < 2)*2)\nprint((1 > 2)*2)\n\n\n\n\n\n\nPlease include informative docstrings for Perceptron.fit(), Perceptron.predict(), and Perceptron.score().\n\n\n\nA concise solution should likely be no more than 60 lines of compact Python code (excluding comments and docstrings)."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-perceptron.html#experiments",
    "href": "assignments/blog-posts/blog-post-perceptron.html#experiments",
    "title": "Implementing the Perceptron Algorithm",
    "section": "3.2 Experiments",
    "text": "3.2 Experiments\nPlease perform experiments (with visualizations) that illustrate the following:\n\nUsing 2d data like the data in the example, if the data is linearly separable then the perceptron algorithm converges to weight vector \\(\\tilde{\\vw}\\) describing a separating line (provided that the maximum number of iterations is large enough).\n\nPlease show visualizations of the data, the separating line, and the evolution of the accuracy over training. It’s also fine for you to use the loss instead of the accuracy if you’d prefer.\n\n\nFor 2d data, when the data is not linearly separable, the perceptron algorithm will not settle on a final value of \\(\\tilde{\\vw}\\), but will instead run until the maximum number of iterations is reached, without achieving perfect accuracy.\n\nPlease show visualizations of the data, the line in the final iteration, and the evolution of the score over training.\n\nThe perceptron algorithm is also able to work in more than 2 dimensions! Show an example of running your algorithm on data with at least 5 features. You don’t need to visualize the data or the separating line, but you should still show the evolution of the score over the training period. Include a comment on whether you believe that the data is linearly separable based on your observation of the score."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-perceptron.html#writing",
    "href": "assignments/blog-posts/blog-post-perceptron.html#writing",
    "title": "Implementing the Perceptron Algorithm",
    "section": "3.3 Writing",
    "text": "3.3 Writing\nIn crafting your blog post, please include the following components:\n\nAt the very top of your blog post, a link to your source code (perceptron.py) on your GitHub repo.\nA brief walk-through of your implementation of the perceptron update (Equation 1) in your source code. Quote the function which you use to perform the update. It’s not necessary to walk the user through every single aspect of your solution class.\nFull code and English descriptions for all the experiments you perform.\nAt the end of your blog post, please address the following question:\n\n\nWhat is the runtime complexity of a single iteration of the perceptron algorithm update as described by Equation 1? Assume that the relevant operations are addition and multiplication. Does the runtime complexity depend on the number of data points \\(n\\)? What about the number of features \\(p\\)?\n\nYou only need to consider this question in the context of a single update. The question of how many updates are required to converge is a trickier one that you don’t have to discuss in your blog post."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html",
    "href": "assignments/blog-posts/blog-post-optimization.html",
    "title": "Optimization for Logistic Regression",
    "section": "",
    "text": "\\[\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\vx}{\\mathbf{x}}\n\\newcommand{\\vy}{\\mathbf{y}}\n\\newcommand{\\mX}{\\mathbf{X}}\n\\newcommand{\\vw}{\\mathbf{w}}\n\\newcommand{\\bracket}[1]{\\langle #1 \\rangle}\n\\newcommand{\\abs}[1]{\\lvert #1 \\rvert}\n\\newcommand{\\paren}[1]{\\left( #1 \\right)}\n\\]\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#introduction",
    "href": "assignments/blog-posts/blog-post-optimization.html#introduction",
    "title": "Optimization for Logistic Regression",
    "section": "Introduction",
    "text": "Introduction\nIn , we introduced the gradient descent algorithm for optimization and showed it in action for the logistic regression problem. In this blog post, you’ll:\n\nImplement gradient descent for logistic regression in an object-oriented paradigm.\nImplement a key variant of gradient descent called stochastic gradient descent, including an optional momentum feature.\nPerform several simple experiments on synthetic data to see which of these algorithms converges most quickly to a satisfactory logistic regression model."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#implement-logistic-regression",
    "href": "assignments/blog-posts/blog-post-optimization.html#implement-logistic-regression",
    "title": "Optimization for Logistic Regression",
    "section": "1. Implement Logistic Regression",
    "text": "1. Implement Logistic Regression\nIn your source file, implement a LogisticRegression() class. Your class should have similar user-facing functions as the Perceptron() class from the previous blog post. These are:\n\nLogisticRegression.fit(X, y) is the primary method. This method has no return value. If LR is a LogisticRegression object, then after LR.fit(X, y) is called, LR should have an instance variable of weights called w. This w is the vector of weights, including the bias term \\(b\\). LR should have an instance variable called LR.loss_history which is a list of the evolution of the loss over the training period (see LogisticRegression.loss(X, y) below). Finally, LR should have an instance variable called LR.score_history which is a list of the evolution of the score over the training period (see LogisticRegression.score(X, y) below).\nLogisticRegression.predict(X) should return a vector \\(\\hat{\\vy} \\in \\{0,1\\}^n\\) of predicted labels. These are the model’s predictions for the labels on the data.\nLogisticRegression.score(X, y) should return the accuracy of the predictions as a number between 0 and 1, with 1 corresponding to perfect classification.\nLogisticRegression.loss(X, y) should return the overall loss (empirical risk) of the current weights on X and y.\n\n\nGradient Descent\nYour LogisticRegression.fit method should use gradient descent as described in lecture. Allow the user to specify the learning rate \\(\\alpha\\) and the maximum number of iterations, which for this blog post we’ll call epochs. So, using the fit method might look like this:\n\nfrom solutions.logistic import LogisticRegression # your source code\nfrom sklearn.datasets import make_blobs\nfrom matplotlib import pyplot as plt\nimport numpy as np\nnp.seterr(all='ignore') \n\n# make the data\np_features = 3\nX, y = make_blobs(n_samples = 200, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\n# fit the model\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = 0.1, max_epochs = 1000)\n\n# inspect the fitted value of w\nLR.w \n\narray([ 1.82446608,  2.00364179, -0.239102  ])\n\n\n\n\nStochastic Gradient Descent\nNow implement an alternative version of the fit method called fit_stochastic. In this method, you will implement stochastic gradient descent. In stochastic gradient descent, we don’t compute the complete gradient\n\\[\n\\nabla L(\\vw) = \\frac{1}{n}\\sum_{i = 1}^n \\nabla \\ell(f_{\\vw}(\\vx_i), y_i)\\;.\n\\]\nInstead, we compute a stochastic gradient by picking a random subset \\(S \\subseteq [n] = \\{1, \\ldots, n\\}\\) and computing\n\\[\n\\nabla_S L(\\vw) = \\frac{1}{\\abs{S}}\\sum_{i \\in S} \\nabla \\ell(f_{\\vw}(\\vx_i), y_i)\\;.\n\\]\nThe size of \\(S\\) is called the batch size. Typically, we cycle through all the points \\(1\\) through \\(n\\) in the following way:\n\nShuffle the points randomly.\nPick the first \\(k\\) random points, compute the stochastic gradient, and then perform an update.\nPick the next \\(k\\) random points and repeat..\nWhen we have gone through all \\(n\\) points, reshuffle them all randomly and proceed again.\n\nThis process can be accomplished efficiently using the np.array_split() function, which will create batches for you. Here is some code to get you started; it will split the data into batches of size batch_size\n\nn = X.shape[0]\nfor j in np.arange(m_epochs):\n            \n    order = np.arange(n)\n    np.random.shuffle(order)\n\n    for batch in np.array_split(order, n // batch_size + 1):\n        x_batch = X[batch,:]\n        y_batch = y[batch]\n        grad = gradient(w, x_batch, y_batch) \n        # perform the gradient step\n        # ...\nFor stochastic gradient descent, only update self.loss_history at the end of each epoch. This allows us to compare to regular gradient descent, since in both algorithms at the end of an epoch we have used every single point once.\n\n\nMomentum (Optional)\nThe momentum method is described on p. 85 of Hardt and Recht. Implement the momentum method for stochastic gradient descent. My advice is to do so as an optional parameter for fit_stochastic. In my implementation, if the user sets momentum = True then I set the parameter \\(\\beta\\) from Hardt and Recht to value 0.8. Otherwise it is set to 0, and we have regular gradient descent.\n\n\nIllustration\nHere is an example plot showing the evolution of the loss function for the three algorithms:\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = True, \n                  batch_size = 10, \n                  alpha = .05) \n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient (momentum)\")\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = False, \n                  batch_size = 10, \n                  alpha = .1)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient\")\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = .05, max_epochs = 100)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"gradient\")\n\nplt.loglog()\n\nlegend = plt.legend() \n\n\n\n\nEvolution of the training loss for three optimization algorithms.\n\n\n\n\nFor these settings, stochastic gradient descent with and without momentum tends to get to a “pretty good” result faster than standard gradient descent, but these random algorithms can “bounce around” near the good solution. Standard gradient descent might need more epochs to find a good solution, but quickly “settles down” once it finds it."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#perform-experiments",
    "href": "assignments/blog-posts/blog-post-optimization.html#perform-experiments",
    "title": "Optimization for Logistic Regression",
    "section": "2. Perform Experiments",
    "text": "2. Perform Experiments\nAfter you have tested and implemented your class, please perform experiments in which you show examples of the following phenomena:\n\nA case in which gradient descent does not converge to a minimizer because the learning rate \\(\\alpha\\) is too large.\nA case in which the choice of batch size influences how quickly the algorithm converges.\nIf you implemented momentum, a case in which the use of momentum significantly speeds up convergence.\n\nIn at least one of these experiments, generate some synthetic data (it’s fine to use make_blobs) for data of at least 10 feature dimensions."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#document-and-write",
    "href": "assignments/blog-posts/blog-post-optimization.html#document-and-write",
    "title": "Optimization for Logistic Regression",
    "section": "3. Document and Write",
    "text": "3. Document and Write\nPlease include informative comments throughout your source code, and a thorough docstring for each of your fit and fit_stochastic methods.\nIn your blog post, please describe both your approach to implementing your algorithm and the findings of your experiments."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#submit",
    "href": "assignments/blog-posts/blog-post-optimization.html#submit",
    "title": "Optimization for Logistic Regression",
    "section": "4. Submit",
    "text": "4. Submit\nSubmit your blog post, making sure to include a link to the online version of your source code at the top of your post."
  },
  {
    "objectID": "assignments/blog-posts/blog-post-optimization.html#tips-and-hints",
    "href": "assignments/blog-posts/blog-post-optimization.html#tips-and-hints",
    "title": "Optimization for Logistic Regression",
    "section": "Tips and Hints",
    "text": "Tips and Hints\nMost of the major math functions are shown in our lecture on gradient descent. You’re welcome to use any of these functions as you wish; please just incorporate comments in your code and blog post to cite where they came from.\nYou will find it convenient again to ensure that X contains a column of 1s prior to any major computations. I defined this function:\ndef pad(X):\n    return np.append(X, np.ones((X.shape[0], 1)), 1)\nand called it at a few strategic places in my implementation.\nMy complete implementation, including all the math functions, momentum, etc. but excluding comments, was about 100 lines of code.\nYou’re welcome to find creative ways to visualize your findings. You might also find it interesting to visualize the score (not just the loss). However, this is optional."
  },
  {
    "objectID": "assignments/process/mid-course.html",
    "href": "assignments/process/mid-course.html",
    "title": "Mid-Course Reflection",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice. I recommend JupyterLab for this one, but you can pick.\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What You Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, review the soundbytes describing letter grades.\nTake some time to reflect on your responses so far. When you’re ready, propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451 so far.\nOptionally, respond to the last prompt with some thoughts on how the semester is going and what we might do to help you meet your goals for the course.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf end-of-course.ipynb\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/process/mid-course.html#the-data",
    "href": "assignments/process/mid-course.html#the-data",
    "title": "Mid-Course Reflection",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\nPresence in Class\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) ____\nHow often have you taken notes on the core readings ahead of the class period? ____\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? ____\nHow many times have you actually presented the daily warm-up to your team? ____\nHow many times have you asked your team for help while presenting the daily warm-up? ____\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? ____\nHow often have you helped a teammate during the daily warm-up presentation? ____\n\n\n\nPresence Outside of Class\n\nHow often have you attended Student Hours or Peer Help? ____\nHow often have you asked for or received help from your fellow students? ____\nHave you been regularly participating in a study group outside class? ____\nHow often have you posted questions or answers in Slack? ____\n\n\n\nAssignments and Effort\n\nHow many blog posts have you submitted? ____\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nNo revisions suggested: ____\nRevisions useful: ____\nRevisions encouraged: ____\nIncomplete: ____\n\nRoughly how many hours per week have you spent on this course outside of class? ____"
  },
  {
    "objectID": "assignments/process/mid-course.html#what-youve-learned",
    "href": "assignments/process/mid-course.html#what-youve-learned",
    "title": "Mid-Course Reflection",
    "section": "What You’ve Learned",
    "text": "What You’ve Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\n[your response here]"
  },
  {
    "objectID": "assignments/process/mid-course.html#reflecting-on-goals",
    "href": "assignments/process/mid-course.html#reflecting-on-goals",
    "title": "Mid-Course Reflection",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\nBlog Posts\n[your response here]\n\n\nCourse Presence (Participation)\n[your response here]\n\n\nProject\n[your response here]\n\n\nOther\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n[your response here]"
  },
  {
    "objectID": "assignments/process/mid-course.html#grade-and-goals",
    "href": "assignments/process/mid-course.html#grade-and-goals",
    "title": "Mid-Course Reflection",
    "section": "Grade and Goals",
    "text": "Grade and Goals\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far. Here are some soundbytes to help guide your thinking:\n\nWhat a Grade Sounds Like\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of ____"
  },
  {
    "objectID": "assignments/process/mid-course.html#optional-how-to-improve",
    "href": "assignments/process/mid-course.html#optional-how-to-improve",
    "title": "Mid-Course Reflection",
    "section": "(Optional:) How to Improve?",
    "text": "(Optional:) How to Improve?\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n[your response here]"
  },
  {
    "objectID": "assignments/process/ideas.html",
    "href": "assignments/process/ideas.html",
    "title": "Ideas for Goal-Setting",
    "section": "",
    "text": "If you’re not sure what goals you might want to set for yourself when setting your goals for the course, here are a few ideas to help you get started. Don’t limit yourself to just these ideas! They are just here to show you some possibilities and get your creative juices flowing. Note that these are not requirements and you do not have to do all of these in order to demonstrate learning in the course.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/process/ideas.html#blog-posts",
    "href": "assignments/process/ideas.html#blog-posts",
    "title": "Ideas for Goal-Setting",
    "section": "Blog Posts",
    "text": "Blog Posts\n\nSubmit a blog post in most weeks during the semester.\nSubmit the first draft of no more than two blog posts after the “best-by” date.\nRevise at least five blog posts to the “No Revisions Suggested” level.\nGo above and beyond in at least two blog posts by implementing more complex algorithms, discussing more advanced theory, or performing experiments significantly beyond what is requested.\nPropose and complete a blog post on a topic not covered in lecture, especially one related to your areas of focused interest.\nPropose and complete an additional blog post on a topic related to algorithmic bias and social responsibility."
  },
  {
    "objectID": "assignments/process/ideas.html#course-presence",
    "href": "assignments/process/ideas.html#course-presence",
    "title": "Ideas for Goal-Setting",
    "section": "Course Presence",
    "text": "Course Presence\n\nComplete all core readings prior to each class periods.\nComplete the optional readings that correspond to my areas of specialization.\n“Pass” at most once when asked to lead the warmup activity for my group.\nAsk questions or make suggestions for the warmup presenter in most weeks.\nPropose questions ahead of time for our guest speaker.\nOrganize a study group outside of class time to work on blog posts or other course work.\nAttend a study group outside of class time.\nFrequently attend Peer Help or Student Hours (after preparing questions and working examples).\nRegularly post questions or answers on the course Slack workspace."
  },
  {
    "objectID": "assignments/process/ideas.html#project",
    "href": "assignments/process/ideas.html#project",
    "title": "Ideas for Goal-Setting",
    "section": "Project",
    "text": "Project\n\nSubmit all project milestones (proposal, progress report, etc) on time.\nSet regular time each week to work with project partners.\nCommunicate with my group in a clear and timely manner.\nImplement algorithms or write automated checks of algorithms written by teammates.\nDraft designated sections of the project report.\nRevise sections of the project report in response to feedback.\nLead creation of the final project presentation.\nTake the lead in delivering part of the final project presentation.\nTake the lead in checking project figures for accuracy and clear labeling."
  },
  {
    "objectID": "assignments/process/goal-setting.html",
    "href": "assignments/process/goal-setting.html",
    "title": "Reflective Goal-Setting",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice. I recommend JupyterLab for this one, but you can pick.\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nIn each of the spaces provided, write down some goals describing what you believe success will look like for you in CSCI 0451. I’ve offered some ideas to help you get started in case you’re not sure, but you shouldn’t feel constrained by these.\nYou may want to look at the end-of-course reflection activity in which you’ll look back on your goals and propose a letter grade that reflects your learning, participation, and achievement in the course. You might especially want to look at the data that I’ll ask you to log and what a grade sounds like.\nSubmit the notebook as a PDF on Canvas.\n\nI’ll respond to your submission with feedback on your goals. I may ask you to display more or less ambition in some of your goals; in that case, I’ll ask you to revise and resubmit.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf goal-setting.ipynb\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/process/goal-setting.html#what-youll-learn",
    "href": "assignments/process/goal-setting.html#what-youll-learn",
    "title": "Reflective Goal-Setting",
    "section": "What You’ll Learn",
    "text": "What You’ll Learn\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\n[your response here]"
  },
  {
    "objectID": "assignments/process/goal-setting.html#what-youll-achieve",
    "href": "assignments/process/goal-setting.html#what-youll-achieve",
    "title": "Reflective Goal-Setting",
    "section": "What You’ll Achieve",
    "text": "What You’ll Achieve\n\nBlog Posts\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\n[your response here]\n\n\nCourse Presence (Participation)\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\n[your response here]\n\n\nProject\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\n[your response here]"
  },
  {
    "objectID": "assignments/process/end-of-course.html",
    "href": "assignments/process/end-of-course.html",
    "title": "End-Of-Course Reflection",
    "section": "",
    "text": "Download this notebook\nOpen the notebook in an editor of your choice. I recommend JupyterLab for this one, but you can pick.\nDelete the first two cells of the notebook (i.e. this one and the raw cell above).\nBriefly review the goals you set for yourself in our goal-setting activity at the beginning of the course. You can find your goals on Canvas.\nIn the The Data section, replace the blanks with brief responses.\nIn the What you Learned and Reflecting on Goals sections, write down your reflections on your learning, achievement, and presence in CSCI 0451 in the provided markdown cells.\nTake some time to reflect on your responses so far. When you’re ready, move on to propose the letter grade that you feel best reflects your learning, participation, and achievement in CSCI 0451.\nSubmit the notebook as a PDF on Canvas.\n\nWe’ll discuss your reflection and your proposed letter grade during our end-of-semester conference.\nThere are lots of ways to render Jupyter notebooks as PDFs. The simplest way is to run this at the command line, after you’ve navigated to the location of the notebook:\njupyter nbconvert --to pdf end-of-course.ipynb\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "assignments/process/end-of-course.html#the-data",
    "href": "assignments/process/end-of-course.html#the-data",
    "title": "End-Of-Course Reflection",
    "section": "The Data",
    "text": "The Data\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often did you attend class,” good answers include “almost always,” “I missed three times,” “about 75% of the time,” “not as often as I wanted,” etc.\n\nPresence in Class\n\nHow often did you attend class? (e.g. “almost always,” “I missed three times,” etc.) ____\nHow often did you take notes on the core readings ahead of the class period? ____\nHow often were you prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? ____\nHow many times did you actually present the daily warm-up to your team? ____\nHow many times did you ask your team for help while presenting the daily warm-up? ____\nHow often did you learn something new from a teammate’s presentation of the daily warm-up? ____\nHow often did you help a teammate during the daily warm-up presentation? ____\nDid you contribute a question for our guest speaker? ____\n\n\n\nPresence Outside of Class\n\nHow often did you attend Student Hours or Peer Help? ____\nHow often did you ask for or receive help from your fellow students? ____\nDid you regularly participate in a study group outside class? ____\nHow often did you post questions or answers in Slack? ____\n\n\n\nAssignments and Effort\n\nHow many blog posts did you submit? ____\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nNo revisions suggested: ____\nRevisions useful: ____\nRevisions encouraged: ____\nIncomplete: ____\n\nRoughly how many hours per week did you spend on this course outside of class? ____"
  },
  {
    "objectID": "assignments/process/end-of-course.html#what-you-learned",
    "href": "assignments/process/end-of-course.html#what-you-learned",
    "title": "End-Of-Course Reflection",
    "section": "What You Learned",
    "text": "What You Learned\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what did you do in order to pursue your interest?\n[your response here]"
  },
  {
    "objectID": "assignments/process/end-of-course.html#reflecting-on-goals",
    "href": "assignments/process/end-of-course.html#reflecting-on-goals",
    "title": "End-Of-Course Reflection",
    "section": "Reflecting on Goals",
    "text": "Reflecting on Goals\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways did you meet your goals from the beginning of the course? Be specific: explain what the goal was and what you did to meet it.\nIn what ways did you not meet your goals from the beginning of the course? Be specific: explain what the goal was and what the gap was between what you aspired to and what happened.\nIf there’s any context you want to share about how you fared relative to your goals, please do!\n\n\nBlog Posts\n[your response here]\n\n\nCourse Presence (Participation)\n[your response here]\n\n\nProject\n[your response here]\n\n\nOther\nIs there anything else that you want to share with me about what you learned, how you participated, or what you achieved in CSCI 0451?\n[your response here]"
  },
  {
    "objectID": "posts/2023-01-01-test.html",
    "href": "posts/2023-01-01-test.html",
    "title": "My First Blog Post",
    "section": "",
    "text": "This is some code that I’m writing, but also some math that I’m doing.\n\\[x = - y\\]\n\nfrom matplotlib import pyplot as plt\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "sol/logistic/experiments.html",
    "href": "sol/logistic/experiments.html",
    "title": "",
    "section": "",
    "text": "from logistic import LogisticRegression\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport numpy as np\n\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nfrom logistic import LogisticRegression, gradient, stochastic_gradient\n\n# for step in [gradient, stochastic_gradient]:\n\n# LR = LogisticRegression()\n# LR.fit_stochastic(X, y, k = 1, max_iter = 10000)\n# plt.plot(LR.history, label = \"stochastic gradient\")\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, m_epochs = 100, momentum = True, batch_size = 1, alpha = .05)\nplt.plot(LR.history, label = \"stochastic gradient (momentum)\")\n\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, m_epochs = 100, momentum = False, batch_size = 1, alpha = .05)\nplt.plot(LR.history, label = \"stochastic gradient\")\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = .05)\nplt.plot(LR.history, label = \"gradient\")\nplt.loglog()\n\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f7acace32e0>\n\n\n\n\n\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\nf1 = np.linspace(-3, 3, 101)\nw = LR.w\np = plt.plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\n\n\n\n\n\n\n[]\n\n\n\n\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "sol/perceptron/perceptron-experiment.html",
    "href": "sol/perceptron/perceptron-experiment.html",
    "title": "",
    "section": "",
    "text": "n = 100\nX = np.random.rand(n, 2) - .5\nw_true = np.array([.5, .5])\ny = 1*(X@w_true > 0)\n\n\ndf = pd.DataFrame(np.append(X, y[..., None], 1), columns=[\"x1\", \"x2\", \"y\"])\nf = sns.relplot(data = df, x = \"x1\", y = \"x2\", hue = \"y\")\n\n\n\n\n\nreload(perceptron)\np = perceptron.Perceptron()\np.fit(X, y, max_steps = 10000)\nplt.plot(p.history)\n\n\n\n\n\np.w\n\narray([2.11140182, 2.63862367, 0.39340574])\n\n\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "You can access this page using go/cs-451.\n\n\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "slides/welcome.html#section",
    "href": "slides/welcome.html#section",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Machine learning is the theory and practice of algorithmically learning patterns in data."
  },
  {
    "objectID": "slides/welcome.html#section-1",
    "href": "slides/welcome.html#section-1",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Machine learning is used for…\n…automated consumer recommendations for content and shopping."
  },
  {
    "objectID": "slides/welcome.html#section-2",
    "href": "slides/welcome.html#section-2",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Machine learning is used for…\n…generating realistic synthetic text, images, and code.\n\n\n\n\n\nAsk chatGPT to condemn itself in the tone of Shakespeare and it looks hilarious. pic.twitter.com/T785FbGmUX\n\n— Deqing Fu (@DeqingFu) December 5, 2022"
  },
  {
    "objectID": "slides/welcome.html#section-3",
    "href": "slides/welcome.html#section-3",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Machine learning is used for…\n…predictions and recommendations for life-changing decisions: housing, healthcare, criminal justice."
  },
  {
    "objectID": "slides/welcome.html#section-4",
    "href": "slides/welcome.html#section-4",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Machine learning is used for…\n…search engines, smart homes, computer vision, speech-to-text, scientific discovery, driver assistance systems…"
  },
  {
    "objectID": "slides/welcome.html#section-5",
    "href": "slides/welcome.html#section-5",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Can you list the times in which you interacted with a machine learning system yesterday?"
  },
  {
    "objectID": "slides/welcome.html#section-6",
    "href": "slides/welcome.html#section-6",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "How is this course going to go?"
  },
  {
    "objectID": "slides/welcome.html#section-7",
    "href": "slides/welcome.html#section-7",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "CSCI 0451 is….\nCoding\n\nNumerical array programming\nObject-oriented interfaces\nExperiments and visualization\n\nMath\n\nLinear algebra\nOptimization (\\(\\implies\\) calculus)\nA bit of probability\n\nReading, writing, discussion\n\nTechnical methods\nBias, fairness, and impact of ML"
  },
  {
    "objectID": "slides/welcome.html#section-8",
    "href": "slides/welcome.html#section-8",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "ML, Ethics, Bias, and Fairness\nAlgorithmic bias is the tendency of automated systems to reproduce structural privilege and oppression, especially in relation to race, gender, and sexuality.\nMost systems that impact people in any way have at least a risk of algorithmic bias. Active mitigation is usually needed.\n\n\n\n\n\nSave the Date\n\nMonday April 24th\nDr. Timnit Gebru will be virtually visiting our class for a Q&A session and giving a talk at 7pm.\nDr. Gebru is one of the world’s leading experts in intersectional bias in AI."
  },
  {
    "objectID": "slides/welcome.html#section-9",
    "href": "slides/welcome.html#section-9",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Rough, tentative plan for the semester\n\n\nFundamentals of prediction (~6 weeks)\n\nCore math concepts\nOptimization (“the algorithms”)\nHow to help models generalize\nFormal definitions of bias and fairness\n\nUnsupervised methods (~1 week)\n\nClustering\nDimensionality reduction\n\nDeep Learning (~4 weeks)\n\nImage classification\nText generation\nWord embedding\n\nProject Presentations (~1 week)"
  },
  {
    "objectID": "slides/welcome.html#section-10",
    "href": "slides/welcome.html#section-10",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Most Days\n\n\nWarmup Activity\n\nComplete ahead of time.\nReinforces content from readings and connects them to lecture.\nPresent in groups of 4-5.\nRandom presenter presents to the group.\n\nLecture\n\nMath\nLive-coding + experiments\nYour questions and ideas!\n\nClose-Out Activity\n\nIn same groups as warmup.\nPractices content from lecture, discussion"
  },
  {
    "objectID": "slides/welcome.html#section-11",
    "href": "slides/welcome.html#section-11",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Activities and assignments\n\n\nBlog Posts\n\nAim for ~1 per week.\nInvolves implementation, experiments, and discussion.\nPublished on your blog.\n\nDaily Warmup Activities\n\nRelatively quick when you’ve done the readings.\nOne (random) person each day will present to your team.\nConnects readings to lecture.\n\nProject\n\nIn groups of your choosing.\nWork on it throughout the semester, presentations in last week.\nWe’ll have activities etc. to help you pick a path."
  },
  {
    "objectID": "slides/welcome.html#section-12",
    "href": "slides/welcome.html#section-12",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Blog Posts\n\nImplement algorithms in source (.py) files.\nPerform experiments in Jupyter notebooks.\nCreate figures, add expository prose, etc.\nRender your notebooks into a blog using the Quarto publishing engine.\nHost source code and rendered blog on GitHub."
  },
  {
    "objectID": "slides/welcome.html#section-14",
    "href": "slides/welcome.html#section-14",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Feedback on blog posts via Hypothes.is"
  },
  {
    "objectID": "slides/welcome.html#section-15",
    "href": "slides/welcome.html#section-15",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Feedback on source code"
  },
  {
    "objectID": "slides/welcome.html#section-16",
    "href": "slides/welcome.html#section-16",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Readings and Warmups\nDo them! Some readings are optional.\nLet’s practice a warmup activity"
  },
  {
    "objectID": "slides/welcome.html#section-17",
    "href": "slides/welcome.html#section-17",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Your Affinity Vegetable\n \n1. Split into teams\n2. Go around and share your name and:\nIf you were a vegetable, which vegetable would you be and why?"
  },
  {
    "objectID": "slides/welcome.html#section-18",
    "href": "slides/welcome.html#section-18",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Your Affinity Vegetable\n \n3. Team leader: lead your team in finding a delicious dish that incorporates all of your vegetables.\nBe ready to share!"
  },
  {
    "objectID": "slides/welcome.html#section-19",
    "href": "slides/welcome.html#section-19",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Collaborative Grading"
  },
  {
    "objectID": "slides/welcome.html#section-20",
    "href": "slides/welcome.html#section-20",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Collaborative Grading\n\n\nInitialization:\n\n\nYou set goals for your learning and achievement (in week 2).\n\n\nMain Loop:\n\n\nYou attend class, participate in activities, and complete assignments.\n\nYou get feedback on your assignments from me and the TAs, and you revise.\nYou reflect on your learning and achievement at different points throughout the course.\n\n\nAt End Of Course:\n\n\nYou propose a letter grade that reflects your learning and achievement, and discuss it with me.\n\n\nIndividual assignments don’t get scores, points, or grades–just feedback."
  },
  {
    "objectID": "slides/welcome.html#section-21",
    "href": "slides/welcome.html#section-21",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Collaborative Grading\n \n\n\n\n\n\n\n\n\n\nOpportunity\nChallenge\n\n\n\n\nNo points, no averages\nYou can focus on feedback and set your own goals.\nYou need to motivate based on your interest in the class\n\n\nResubmit assignments\nOne of the best ways to learn\nNeed to read feedback and prioritize time for revisions\n\n\nCan skip assignments\nNo busy work – work on what’s valuable to you.\nStill need to work enough to learn and meet your goals\n\n\nNo hard due-dates\nDon’t ask for extensions, take the time you need\nNeed to keep yourself on pace to achieve your goals"
  },
  {
    "objectID": "slides/welcome.html#section-22",
    "href": "slides/welcome.html#section-22",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "What a Grade Sounds Like…\nA: I am ready to take the theory, techniques, and ideas of this course into my endeavours outside this classroom: future classes, projects, hobbies, career.\nB: With help or review, I might be able to take some of what I learned outside this classroom.\nC: I showed up and did stuff, but I don’t really see any ways to take what I learned outside this classroom.\nD-F: I didn’t really show up or do much.\n\n\nWork Expected Work Expected\nI am very likely to accept your proposed grade in the course if you EITHER:\n\nComplete most assignments to a high standard (including revisions) OR\nWork for ~10 productive hours per week outside of class OR\nDo some of the assignments I give you and also some other things (that you propose) that are relevant to the course learning goals."
  },
  {
    "objectID": "slides/welcome.html#section-23",
    "href": "slides/welcome.html#section-23",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "What is something that makes you feel excited or empowered about collaborative grading?\nWhat is something that makes you feel nervous or confused about collaborative grading?"
  },
  {
    "objectID": "slides/welcome.html#section-24",
    "href": "slides/welcome.html#section-24",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "What I expect from you now"
  },
  {
    "objectID": "slides/welcome.html#section-25",
    "href": "slides/welcome.html#section-25",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "CS Stuff\nYou can write moderately-complex, object-oriented software.\nYou are comfortable reading software documentation and researching how to perform a task that you haven’t seen before.\nYou know what a terminal is and how to perform simple operations at the command line.\nYou have experience debugging your code and you are ready to do it a lot more.\n\n\nMath Stuff\nYou remember most of MATH 0200 and CSCI 0200:\n\nMatrix multiplication and inner products\nEverything about \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\).\n\nVisualizing linear spaces.\nEigenvalues, eigenvectors, positive-definite matrices.\nDerivatives, critical points of functions.\nSample spaces, probability distribution functions.\nRandom variables, mean and variance.\nConditional probability and expectations.\n\nYou are ready to look up what you don’t remember."
  },
  {
    "objectID": "slides/welcome.html#section-26",
    "href": "slides/welcome.html#section-26",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "NYT, 1957\n \n\n\n\n\n\n\n\nWhat We Are Actually Talking About\n\n\n\n\n\n\\[\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\mathbb{1}(y_i \\langle \\mathbf{w}^{(t)}, \\mathbf{x}_i \\rangle < 0)y_i \\mathbf{x}_i\\]"
  },
  {
    "objectID": "slides/welcome.html#section-27",
    "href": "slides/welcome.html#section-27",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "NYT, 2022\n \n\n\n\n\nWhat We Are Actually Talking About\n\n\nxkcd"
  },
  {
    "objectID": "slides/welcome.html#section-28",
    "href": "slides/welcome.html#section-28",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Most of all, I expect that you are ready to make thoughtful decisions to guide your own learning in this course."
  },
  {
    "objectID": "slides/welcome.html#section-29",
    "href": "slides/welcome.html#section-29",
    "title": "Welcome to CSCI 0451!",
    "section": "",
    "text": "Based on what you know about the course so far, what are some ways that success might look like for you?"
  },
  {
    "objectID": "collaboration.html",
    "href": "collaboration.html",
    "title": "Collaboration And Academic Honesty",
    "section": "",
    "text": "This is a page of general principles and guidelines that apply in courses I (Phil Chodrow) teach at Middlebury College. It is lightly adapted from the handout “Collaborating on Mathematics” by the Harvey Mudd Department of Mathematics, which I discovered in a Tweet by Francis Su.\nIn any case in which the guidelines and principles on this page conflict with the policies of a specific course, the policies of the specific course should be followed. For example, if the course syllabus says that collaboration is not permitted on homeworks, then collaboration is not permitted on homeworks, regardless of anything written here.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "collaboration.html#why-collaborate",
    "href": "collaboration.html#why-collaborate",
    "title": "Collaboration And Academic Honesty",
    "section": "Why Collaborate?",
    "text": "Why Collaborate?\nMost scientists and engineers don’t work on their own; they work with colleagues and students while doing and publishing research. Increasingly, open problems in science and engineering require multiple skill sets and areas of expertise. Because of this, the need to collaborate will only increase in the future. This is why several of CS@Midd’s learning goals are explicitly focused on communication and collaboration. We want our students to have strong professional and communication skills, to be able to function well as part of a team, and to be able to work and communicate with diverse groups of people."
  },
  {
    "objectID": "collaboration.html#collaborating-on-homework-and-other-individually-assessed-assignments",
    "href": "collaboration.html#collaborating-on-homework-and-other-individually-assessed-assignments",
    "title": "Collaboration And Academic Honesty",
    "section": "Collaborating on Homework and Other Individually-Assessed Assignments",
    "text": "Collaborating on Homework and Other Individually-Assessed Assignments\n\n(COLLABORATION IS A LIFE SKILL) Understand that working with others and asking for assistance are not signs of weakness or deficiency; rather, they are essential life skills important for making progress in any discipline, including computer science. Our department wants you to develop these skills. If you’re too shy to come to my office hours or to join a group of people working on their homework, ask a friend to come with you.\n(COLLABORATIONS BENEFIT FROM DIVERSITY) Open yourself up to working with people whom you don’t know (yet). You might find someone you work really well with and who doesn’t think exactly like you do. A wide range of experiecnes and backgrounds is beneficial in problem solving, although it may be helpful to find folks who can work on assignments during the same time of day and at roughly the same pace. If you’re having trouble finding people to work with, I can help!\n(COLLABORATIONS ARE INCLUSIVE) Believe that everyone has something meaningful to contribute (you included), and that you have something to learn from each person. This can be a difficult state of mind to achieve, but critical for healthy, effective collaboration. Here are some practical consequences:\n\nIn any group setting, listen carefully for everyone’s contributions. Don’t dismiss or ignore what someone says, and don’t move on until you’ve considered it carefully. If what is said doesn’t make sense to you, that doesn’t necessarily mean it’s incorrect–the person might just have a way of approaching the problem that is different and not yet clear to you. Furthermore, even ideas that ultimately turn out to be incomplete or incorrect are often still useful building blocks towards a successful approach.\nFind ways to verbally validate the ideas of others. For example: “One really neat feature of Zenith’s approach to part (b) is that it also works with a small modification for part (c).”\nIf someone in the group hasn’t spoken for a while, ask for their ideas or opinions. Conversely, if you find yourself talking a lot, take a step back and allow someone else to contribute to the discussion.\n\n(COLLABORATIONS REQUIRE PREPARATION) Don’t seek help from others on a probem before you’ve had time to think about it yourself, try at least one approach, and formulate the obstacle as clearly as you can. But at the same time, if you find yourself frustrated with a problem and you’re not making progress, don’t wait too long before you look for help from your classmates, your tutors, or me.\n(COLLABORATIONS GENERATE DEEPER UNDERSTANDING) Don’t be satisfied with only producing the correct final result; use your collaboration to push each other to understand:\n\nWhy does this approach work?\nWhat alternative approaches would also have worked?\nWhat are some of the merits and drawbacks of these different approaches?\n\n(COLLABORATIONS ARE EMPOWERING) Good collaborations empower people towards further growth.\n\nWhen you’re working on a problem with others and you find a path before everyone else, avoid ruining the experience of discovery for others. Conversely, if you haven’t figured out something yet and want to enjoy the discovery for yourself, don’t let someone else ruin your joy.\nIf someone asks you for help, don’t just tell them the answer or start showing them a solution method. Listen carefully to their question. Ask for more information if they aren’t being specific enough. If they say “I don’t know where to start,” ask them to tell you about their understanding of what the question is asking and which parts of it seem most puzzling. Ask guiding questions to help them discover ideas for themselves. In these situations, you have the opportunity to learn how to help others learn – this is an invaluable life skill.\n\n(COLLABORATIONS ACKNOWLEDGE CONTRIBUTORS) Whenever you’ve received help on a homework assignment from a classmate, a friend, a tutor, or me, acknowledge the support and briefly describe how it helped you in your assignment.\n\nThe reason I ask you to acknowledge tutors and myself is actually different from the reason I ask you to acknowledge classmates and friends. For classmates and friends, it’s about cultivating transparency and integrity. The primary reason I want you to acknowledge tutors and myself is that the exercise of explicitly remembering and reflecting on your learning journey is part of metacognition, a valuable set of practices that will help you succeed in this class, in college, and in your long-term career."
  },
  {
    "objectID": "collaboration.html#collaborating-on-group-projects",
    "href": "collaboration.html#collaborating-on-group-projects",
    "title": "Collaboration And Academic Honesty",
    "section": "Collaborating on Group Projects",
    "text": "Collaborating on Group Projects\n\n(COLLABORATIONS SET GOOD EXPECTATIONS) Establish clear expectations and ways of communicating with each other to avoid misunderstandings. When, where, and how often will you meet? How can you reach each other in case of an emergency?\n(COLLABORATION IS NOT DIVISION OF LABOR) Collaboration is not the same as splitting up a problem into pieces and then slapping the completed pieces together.\n\nIdentify the parts of the problem that need to be completed together and the parts that can be completed individually.\nWork toward a final product that everyone is happy with and that represents the contributions of everyone on the group.\nDon’t just divide up the work based on who might have the most experience or skill with each part of the problem. Let those who want to develop their skills also have a chance to work on pieces that are unfamiliar to them\n\n(COLLABORATIONS ARE EQUITABLE) Aim for each person to contribute a fair and equitable amount of effort and/or time to the group’s deliverables.\n(COLLABORATIONS RESOLVE CONFLICT QUICKLY) Resolve any misunderstands between the team members quickly. Don’t let those misunderstandings fester into distrust, resentment, or anger. Don’t be afraid to ask your professor for help in resolving interpersonal conflict in your team. While this can feel uncomfortable, often these kinds of situations are important opportunities for everyone to learn more about how to coexist as collaborative, whole humans."
  },
  {
    "objectID": "collaboration.html#collaboration-is-a-skill",
    "href": "collaboration.html#collaboration-is-a-skill",
    "title": "Collaboration And Academic Honesty",
    "section": "Collaboration is a Skill",
    "text": "Collaboration is a Skill\nYou might imagine that you already know whether you need to collaborate and how to do it. And indeed, there’s a lot you know already! But collaboration is a skill, and like other skills it rewards practice and growth. Effective collaboration involves perspective-taking, empathy, respect, and clear communication. We hope that you will find that the benefits of collaboration far outweigh its challenges."
  },
  {
    "objectID": "collaboration.html#collaboration-and-the-middlebury-honor-code",
    "href": "collaboration.html#collaboration-and-the-middlebury-honor-code",
    "title": "Collaboration And Academic Honesty",
    "section": "Collaboration and the Middlebury Honor Code",
    "text": "Collaboration and the Middlebury Honor Code\nThe Middlebury Honor Code’s preamble states that:\n\nThe students of Middlebury College believe that individual undergraduates must assume responsibility for their own integrity on all assigned academic work…The Middlebury student body, then, declares its commitment to an honor system that fosters moral growth and to a code that will not tolerate academic dishonesty in the College community.\n\nIn any assignment in which you receive a grade individually (homeworks, exams), the purpose of the grade is to measure your learning and achievement. When you turn in such an assignment, you implicitly represent that work as work that you are able to complete yourself under the stated conditions (which may include getting help or working with others). If you cannot complete some work under the stated collaboration conditions, it is dishonest to turn in that work.\nWhen working individually, it is your responsibility to uphold the Code’s standards of integrity and academic honesty. When working in a group, it is additionally your responsibility to ensure that your group as a whole upholds these standards.\nIf you have a question about whether some form of collaboration is permitted, just ask!\n\nWhat Happens if I Observe an Honor Violation?\n\nWe all fail to uphold our highest moral aspirations at times. If you show lack of integrity or academic honesty, that doesn’t mean you’re a bad person. It means that you’re under pressure and chose the course of action that looked like the most workable one to you at the time.\nThat said, if you show lack of integrity or academic honesty, that’s an indicator that you have an opportunity for some very important growth.\nIt is part of my job to help you achieve that growth. I take this part of my job very seriously. In order to help you on your journey, I will connect both of us with the Middlebury Community Standards Office. Office leadership will help us all find a path that helps you grow toward integrity and honesty.\nThis is an awkward and uncomfortable process for everyone involved. You don’t want this."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software and Setup",
    "section": "",
    "text": "After following this set of instructions, you will be all ready to go for participation in CSCI 0451.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "software.html#install-anaconda",
    "href": "software.html#install-anaconda",
    "title": "Software and Setup",
    "section": "1. Install Anaconda",
    "text": "1. Install Anaconda\nInstall and configure Anaconda Python by following these instructions. Choose the installer appropriate for your operating system."
  },
  {
    "objectID": "software.html#create-the-ml-0451-environment",
    "href": "software.html#create-the-ml-0451-environment",
    "title": "Software and Setup",
    "section": "2. Create the ml-0451 Environment",
    "text": "2. Create the ml-0451 Environment\n\n\n\nThe Environments tab, with the Create button on the bottom.\nAn environment is a separate installation of Python that exists independently of any other versions of Python on your computer. Using environments allows us to have fine-grained control over which version of Python we use, which additional packages are installed, etc.\nTo create an environment in Anaconda, first open the Anaconda Navigator program. Then, navigate to the Environments tab. There, you’ll find the current existing environments, including the default base(root) environment. Click the Create button to create a new environment.\nIn the resulting dialog box:\n\nName your environmnent ml-0451.\nEnsure that the installed Python is some version of Python 3.9 (it’s ok if your version number differs in the last two digits from the one shown in the example).\n\n\n\n Configuring the ml-0451 environment."
  },
  {
    "objectID": "software.html#install-packages",
    "href": "software.html#install-packages",
    "title": "Software and Setup",
    "section": "Install Packages",
    "text": "Install Packages\nYou will need to install several packages to the ml-0451 environment. Note that you need to do this even if you previously installed these packages to another version of Python on your laptop.\nTo add packages to the environment, first ensure that the environment is selected (it will be highlighted in green). Then, on the righthand menu, search for the package you want to install. You may need to change the box on the top left from “Installed” to “Not Installed” in order to view packages that you have not installed yet.\n\nInstall the following packages:\n\nnb_conda\nnumpy\nmatplotlib\npandas\nscikit-learn\nseaborn\n\nI may ask you to install additional packages later on, or you may find it useful to install packages yourself in order to deal with problems or projects. You’ll follow this same process to install them to the ml-0451 environment."
  },
  {
    "objectID": "software.html#launch-jupyterlab",
    "href": "software.html#launch-jupyterlab",
    "title": "Software and Setup",
    "section": "Launch JupyterLab",
    "text": "Launch JupyterLab\nNow back on the Home tab, launch the JupyterLab app. You may need to install it first. Create a notebook using the ml-0451 environment as a kernel.\n\n\n Creating a notebook using the ml-0451 environment as the kernel.\nNext, type the following code into the grey code cell that appears in the notebook:\nimport sklearn as sk\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nprint(\"I did it!\")\nFinally, run the cell (cmd + enter on Mac or ctrl + enter on Windows). If you get no errors, only the output of the print statement, then you did it!\n\n\n If you see this then you did it!"
  },
  {
    "objectID": "software.html#alternative-vscode-and-others",
    "href": "software.html#alternative-vscode-and-others",
    "title": "Software and Setup",
    "section": "Alternative: VSCode and Others",
    "text": "Alternative: VSCode and Others\nJupyterLab is probably the easiest way for you to get up and coding. The reason is that it supports two ways of working with Python:\n\nNotebooks, which allow us to combine code, text, and outputs, including data visualizations.\nText files, like .py files, which are best for holding complex, reusable source code.\n\nThere are other editors that support these as well. My personal favorite is Visual Studio Code (often called VSCode), and you’re likely to see me using it in class. It’s fine for you to use VSCode or any other editor, but please note that I’ll only troubleshoot Anaconda + JupyterLab. That is, you can use VSCode, but you’ll be “on your own” in terms of getting up and running. That said, the documentation on working with notebooks in VSCode is pretty good."
  },
  {
    "objectID": "software.html#optional-github-desktop",
    "href": "software.html#optional-github-desktop",
    "title": "Software and Setup",
    "section": "Optional: GitHub Desktop",
    "text": "Optional: GitHub Desktop\nIf you are comfortable working with git from the command line, you can continue to do this! If you are unfamiliar with git, I recommend that you download and install the GitHub Desktop graphical client. You will need to connect it to your GitHub account."
  },
  {
    "objectID": "software.html#clone-your-blog",
    "href": "software.html#clone-your-blog",
    "title": "Software and Setup",
    "section": "Clone your blog",
    "text": "Clone your blog\nFinally, clone your blog to your local computer in a place where you’ll be able to find it in the future. You can do this using the big green “Clone” button on GitHub. You can clone either using GitHub Desktop or at the command line: both options are good!\n\nWhat if I already have a GitHub Pages site?\nGreat! You can publish your blog as a project website rather than as a user site. Find out more on the difference and how to publish a project website."
  },
  {
    "objectID": "software.html#test-drive-quarto",
    "href": "software.html#test-drive-quarto",
    "title": "Software and Setup",
    "section": "Test Drive Quarto",
    "text": "Test Drive Quarto\nChange modify the About page of your blog by modifying the file about.qmd. You can do things like change text or change the profile picture (it doesn’t have to be of yourself). Once you’ve made these changes, open a terminal in the location of your cloned blog and type the command\nquarto preview\nAfter a few moments, a web browser window should pop up with a preview of your blog. If you navigate over to the About tab, you should see your changes."
  },
  {
    "objectID": "software.html#finalize-and-publish",
    "href": "software.html#finalize-and-publish",
    "title": "Software and Setup",
    "section": "Finalize and Publish",
    "text": "Finalize and Publish\nIn the terminal, use ctrl + c to stop the preview process. Then type the command\nquarto render\nThis time you won’t see a preview, but that’s ok! Over in git or GitHub Desktop, check all the new and modified files that have been generated, add a short message, and commit them to the main branch. Then, push your commit. This sends your files back to GitHub.com, where it will be published. After a minute or two, navigate back over to the URL housing your website and check that your changes have been made."
  },
  {
    "objectID": "warmup-exercises.html",
    "href": "warmup-exercises.html",
    "title": "Warmup Exercises",
    "section": "",
    "text": "\\[\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\vx}{\\mathbf{x}}\n\\newcommand{\\vw}{\\mathbf{w}}\n\\newcommand{\\vz}{\\mathbf{z}}\n\\newcommand{\\norm}[1]{\\lVert #1 \\rVert}\n\\newcommand{\\bracket}[1]{\\langle #1 \\rangle}\n\\newcommand{\\abs}[1]{\\lvert #1 \\rvert}\n\\newcommand{\\paren}[1]{\\left( #1 \\right)}\n\\]\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "warmup-exercises.html#sec-perceptron",
    "href": "warmup-exercises.html#sec-perceptron",
    "title": "Warmup Exercises",
    "section": "Perceptron",
    "text": "Perceptron\n\nPart 1\nSketch the line in \\(\\R^2\\) described by the equation\n\\[\n\\bracket{\\vw, \\vx}  =  b\\;,\n\\tag{1}\\]\nwhere \\(\\vw = \\paren{1, -\\frac{1}{2}}^T \\in \\R^2\\) and \\(b = \\frac{1}{2}\\). Here, \\(\\bracket{\\vw, \\vx} = \\sum_{i = 1}^n w_i x_i\\) is the inner product (or dot product) between the vectors \\(\\vw\\) and \\(\\vw\\).\n\n\nPart 2\nWrite a quick Python function called perceptron_classify(w, b, x). w and x should both be 1d numpy arrays of the same length, and b should be a scalar. Your function should return 0 if \\(\\bracket{\\vw, \\vx} < b\\) and 1 if \\(\\bracket{\\vw, \\vx} \\geq b\\). An excellent solution will use neither a for-loop nor an if-statement.\nVerify that your function works on a few simple examples.\n\n\nPart 3\nConsider a line of the general form of Equation 1. Let’s allow \\(\\vx\\) and \\(\\vw\\) to both be \\(n\\)-dimensional, so that this equation defines a hyperplane in \\(\\R^n\\). Suppose that we wanted to represent the same hyperplane in \\(\\R^n\\) using an equation of the form\n\\[\n\\bracket{\\tilde{\\vw}, \\tilde{\\vx}} = 0\\;.\n\\tag{2}\\]\nfor some \\(\\tilde{\\vw} \\in \\R^{n+1}\\). Define \\(\\tilde{\\vx} = (\\vx, 1)\\). How could you define \\(\\tilde{\\vw}\\) to make Equation 2 equivalent to Equation 1?"
  },
  {
    "objectID": "warmup-exercises.html#sec-convexity",
    "href": "warmup-exercises.html#sec-convexity",
    "title": "Warmup Exercises",
    "section": "Convexity",
    "text": "Convexity\nAs you learned in Daumé, informally, a convex function is a function that is “bowl-shaped.” Hardt and Recht give the formal definition, which has the benefit of applying to functions of many variables.\n\nPart 1\nConsider the 0-1 step function that I’ve plotted below:\n\nfrom matplotlib import pyplot as plt \nimport numpy as np\n\nfig, ax = plt.subplots(1, 1) \ny_hat = np.linspace(-1, 1, 101)\n\nloss = lambda y_hat, y: 1 - 1*(y_hat*y > 0)\n\nax.set(xlabel = r\"$\\hat{y}$\", \n       ylabel = r\"$\\ell(\\hat{y}, y)$\")\n\nax.plot(y_hat, loss(y_hat, 1))\n\n\n\n\nShow pictorially that this function is not convex. No proof needed – just the right drawing.\n\n\nPart 2: Second Derivative Test\nAnother way to tell whether a function is convex is to check its second derivative. If a function \\(f:S\\rightarrow \\R\\) has a convex domain \\(S\\subseteq \\R\\), if \\(f\\) is everywhere twice-differentiable, and if \\(\\frac{d^2f(z_0)}{dz^2} > 0\\) for all \\(z_0 \\in S\\), then \\(f\\) is convex.\nUse the second derivative test to check that the following two functions are convex: The base of the logarithm doesn’t really matter, but for this course it is always most convenient to assume logs base \\(e\\), which you might also have seen written \\(\\ln\\).\n\\[\n\\begin{aligned}\nf(z) &= - \\log z \\\\\ng(z) &= - \\log(1-z)\\;.\n\\end{aligned}\n\\]\n\n\nPart 3: Plotting Practice\nIn a Jupyter notebook, write a simple program to plot each of the functions \\(f\\) and \\(g\\) from Part 2. Some of the Part 1 code is likely to help you.\n\n\nPart 4: Convexity in Many Variables\nRecall the Hardt and Recht definition of convexity: a function \\(f:\\R^p \\rightarrow \\R\\) is convex if, for any \\(\\lambda \\in [0,1]\\) and any points \\(\\vz_1, \\vz_2 \\in \\R^p\\),\n\\[\nf(\\lambda \\vz_1 + (1-\\lambda)\\vz_2) \\leq \\lambda f(\\vz_1) + (1-\\lambda)f(\\vz_2)\\;.\n\\]\nUsing this definition, write a short mathematical proof that the function \\(f(\\vz) = \\norm{\\vz} = \\sqrt{\\bracket{\\vz, \\vz}}\\) is convex. You will want to use the triangle inequality, which says that \\(\\norm{\\vz_1 + \\vz_2} \\leq \\norm{\\vz_1} + \\norm{\\vz_2}\\). This proof requires just a few lines if you carefully use your definitions!"
  },
  {
    "objectID": "warmup-exercises.html#sec-gradient-descent",
    "href": "warmup-exercises.html#sec-gradient-descent",
    "title": "Warmup Exercises",
    "section": "Gradient Descent",
    "text": "Gradient Descent\nConsider the quadratic function \\(g(z) = \\frac{1}{2}az^2 + bz + c\\).\n\nProve that \\(g\\) has a critical point at the point \\(z^* = -\\frac{b}{a}\\) (hint: solve \\(g'(z^*) = 0\\)).\nWhat must be true about the constants \\(a\\), \\(b\\), and \\(c\\) to ensure that this point is a local minimum of \\(g\\)? (Hint: second derivative test).\nSuppose now that we are able to evaluate the function \\(g\\), as well as its derivative \\(g'\\), but not able to use algebra to find \\(z^*\\) (this mirrors our situation in most practical problems). Instead, we are going to use the following algorithm to attempt to approximate \\(z^*\\):\n\nBegin with some initial guess \\(z^{(0)}\\).\nIn each time-step \\(t\\), compute \\(z^{(t+1)} \\gets z^{(t)} - \\alpha g'(z^{(t)})\\), where \\(\\alpha > 0\\) is the learning rate.\nIn practice we would need to specify a stopping criterion, but for this theoretical problem we don’t need to worry about it.\n\nUsing algebra, prove that for any timestep \\(t\\),\n\n\\[\n(z^* - z^{(t+1)})^2 = (a\\alpha - 1)^2(z^* - z^{(t)})^2\\;.\n\\]\n\nLet’s think \\(\\abs{z^* - z^{(t)}}\\) as the error in our current estimate \\(z^{(t)}\\). Using the recurrence above, conclude that, for any \\(t\\), the error \\(\\abs{z^* - z^{(t)}}\\) satisfies\n\n\\[\n\\abs{z^* - z^{(t)}} = \\abs{a\\alpha - 1}^{t}\\abs{z^* - z^{(0)}}\\;.\n\\]\n\nFor \\(\\alpha \\in (\\alpha_*, \\alpha^*)\\), we are guaranteed that the error \\(\\abs{z^* - z^{(t)}}\\rightarrow 0\\) as \\(t\\rightarrow \\infty\\). What are \\(\\alpha_*\\) and \\(\\alpha^*\\)?\n\nSuppose that \\(\\alpha\\) is within the necessary range. I want to guarantee that \\(\\abs{z^* - z^{(t)}} < \\epsilon\\) for some small \\(\\epsilon < 0\\) (in practice we often call this the tolerance). Conclude that the number of steps necessary to reach this tolerance is no greater than\n\n\\[\n\\bar{t} = \\frac{\\log \\abs{a\\alpha - 1} + \\log \\abs{z^* - z^{(0)}}}{\\log \\epsilon}\\;.\n\\]\nIgnoring stuff in the numerator, we say that this algorithm for finding the minimum of \\(g\\) with tolerance \\(\\epsilon\\) has a \\(\\frac{1}{\\log \\epsilon}\\) a convergence rate."
  },
  {
    "objectID": "warmup-exercises.html#sec-erm",
    "href": "warmup-exercises.html#sec-erm",
    "title": "Warmup Exercises",
    "section": "The Coin-Flipping Game",
    "text": "The Coin-Flipping Game\nLet’s play a game! Here is the setup:\nI have a coin with probability of heads equal to \\(p \\in [0,1]\\). I am going to ask you to pick a number \\(\\hat{p} \\in [0,1]\\). Then, I flip my coin.\nThis game is more fun for me than it is for you.\n\nIf my coin comes up heads, you give me \\(-\\log \\hat{p}\\) dollars.\nIf my coin comes up tails, you give me \\(-\\log (1-\\hat{p})\\) dollars.\n\n\nPart 1\nCompute the expected amount of money you will give me when we play this game in terms of \\(p\\) and \\(\\hat{p}\\). Call this quantity \\(R(\\hat{p}, p)\\). This is the risk of the guess \\(\\hat{p}\\).\n\n\nPart 2\nTake the derivative and set it equal to 0! Don’t forget to check that you’ve found a minimum of \\(R(\\hat{p}, p)\\) rather than a maximum or an inflection point.\nSuppose I tell you the value of \\(p\\). Write a mathematical proof to show that your best choice of \\(\\hat{p}\\) (the one that loses you the least money) is \\(\\hat{p} = p\\).\n\n\nPart 3\nNow suppose that I don’t tell you the true value of \\(p\\). Instead, I let you observe \\(n\\) coin flips before asking you to make your guess. Describe:\n\nA suggestion for choosing \\(\\hat{p}\\) based only on the results of the previous flips.\nA way to estimate the risk (expected amount of money lost) based only on the results of the previous flips.\n\nYour answer should depend on \\(\\hat{p}\\) but not on \\(p\\)!"
  },
  {
    "objectID": "warmup-exercises.html#sec-classification-rates",
    "href": "warmup-exercises.html#sec-classification-rates",
    "title": "Warmup Exercises",
    "section": "Classification Rates",
    "text": "Classification Rates\n\nPart 1\nCOVID-19 rapid tests have approximately an 80% sensitivity rate, which means that, in an individual who truly has COVID-19, the probability of a rapid test giving a positive result is roughly 80%.  On the other hand, the probability of a rapid test giving a positive result for an individual who truly does not have COVID-19 is 5%. Suppose that approximately 4% of the population are currently infected with COVID-19. These numbers are mostly made-up.Example 2.3.1 of Murphy, page 46, has a good review of the relevant probability and the definition of each of the rates below.\nWrite a Python function called rate_summary that prints the following output, filling in the correct values for each of the specified rates:\ns = 0.8           # test sensitivity\nf = 0.02          # probability of positive test if no COVID\nprevalence = 0.05 # fraction of population infected\n\nrate_summary(s, f, current_infection)\nThe true positive rate is ___.\nThe false positive rate is ___.\nThe true negative rate is ___. \nThe false positive rate is ___. \n\n\nPart 2\n\nSuppose that scientists found an alternative rapid test which had a 75% sensitivity rate with a 0% chance of a positive test on someone who is truly not infected. Would you suggest replacing the old rapid tests with these alternative tests? Why? \nWhat if the alternative test had an 85% sensitivity rate and a 10% chance of a positive test on someone who is truly not infected?\n\nYou don’t necessarily need to use your function from the previous part in this part.\n\nPart 3\nIt’s all well and good to do the math, but what about when we actually have data? Write a function called rate_summary_2 that accepts two columns of a pandas.DataFrame (or equivalently two one-dimensional numpy.arrays of equal length). Call these y and y_pred. Assume that both y and y_pred are binary arrays (i.e. arrays of 0s and 1s). y represents the true outcome, whereas y_pred represents the prediction from an algorithm or test. Here’s an example of the kind of data we are thinking about:\n\nimport pandas as pd\n\nurl = \"https://github.com/middlebury-csci-0451/CSCI-0451/raw/main/data/toy-classification-data.csv\"\ndf = pd.read_csv(url)\n\ndf.head() # just for visualizing the first few rows\n\n\n\n\n\n  \n    \n      \n      y\n      y_pred\n    \n  \n  \n    \n      0\n      0\n      0\n    \n    \n      1\n      1\n      0\n    \n    \n      2\n      1\n      0\n    \n    \n      3\n      0\n      1\n    \n    \n      4\n      0\n      0\n    \n  \n\n\n\n\nYou should be able to use your function like this:\n# y is the true label, y_pred is the prediction\nrate_summary_2(df[\"y\"], df[\"y_pred\"]) \nThe true positive rate is ___.\nThe false positive rate is ___.\nThe true negative rate is ___. \nThe false positive rate is ___. \n\nHints\nAn excellent solution for this part will not use any for-loops. Computing each of the four rates can be performed in a single compact line of code. To begin thinking of how you might do this, you may want to experiment with code like the following:\ndf[[\"y\"]] == df[[\"y_pred\"]]\ndf[[\"y\"]].sum(), df[[\"y\"]].sum()"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This is an advanced elective on the topic of algorithms that learn patterns from data. Artificial intelligence, predictive analytics, computational science, pattern recognition, signal processing, and data science are all disciplines that draw heavily on techniques from machine learning.\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "syllabus.html#social-annotation",
    "href": "syllabus.html#social-annotation",
    "title": "Syllabus",
    "section": "Social Annotation",
    "text": "Social Annotation\nA an extremely useful way for you to engage with the readings is to make comments, ask questions, and answer questions about them as you are reading. For this reason, I’ll be providing most links to readings through Hypothes.is. You’ll be able to make marginal comments and view the marginal comments of others. I’ll also regularly be checking on your annotations to see what questions might have come up with the readings."
  },
  {
    "objectID": "syllabus.html#what-will-class-time-look-like",
    "href": "syllabus.html#what-will-class-time-look-like",
    "title": "Syllabus",
    "section": "What Will Class Time Look Like?",
    "text": "What Will Class Time Look Like?\nMy plan is for most class periods to look like a “lecture sandwich:”\n\n10 to 15 minutes of a warmup activity that addresses the recent lectures and readings.\n40-50 minutes of lecture, punctuated by short activities and breaks.\n10-15 minutes of a closing activity that helps us get solid with the day’s content.\n\n\nThe Warmup Activity\nOn most days, we’ll have a warmup activity. The warmup activity will usually ask you to engage with the readings and complete a small amount of work ahead of class time. This could be a short piece of writing, a math problem, or an implementation of a Python function.\nEach day, a few students will be randomly selected to present their work to a small group of peers. It’s ok to ask for help or even pass if you’re not feeling confident in your solution, but you should plan to at least make a good attempt at the warmup before every class period. Your participation on the warmup activity is an important aspect of presence in the course, and I’ll ask you to reflect on it when proposing your course grade."
  },
  {
    "objectID": "syllabus.html#collaborative-grading",
    "href": "syllabus.html#collaborative-grading",
    "title": "Syllabus",
    "section": "Collaborative Grading",
    "text": "Collaborative Grading\nThis course is collaboratively graded.  In a nutshell, this means:You may have also heard the term ungrading to refer to a similar approach.\n\nThere are no points or scores attached to any assignment. When you turn in assignments, you’ll get feedback on how to revise/resubmit, improve or otherwise proceed in the course, but you won’t get “graded.”\nThere also aren’t any firm due dates, although I will give you suggestions on how to maintain a good pace. \nPeriodically throughout the semester, you will complete reflection activities to help you take stock of your learning and achievement in the course. In your final activity at the end of the semester, you’ll make a proposal for your letter grade in the course, and support it with evidence of your learning. You and I will then meet to discuss how the course went for you, using your reflection activity and proposal as a starting point. In this conversation, you and I will agree on your final letter grade for the course, which I will then submit to the registrar.\n\nAll work you wish to be considered toward your achievement in the course needs to be submitted by the end of Finals Week.Reflection activities:\n\nReflective goal-setting.\nMid-course reflection.\nEnd-of-course reflection and grade proposal."
  },
  {
    "objectID": "syllabus.html#why-collaborative-grading",
    "href": "syllabus.html#why-collaborative-grading",
    "title": "Syllabus",
    "section": "Why Collaborative Grading?",
    "text": "Why Collaborative Grading?\nBecause grading is broken! Traditional points-based grading is ineffective at both (a) accurately measuring student learning and (b) motivating students to learn. I broadly agree with Jesse Stommel when he writes:\n\nAgency, dialogue, self-actualization, and social justice are not possible in a hierarchical system that pits teachers against students and encourages competition by ranking students against one another. Grades (and institutional rankings) are currency for a capitalist system that reduces teaching and learning to a mere transaction. Grading is a massive co-ordinated effort to take humans out of the educational process.\n\nI’d prefer to just not give you grades at all. But, Middlebury says I have to, and so my aim is to instead put the process of grading under your control to the greatest extent that I reasonably can."
  },
  {
    "objectID": "syllabus.html#assignments",
    "href": "syllabus.html#assignments",
    "title": "Syllabus",
    "section": "Assignments",
    "text": "Assignments\nThere are three kinds of assessed assignments in this course, plus a mysterious “Other” category.\n\n\n\n\n\nBlog Posts\n\n\n\nBlog posts are the primary way in which you will demonstrate your understanding of course content. Blog posts usually involve: written explanation of some relevant theory; implementation one or more algorithms according to written specifications; performing experiments to test the performance of the implementations; and communicating findings in a professional way. Some blog posts will be more like short essays than problem sets or programming assignments. Your blog posts will be hosted on your own public website (which you will create). This website will serve as your portfolio for the course.\n\n\n\n\n\n\nProject\n\n\n\nYour project is a large-scale undertaking that you will design and complete, usually in a group of 2 or 3, over the course of the semester. Your project should usually involve some combination of data collection, implementation, research of related work, experimentation, deployment, or theory work (but not necessarily all components). Projects are expected to demonstrate deep engagement with both the course content and the problem selected.\n\n\n\n\n\nProcess Reflections\n\n\n\nAt the beginning of the course, you’ll write a process reflection describing your aspirations for the course—what you want to learn and achieve, and how you’d like to be assessed against your goals. We’ll have a second process reflection mid-way through the course that will allow you to reflect on your progress toward your objectives and consider changing direction if needed. At the end of the course, you’ll write a summary reflection on your learning, accomplishment, and engagement with the class. This is also the place where you’ll propose your final letter grade.   I’ll usually give you written feedback on your process reflections. We’ll also meet at the end of the course to discuss your final reflection and agree on your letter grade for the course.\n\n\n\n\n\nOther…?\n\n\n\nYou may have some topic or idea that especially interests you and which you want to explore. If you’d like to work on this topic and use it to demonstrate your learning in the course, you can propose it to me. I may have suggestions or requested modifications before I agree to count the work in your course portfolio."
  },
  {
    "objectID": "syllabus.html#best-by-dates",
    "href": "syllabus.html#best-by-dates",
    "title": "Syllabus",
    "section": "Best-By Dates",
    "text": "Best-By Dates\nWhile we don’t have formal due dates, there is a benefit to keeping yourself on a schedule. It’s best to complete assignments close to the time when we covered the corresponding content in class, and it’s important for your wellbeing not to let work pile up. I’ll provide “best-by” dates for all assignments. These are my recommendations for when you should submit the first versions of these assignments to me for feedback.\n\n\n Image credit: Dr. Spencer Bagley"
  },
  {
    "objectID": "syllabus.html#feedback",
    "href": "syllabus.html#feedback",
    "title": "Syllabus",
    "section": "Feedback",
    "text": "Feedback\nI won’t “grade” your individual assignments, but our course team and I will offer you feedback about what I thought was successful and where you can improve. My general expectation is that you will often (though not always) revise your work in response to feedback and resubmit it. Revising in response to feedback is one of the single most effective ways for you to deepen your learning.\nI’ll usually describe the importance of revisions on your assignment using one of the following categories:\n\nNo revisions suggested: you’ve done great work and should focus on the next thing.\nRevisions useful: you have opportunities for improvement on this assignment, but focusing on the next topic or assignment may be a better use of your time—use your judgment.\n\nRevisions encouraged: the best use of your time is to respond to feedback and resubmit, rather than moving on to the next assignment.\nIncomplete: the assignment isn’t sufficiently complete for it to be used as evidence of your learning."
  },
  {
    "objectID": "syllabus.html#what-work-do-you-need-to-do",
    "href": "syllabus.html#what-work-do-you-need-to-do",
    "title": "Syllabus",
    "section": "What Work Do You Need To Do?",
    "text": "What Work Do You Need To Do?\nAt the beginning of the semester, you’ll write a process letter that will outline what you’d like to learn and achieve in the course. It’s ok if you don’t meet all your aspirations by the end of the course. To help guide you in your goal-setting and work-planning, I do have some general expectations.\nI am likely to consider your time in my course to be highly successful if you do at least one of the following things:\nTime spent being stuck doesn’t count as “productive hours” – get help if you need it!\n\nYou complete almost all assignments with a high degree of quality, including revising in response to my feedback.\nYou spend on average 10 productive hours of work time on this course outside of class.\nYou complete many assignments that I give you, and also propose and complete alternative work that demonstrates your learning and achievement."
  },
  {
    "objectID": "syllabus.html#directing-your-learning",
    "href": "syllabus.html#directing-your-learning",
    "title": "Syllabus",
    "section": "Directing Your Learning",
    "text": "Directing Your Learning\nThis course asks you to set your own goals and motivate yourself to achieve them. Neither of these tasks are easy. It’s ok to mess up every now and then – we all do! The real question is whether you’re going to look at mistakes and make time to reflect on what to do next time."
  },
  {
    "objectID": "syllabus.html#programming",
    "href": "syllabus.html#programming",
    "title": "Syllabus",
    "section": "Programming",
    "text": "Programming\n\nYou can write moderately-complex, object-oriented software.\nYou are comfortable reading software documentation and researching how to perform a task that you haven’t seen before.\nYou know what a terminal is and how to perform simple operations at the command line.\nYou have experience debugging your code and you are ready to do it a lot more."
  },
  {
    "objectID": "syllabus.html#math",
    "href": "syllabus.html#math",
    "title": "Syllabus",
    "section": "Math",
    "text": "Math\nI am assuming that you remember most of MATH 0200 and CSCI 0200. It’s ok if you haven’t memorized every single fact. What I need is for you to be ready to rapidly look up what you need so that you won’t be slowed down by math along the way.\n\nMatrix multiplication and inner products\nEverything about \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\).\n\nVisualizing linear spaces.\nEigenvalues, eigenvectors, positive-definite matrices.\nDerivatives, critical points of functions.\nSample spaces, probability distribution functions.\nRandom variables, mean and variance.\nConditional probability and expectations.\n\n\nReviews/Diagnostics\n\nThis resource from Stanford’s CS246 contains most of the linear algebra that you’ll need for the course. The only big topic that’s missing is treatment of the existence of solutions of the linear system \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) in terms of the rank of \\(\\mathbf{A}\\). You don’t need to have memorized everything here, but most of it should look familiar.\nProbability is not a formal requirement for CSCI 0451, but some probability can certainly be useful. To brush up on some basics, I suggest Chapter 2 of Introduction to Probability for Data Science by Stanley Chan. This treatment may be a little more advanced than what you learned in CSCI 0200, but you should recognize many of the main ideas."
  },
  {
    "objectID": "syllabus.html#covid-19-considerations",
    "href": "syllabus.html#covid-19-considerations",
    "title": "Syllabus",
    "section": "COVID-19 Considerations",
    "text": "COVID-19 Considerations\n\nMasks Are Required in CSCI 0451\nThe Computer Science Department policy states that:\n\nWe in the Computer Science department value a safe learning and working environment for all. While we can’t eliminate the risks associated with COVID-19, evidence suggests that widespread masking can significantly reduce the transmission and severity of disease. In order to protect the health of our community, the CS department recommends that students and faculty wear masks in CS learning spaces, including classrooms, office hours, and public areas. We acknowledge the College policy gives instructors the final say over classroom masking requirements, and expect all students to respect instructors’ stated policies in each course.\n\nIn alignment with this policy, I require you to wear masks in class and office hours. I encourage you to wear masks during help sessions and at all other times when you are inside 75 Shannon Street.\nIf you arrive in class without a mask, I will offer you one. I will expect you to either wear it or excuse yourself from class that day."
  },
  {
    "objectID": "syllabus.html#academic-integrity-and-collaboration",
    "href": "syllabus.html#academic-integrity-and-collaboration",
    "title": "Syllabus",
    "section": "Academic Integrity and Collaboration",
    "text": "Academic Integrity and Collaboration\n\nAcademic Integrity\nBriefly, academic integrity means that you assume responsibility for ensuring that the work you submit demonstrates your learning and understanding.\nTo be frank, it’s pretty easy to act without integrity (i.e. cheat) in this course. First, there’s a lot of solution code for machine learning tasks in Python online. Second, I’m literally asking you all to post your assignments publicly online. So, there are lots of opportunities to turn in assignments without actually doing the learning that those assignments are designed to offer you.\nI assume that both of us want you to learn some cool stuff. Cheating stops you from doing that, and ultimately wastes both your time and mine. I won’t be vigorously hunting for academic integrity violations, but I may ask you to discuss code or theory with me in class or in our meetings. If I notice you struggling to explain code that you submitted for feedback, I may have questions.\nTrust me. Neither of us want this."
  },
  {
    "objectID": "syllabus.html#collaboration",
    "href": "syllabus.html#collaboration",
    "title": "Syllabus",
    "section": "Collaboration",
    "text": "Collaboration\nI love it! Please collaborate in ways that allow you and your collaboration partners to fully learn from and engage with the content. Sharing small snippets of code or math is often helpful to get someone unstuck, but sharing complete function implementations or mathematical arguments is usually counterproductive.\nHere are some general guidelines for how I think about collaboration."
  },
  {
    "objectID": "syllabus.html#general-advice",
    "href": "syllabus.html#general-advice",
    "title": "Syllabus",
    "section": "General Advice",
    "text": "General Advice\nI am always happy to talk with you about your future plans, including internships, research opportunities, and graduate school applications. Because I am a creature of the academy, I am less knowledgeable about industry jobs, although you are welcome to ask about those too. You can drop in during Student Hours or email me to make an appointment."
  },
  {
    "objectID": "syllabus.html#letters-of-recommendation",
    "href": "syllabus.html#letters-of-recommendation",
    "title": "Syllabus",
    "section": "Letters of Recommendation",
    "text": "Letters of Recommendation\nWriting letters of recommendation for students is a fundamental part of my job and something that I am usually very happy to do. Here’s how to ask me for a letter."
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Asking for Help",
    "section": "",
    "text": "Asking for help is a fundamental part of how you will learn in CSCI 0451. Do it often. Here is some wisdom on this topic from the Best Cat On the Internet:\n© Phil Chodrow, 2023"
  },
  {
    "objectID": "help.html#dont-get-stuck",
    "href": "help.html#dont-get-stuck",
    "title": "Asking for Help",
    "section": "Don’t Get Stuck",
    "text": "Don’t Get Stuck\nWe want to productively challenge you, which is different from letting you get stuck. If you’ve spent more than 30 minutes without making any progress or change in your understanding, then that’s likely a sign that you should consult a new reading or other resource, ask for help from a classmate, a Course Assistant, or me."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week 1 \n            \n        \n            \n                    M\n                    \n                    Feb. 13 \n             Welcome!\n   \n        \n        \n             \n                We discuss how the course works and begin our discussion of classification and auditing. \n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Getting Oriented  \n            \n            \n                    Reading\n                           Course syllabus \n                           Collaboration \n                           Why I Don't Grade by Jesse Stommel \n                           Daumé 1.1-1.5 \n            \n            \n                    Notes\n                            Welcome slides\n  \n            \n            \n                    Warmup\n                    Set up your software.\n            \n            \n                    Assignments\n                    No really, set up your software.\n            \n        \n        \n            \n                    W\n                    \n                    Feb. 15 \n             Classification: The Perceptron\n   \n        \n        \n             \n                We study the perceptron algorithm, a historical method that serves as the foundation for many modern classifiers. \n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Theory  \n                            Implementation  \n            \n            \n                    Reading\n                           Daumé 4.1-4.5, 4.7 \n                           Introduction to Numpy from The Python Data Science Handbook by Jake VanderPlas \n                           Linear algebra with Numpy \n                           Hardt and Recht, p. 33-41 (if you need to see a definition of a function gradient, see Daumé p. 93) \n            \n            \n                    Notes\n                            Lecture notes\n  \n            \n            \n                    Warmup\n                    Perceptron\n            \n            \n                    Assignments\n                    Blog post: perceptron\n            \n        \n            \n             Week 2 \n            \n        \n            \n                    M\n                    \n                    Feb. 20 \n             Convex Linear Models and Logistic Regression\n   \n        \n        \n             \n                We discuss the modeling choices necessary to make the empirical risk minimization problem for linear classifiers tractable. In doing so we discuss convex functions and some of their properties that are relevant for optimization. Finally, we introduce logistic regression as an example of a convex linear classifier. \n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Theory  \n                            Implementation  \n            \n            \n                    Reading\n                           Daumé 2.1-2.7\n \n                           Daumé 7.1-7.3\n \n                           Hardt and Recht, p. 70-77 \n            \n            \n                    Notes\n                            Lecture notes  \n            \n            \n                    Warmup\n                    Convexity\n            \n            \n            \n        \n        \n            \n                    W\n                    \n                    Feb. 22 \n             Optimization via Gradient Descent \n   \n        \n        \n             \n                We discuss standard mathematical methods for empirical risk minimization, including gradient descent and stochastic gradient descent. We also recontextualize the perceptron algorithm as stochastic subgradient descent for a linear classifier with a specific loss function. \n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Theory  \n                            Implementation  \n            \n            \n                    Reading\n                           Daumé 7.4-7.6 \n                           Diesenroth, Faisal, and Soon, p. 225-233 \n            \n            \n                    Notes\n                            Lecture notes  \n            \n            \n                    Warmup\n                    Gradient Descent\n            \n            \n                    Assignments\n                    Blog post: gradient descent\n            \n        \n            \n             Week 3 \n            \n        \n            \n                    M\n                    \n                    Feb. 27 \n             Features, Regularization, and Nonlinear Decision Boundaries\n   \n        \n        \n             \n                TBD\n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Theory  \n                            Implementation  \n                            Navigation  \n                            Experimentation  \n            \n            \n                    Reading\n                           TBD \n            \n            \n                    Notes\n                            TBD  \n            \n            \n                    Warmup\n                    TBD\n            \n            \n                    Assignments\n                    ACTUAL REAL DUE DATE: Reflective Goal-Setting due 2/27 \n            \n        \n        \n            \n                    W\n                    \n                    Mar. 01 \n             Kernel Methods\n   \n        \n        \n             \n                TBD\n            \n        \n        \n            \n            \n                    Learning Objectives\n                            Theory  \n            \n            \n                    Reading\n                           TBD \n            \n            \n                    Notes\n                            TBD  \n            \n            \n                    Warmup\n                    TBD\n            \n            \n                    Assignments\n                    Blog post: kernel logistic regression\n            \n        \n            \n            \n            \n        \n\nNo matching items\n\n  © Phil Chodrow, 2023"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "© Phil Chodrow, 2023"
  }
]