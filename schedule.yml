- date: 2023-02-13
  header: | 
    Welcome!
  summary: |
    We discuss how the course works and begin our discussion of classification and auditing. 
  objectives: 
    - Getting Oriented
  reading:
    - <a href="syllabus.qmd">Course syllabus</a>
    - <a href="collaboration.qmd">Collaboration</a>
    - <a href="https://via.hypothes.is/https://www.jessestommel.com/why-i-dont-grade/">Why I Don't Grade</a> by Jesse Stommel
    - <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch01.pdf">Daumé 1.1-1.5</a>
  notes: 
    - |
      <a href="slides/welcome.qmd">Welcome slides</a>
  module: Classification
  publish: true
  warmup: <a href="software.qmd">Set up your software</a>.
  assignments: No really, <br><a href="software.qmd">set up your software</a>.
- date: 2023-03-01
  header: | 
    More On Classification and Auditing
  summary: |
    We continue our discussion of classification and introduce algorithmic bias. 
  objectives: 
    - Social Responsibility
    - Navigation
    - Experimentation
  reading:
    - <a href="https://via.hypothes.is/https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias</a> from <i>ProPublica</i>
    - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/#3.-Data-Manipulation-with-Pandas">Data Manipulation with Pandas</a> from <i>The Python Data Science Handbook</i> by Jake VanderPlas
    - Example 2.3.1 from <a href="https://github.com/probml/pml-book/releases/latest/download/book1.pdf">Murphy</a> 
  notes: 
    - |
      <a href="lecture-notes/intro-classification.ipynb">Lecture notes</a>
  module: Classification
  publish: false
  warmup: <a href="warmup-exercises.qmd#classification-rates"> Classification rates </a>
  assignments:
    - |
      <a href="assignments/process/goal-setting.ipynb">Reflective goal-setting</a> <br><b>ACTUAL REQUIRED DUE DATE: 2/24</b>
- date: 2023-02-15
  header: | 
    Classification: The Perceptron
  summary: |
    We study the perceptron algorithm, a historical method that serves as the foundation for many modern classifiers. 
  objectives: 
    - Theory
    - Implementation
  reading:
    - <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch04.pdf">Daumé 4.1-4.5, 4.7</a>
    - <a href="https://jakevdp.github.io/PythonDataScienceHandbook/#2.-Introduction-to-NumPy">Introduction to Numpy</a> from The Python Data Science Handbook by Jake VanderPlas
    - <a href="https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/math/linear-algebra-I.ipynb">Linear algebra with Numpy</a>
  optional: 
    - <a href="https://via.hypothes.is/https://arxiv.org/pdf/2102.05242.pdf">Hardt and Recht</a>, p. 33-41 (if you need to see a definition of a function gradient, see <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé p. 93</a>)
  notes: 
    - |
      <a href="lecture-notes/perceptron.ipynb">Lecture notes</a>
  module: Classification
  publish: true
  warmup: <a href="warmup-exercises.qmd#sec-perceptron">Perceptron</a>
  assignments: 
    - |
      <a href="assignments/blog-posts/blog-post-perceptron.qmd">Blog post: perceptron</a>
- date: 2023-02-20
  header: | 
    Convex Linear Models and Logistic Regression
  summary: |
    We discuss the modeling choices necessary to make the empirical risk minimization problem for linear classifiers tractable. In doing so we discuss convex functions and some of their properties that are relevant for optimization. Finally, we introduce logistic regression as an example of a convex linear classifier. 
  objectives: 
    - Theory
    - Implementation
  reading:
    - |
      <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch02.pdf">Daumé 2.1-2.7</a>
    - |
      <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé 7.1-7.3</a>
    - <a href="https://via.hypothes.is/https://arxiv.org/pdf/2102.05242.pdf">Hardt and Recht, p. 70-77</a>
  notes: 
    - <a href="lecture-notes/convex-linear-models.ipynb">Lecture notes</a>
  module: Classification
  publish: true
  warmup: <a href="warmup-exercises.qmd#sec-convexity">Convexity</a>
- date: 2023-02-22
  header: | 
    Optimization via Gradient Descent 
  summary: |
    We discuss standard mathematical methods for empirical risk minimization, including gradient descent and stochastic gradient descent. We also recontextualize the perceptron algorithm as stochastic subgradient descent for a linear classifier with a specific loss function. 
  objectives: 
    - Theory
    - Implementation
  reading:
    - <a href="https://via.hypothes.is/http://ciml.info/dl/v0_99/ciml-v0_99-ch07.pdf">Daumé 7.4-7.6</a>
    - <a href="https://via.hypothes.is/https://mml-book.github.io/book/mml-book.pdf">Diesenroth, Faisal, and Soon, p. 225-233</a>
  notes: 
    - <a href="lecture-notes/gradient-descent.qmd">Lecture notes</a>
  module: Classification
  publish: true
  warmup: TBD
  assignments:
    - |
      Blog post: Gradient Descent for Logistic Regression (details soon) <br> <br> <b> ACTUAL REAL DUE DATE: <a <a href="assignments/process/goal-setting.ipynb">Reflective Goal-Setting</a> due 2/24 </b>
- date: 2023-02-27
  header: | 
    Features, Regularization, and Nonlinear Decision Boundaries
  summary: |
    TBD
  objectives: 
    - Theory
    - Implementation
    - Navigation
    - Experimentation
  reading:
    - TBD
  notes: 
    - TBD
  module: Classification
  publish: true
  warmup: TBD
  assignments:
- date: 2023-03-01
  header: | 
    Kernel Methods
  summary: |
    TBD
  objectives: 
    - Theory
  reading:
    - TBD
  notes: 
    - TBD
  module: Classification
  publish: true
  warmup: TBD
  assignments:
    - |
      Blog post: kernel logistic regression or kernel support vector machine SVM
- date: 2023-03-06
  header: | 
    Generalization
  summary: |
    TBD
  objectives: 
    - Theory
    - Implementation
    - Navigation
  reading:
    - TBD
  notes: 
    - TBD
  module: Classification
  publish: false
  warmup: TBD
  assignments:
- date: 2023-03-08
  header: | 
    Model Selection in Practice
  summary: |
    TBD
  objectives: 
    - Navigation
    - Experimentation
  reading:
    - TBD
  notes: 
    - TBD
  module: Classification
  publish: false
  warmup: TBD
  assignments:
    - |
      Blog post: automated feature selection
- date: 2023-03-13
  header: | 
    Linear Regression
  summary: |
    TBD
  objectives: 
    - Implementation
  reading:
    - TBD
  notes: 
    - TBD
  module: Regression
  publish: false
  warmup: TBD
  assignments:
- date: 2023-03-15
  header: | 
    Introduction to Algorithmic Bias
  summary: |
    TBD
  objectives: 
    - Social Responsibility 
    - Experimentation
  reading:
    - TBD
  notes: 
    - TBD
  module: Regression
  publish: false
  warmup: TBD
  assignments:
    - TBD
- date: 2023-03-20
  header: | 
    Formal Definitions of Bias and Fairness
  summary: |
    TBD
  objectives: 
    - Social Responsibility 
    - Theory
  reading:
    - Formal definitions
    - Limitations of formal definitions
  notes: 
    - TBD
  module: Regression
  publish: false
  warmup: TBD
  assignments:
- date: 2023-03-22
  header: TBD
  summary: |
    TBD
  objectives: 
    - Implementation
  reading:
    - TBD
  notes: 
    - TBD
  module: Regression
  publish: false
  warmup: TBD
  assignments:
    - TBD




